{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38705a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['INDEX', '在院日数', '転帰', '平均気温', '平均気圧', 'Month', 'Age', 'Male', 'BMI',\n",
      "       'NIHSS_aa意識レベル', 'NIHSS_ab質問に対する反応', 'NIHSS_ac命令への反応', 'NIHSS_b最良の注視',\n",
      "       'NIHSS_c視野', 'NIHSS_d顔面麻痺', 'NIHSS_e上肢の運動右', 'NIHSS_f上肢の運動左',\n",
      "       'NIHSS_g下肢の運動右', 'NIHSS_h下肢の運動左', 'NIHSS_i四肢の運動失調', 'NIHSS_j感覚',\n",
      "       'NIHSS_k言語', 'NIHSS_l構音障害', 'NIHSS_m消去無視', 'NIHSS_total score',\n",
      "       'NIHSS_total_初診時', 'NIHSS_total_24h後', 't-pa', 'エダラボン', '抗てんかん剤', 'RAS',\n",
      "       'Asprin', 'P2Y12', '睡眠薬', '抗凝固薬', '糖尿病治療薬', 'スタチン', 'β遮断薬', '抗生剤',\n",
      "       '精神薬', 'リハビリ介入', '脳血栓回収術', '食事', 'ad_APTT', 'ad_Alb', 'ad_BNP',\n",
      "       'ad_BUN', 'ad_CRP', 'ad_Hb', 'ad_HbA1c', 'ad_K', 'ad_LDL_C', 'ad_Na',\n",
      "       'ad_PT_INR', 'ad_WBC', 'ad_eGFR', 'hours_48_APTT', 'hours_48_Alb',\n",
      "       'hours_48_BNP', 'hours_48_BUN', 'hours_48_CRP', 'hours_48_Hb',\n",
      "       'hours_48_HbA1c', 'hours_48_K', 'hours_48_LDL_C', 'hours_48_Na',\n",
      "       'hours_48_PT_INR', 'hours_48_WBC', 'hours_48_eGFR', 'hours_48_心拍数',\n",
      "       'hours_48_非観血_収縮期', '寝返り', '移乗', '口腔清潔', '食事摂取', '衣服の着脱', '指示が通じる',\n",
      "       '危険行動', 'B項目', 'TIA', 'アテローム血栓性梗塞', 'その他の脳梗塞', 'ラクナ梗塞', '心原性脳塞栓',\n",
      "       '脳出血'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Excelファイルを読み込む\n",
    "df = pd.read_excel(r\"C:\\Users\\tears\\Desktop\\Study\\2025\\12_CI\\004_ML2\\Merge_20250815_1.xlsx\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccf720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# --- 1. データ準備 ---\n",
    "df = pd.read_excel(r\"C:\\Users\\tears\\Desktop\\Study\\2025\\12_CI\\004_ML2\\Merge_20250815_1.xlsx\")\n",
    "idx_event = df[['INDEX', '在院日数', '転帰']]\n",
    "df_values = df.drop(columns=['INDEX', '在院日数', '転帰'])\n",
    "\n",
    "# --- 2. LGBMRegressor を推定器に指定 ---\n",
    "est_lgb = LGBMRegressor(\n",
    "    n_estimators=50,      # 木の本数\n",
    "    learning_rate=0.1,    # 学習率\n",
    "    n_jobs=-1,            # 全コア並列\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    estimator=est_lgb,\n",
    "    max_iter=5,           # イテレーション回数\n",
    "    random_state=0,\n",
    "    initial_strategy='mean'\n",
    ")\n",
    "\n",
    "# --- 3. 補完＋結合を一気に実行 ---\n",
    "df_imputed = pd.concat([\n",
    "    pd.DataFrame(\n",
    "        imp.fit_transform(df_values),\n",
    "        columns=df_values.columns,\n",
    "        index=df.index\n",
    "    ),\n",
    "    idx_event\n",
    "], axis=1)\n",
    "\n",
    "# --- 4. 結果確認 ---\n",
    "print(df_imputed.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34162af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完全データセットをエクセルファイルに保存\n",
    "df_imputed.to_excel('completed_data_20250815.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51530b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['平均気温', '平均気圧', 'Month', 'Age', 'Male', 'BMI', 'NIHSS_aa意識レベル',\n",
      "       'NIHSS_ab質問に対する反応', 'NIHSS_ac命令への反応', 'NIHSS_b最良の注視', 'NIHSS_c視野',\n",
      "       'NIHSS_d顔面麻痺', 'NIHSS_e上肢の運動右', 'NIHSS_f上肢の運動左', 'NIHSS_g下肢の運動右',\n",
      "       'NIHSS_h下肢の運動左', 'NIHSS_i四肢の運動失調', 'NIHSS_j感覚', 'NIHSS_k言語',\n",
      "       'NIHSS_l構音障害', 'NIHSS_m消去無視', 'NIHSS_total score', 'NIHSS_total_初診時',\n",
      "       'NIHSS_total_24h後', 't-pa', 'エダラボン', '抗てんかん剤', 'RAS', 'Asprin', 'P2Y12',\n",
      "       '睡眠薬', '抗凝固薬', '糖尿病治療薬', 'スタチン', 'β遮断薬', '抗生剤', '精神薬', 'リハビリ介入',\n",
      "       '脳血栓回収術', '食事', 'ad_APTT', 'ad_Alb', 'ad_BNP', 'ad_BUN', 'ad_CRP',\n",
      "       'ad_Hb', 'ad_HbA1c', 'ad_K', 'ad_LDL_C', 'ad_Na', 'ad_PT_INR', 'ad_WBC',\n",
      "       'ad_eGFR', 'hours_48_APTT', 'hours_48_Alb', 'hours_48_BNP',\n",
      "       'hours_48_BUN', 'hours_48_CRP', 'hours_48_Hb', 'hours_48_HbA1c',\n",
      "       'hours_48_K', 'hours_48_LDL_C', 'hours_48_Na', 'hours_48_PT_INR',\n",
      "       'hours_48_WBC', 'hours_48_eGFR', 'hours_48_心拍数', 'hours_48_非観血_収縮期',\n",
      "       '寝返り', '移乗', '口腔清潔', '食事摂取', '衣服の着脱', '指示が通じる', '危険行動', 'B項目', 'TIA',\n",
      "       'アテローム血栓性梗塞', 'その他の脳梗塞', 'ラクナ梗塞', '心原性脳塞栓', '脳出血', 'INDEX', '在院日数',\n",
      "       '転帰'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "completed_data = pd.read_excel(r\"C:\\Users\\tears\\Desktop\\Study\\2025\\12_CI\\004_ML2\\completed_data_20250815.xlsx\") \n",
    "print(completed_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d138ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 16:59:53,006 [INFO] MODE=full | {'MI_M': 10, 'MI_MAX_ITER': 20, 'MI_SAMPLE_POST': True, 'N_SPLITS': 5, 'N_TRIALS': 80, 'PATIENCE': 20, 'N_BOOT': 600, 'BIG_SEARCH': True, 'ES_ROUNDS': 100, 'XGB_N_EST_CLS': 1200, 'XGB_N_EST_REG': 900, 'MAX_BIN': 256, 'DO_SHAP': True}\n",
      "2025-08-15 16:59:54,806 [INFO] Raw shape: (3000, 86)\n",
      "2025-08-15 17:02:50,645 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,645 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,645 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,645 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,645 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,645 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,663 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,667 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,668 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 17:02:50,671 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_with_meta (MI#1): (3000, 90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.811643:  80%|████████  | 64/80 [1:02:13<15:33, 58.33s/it] \n",
      "2025-08-15 18:05:03,686 [INFO] [STACK TUNED - CLASS] {'max_depth': 12, 'learning_rate': 0.007745914425222318, 'min_child_weight': 18, 'gamma': 8.420114543465075, 'subsample': 0.5872490444948715, 'colsample_bytree': 0.5056305867508254, 'reg_alpha': 0.5198653317679335, 'reg_lambda': 3.591189787205119}\n",
      "2025-08-15 18:05:03,686 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,702 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,705 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,706 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,712 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,712 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,712 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,721 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,724 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:05:03,724 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "Best trial: 35. Best value: -14.0456:  70%|███████   | 56/80 [06:08<02:38,  6.59s/it]\n",
      "2025-08-15 18:11:12,642 [INFO] [STACK TUNED - REG] {'learning_rate': 0.12380207970931287, 'max_depth': 3, 'min_child_weight': 10, 'gamma': 6.458226477034435, 'subsample': 0.931938805193547, 'colsample_bytree': 0.9424333141500365, 'reg_alpha': 10.2688663428639, 'reg_lambda': 0.0075168622044808715}\n",
      "2025-08-15 18:11:12,645 [INFO] ===== MI #1 / 10 =====\n",
      "2025-08-15 18:11:12,650 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:11:19,845 [INFO] SHAP error (MI#1): module 'shap.utils' has no attribute '_log'\n",
      "2025-08-15 18:11:19,847 [INFO] ===== MI #2 / 10 =====\n",
      "2025-08-15 18:11:19,851 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:11:26,984 [INFO] ===== MI #3 / 10 =====\n",
      "2025-08-15 18:11:26,986 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:11:33,991 [INFO] ===== MI #4 / 10 =====\n",
      "2025-08-15 18:11:33,995 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:11:41,013 [INFO] ===== MI #5 / 10 =====\n",
      "2025-08-15 18:11:41,015 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:11:48,294 [INFO] ===== MI #6 / 10 =====\n",
      "2025-08-15 18:11:48,298 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:11:55,524 [INFO] ===== MI #7 / 10 =====\n",
      "2025-08-15 18:11:55,526 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:12:02,819 [INFO] ===== MI #8 / 10 =====\n",
      "2025-08-15 18:12:02,821 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:12:10,054 [INFO] ===== MI #9 / 10 =====\n",
      "2025-08-15 18:12:10,056 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      "2025-08-15 18:12:17,924 [INFO] ===== MI #10 / 10 =====\n",
      "2025-08-15 18:12:17,926 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了。出力先: C:\\Users\\tears\\Desktop\\Study\\2025\\12_CI\\004_ML2\\results_20250815_1659\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ============================================\n",
    "# 段階版フルコード：MI(時間意識) + GroupKFold + XGBoost + Optuna\n",
    "#  + EarlyStopping→全学習リフィット + GPUフォールバック + DCA/Calibration\n",
    "#  + RMSE後方互換 + LOSプール修正 + 実行環境の記録 + SHAP(任意)\n",
    "# MODE = \"quick\" | \"medium\" | \"full\" で切替\n",
    "# ============================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, sys, warnings, pickle, logging, inspect, platform, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple, Sequence, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from xgboost.core import XGBoostError\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 0) 基本設定\n",
    "# ─────────────────────────────────────────────\n",
    "MODE = \"full\"  # ← \"quick\" | \"medium\" | \"full\" に変更可\n",
    "\n",
    "# Excel（時間検証=0/1 を含む、転帰/在院日数/INDEX あり）\n",
    "RAW_PATH = r\"C:\\Users\\tears\\Desktop\\Study\\2025\\12_CI\\004_ML2\\Merge_20250815_1.xlsx\"\n",
    "\n",
    "# ログ・警告\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "class Config:\n",
    "    RESULT_DIR = Path(f\"results_{datetime.now():%Y%m%d_%H%M}\")\n",
    "    TARGET_COL = \"転帰\"        # 0/1/2 と一致していること\n",
    "    LOS_COL = \"在院日数\"\n",
    "    INDEX_COL = \"INDEX\"        # グルーピングに使用\n",
    "    TIME_FLAG_COL = \"時間検証\"  # 0: dev, 1: hold\n",
    "    CLASS_NAMES = [\"自宅\", \"転院\", \"死亡\"]\n",
    "    RANDOM_STATE = 42\n",
    "    REG_OBJECTIVE = \"reg:squarederror\"  # or \"count:poisson\"\n",
    "\n",
    "Config.RESULT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.FileHandler(Config.RESULT_DIR / \"training.log\", encoding=\"utf-8\"),\n",
    "              logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 1) 段階パラメータ（MODEで一括切替）\n",
    "# ─────────────────────────────────────────────\n",
    "class Tiers:\n",
    "    QUICK = dict(\n",
    "        MI_M=3, MI_MAX_ITER=10, MI_SAMPLE_POST=True,\n",
    "        N_SPLITS=3, N_TRIALS=12, PATIENCE=6, N_BOOT=150,\n",
    "        BIG_SEARCH=False, ES_ROUNDS=30,\n",
    "        XGB_N_EST_CLS=300, XGB_N_EST_REG=500, MAX_BIN=128,\n",
    "        DO_SHAP=False\n",
    "    )\n",
    "    MEDIUM = dict(\n",
    "        MI_M=5, MI_MAX_ITER=15, MI_SAMPLE_POST=True,\n",
    "        N_SPLITS=4, N_TRIALS=30, PATIENCE=10, N_BOOT=300,\n",
    "        BIG_SEARCH=False, ES_ROUNDS=50,\n",
    "        XGB_N_EST_CLS=500, XGB_N_EST_REG=700, MAX_BIN=256,\n",
    "        DO_SHAP=True\n",
    "    )\n",
    "    FULL = dict(\n",
    "        MI_M=10, MI_MAX_ITER=20, MI_SAMPLE_POST=True,\n",
    "        N_SPLITS=5, N_TRIALS=80, PATIENCE=20, N_BOOT=600,\n",
    "        BIG_SEARCH=True, ES_ROUNDS=100,\n",
    "        XGB_N_EST_CLS=1200, XGB_N_EST_REG=900, MAX_BIN=256,\n",
    "        DO_SHAP=True\n",
    "    )\n",
    "\n",
    "tier = {\"quick\": Tiers.QUICK, \"medium\": Tiers.MEDIUM, \"full\": Tiers.FULL}[MODE.lower()]\n",
    "\n",
    "# 反映\n",
    "class MIConfig:\n",
    "    M: int = tier[\"MI_M\"]\n",
    "    MAX_ITER: int = tier[\"MI_MAX_ITER\"]\n",
    "    SAMPLE_POSTERIOR: bool = tier[\"MI_SAMPLE_POST\"]\n",
    "    SEED: int = 20250815\n",
    "    USE_STACK_TUNING: bool = True  # ハイパラ探索は各MIのdevを縦結合して一度だけ\n",
    "\n",
    "Config.N_SPLITS = tier[\"N_SPLITS\"]\n",
    "Config.N_TRIALS = tier[\"N_TRIALS\"]\n",
    "Config.PATIENCE = tier[\"PATIENCE\"]\n",
    "Config.N_BOOT = tier[\"N_BOOT\"]\n",
    "Config.BIG_SEARCH = tier[\"BIG_SEARCH\"]\n",
    "\n",
    "ES_ROUNDS = tier[\"ES_ROUNDS\"]\n",
    "_XGB_N_EST_CLS = tier[\"XGB_N_EST_CLS\"]\n",
    "_XGB_N_EST_REG = tier[\"XGB_N_EST_REG\"]\n",
    "_MAX_BIN = tier[\"MAX_BIN\"]\n",
    "DO_SHAP = tier[\"DO_SHAP\"]\n",
    "\n",
    "logger.info(f\"MODE={MODE} | {tier}\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 2) 環境情報の保存（論文化用の再現性）\n",
    "# ─────────────────────────────────────────────\n",
    "def save_environment_snapshot(out_dir: Path):\n",
    "    try:\n",
    "        txt = []\n",
    "        txt.append(f\"Python: {sys.version}\")\n",
    "        txt.append(f\"Platform: {platform.platform()}\")\n",
    "        txt.append(f\"xgboost: {xgb.__version__}\")\n",
    "        try:\n",
    "            import sklearn\n",
    "            txt.append(f\"scikit-learn: {sklearn.__version__}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        # pip freeze\n",
    "        try:\n",
    "            pkgs = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"], text=True)\n",
    "            (out_dir / \"pip_freeze.txt\").write_text(pkgs, encoding=\"utf-8\")\n",
    "        except Exception as e:\n",
    "            txt.append(f\"pip freeze failed: {e}\")\n",
    "        (out_dir / \"env_info.txt\").write_text(\"\\n\".join(txt), encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"save_environment_snapshot failed: {e}\")\n",
    "\n",
    "save_environment_snapshot(Config.RESULT_DIR)\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 3) GPU 設定（強気） + フォールバック\n",
    "# ─────────────────────────────────────────────\n",
    "def gpu_params() -> dict:\n",
    "    ver = tuple(int(x) for x in xgb.__version__.split(\".\")[:2])\n",
    "    if ver >= (2, 0):\n",
    "        # まず GPU を試し、ダメなら後段のフォールバックでCPUへ\n",
    "        return dict(tree_method=\"hist\", device=\"cuda\", predictor=\"gpu_predictor\")\n",
    "    else:\n",
    "        try:\n",
    "            import cupy  # noqa\n",
    "            return dict(tree_method=\"gpu_hist\", predictor=\"gpu_predictor\")\n",
    "        except Exception:\n",
    "            return dict(tree_method=\"hist\", predictor=\"auto\")\n",
    "\n",
    "def fit_with_gpu_fallback_xgb(model, X, y, sample_weight=None, fit_kwargs=None):\n",
    "    \"\"\"\n",
    "    XGBClassifier/Regressor を GPU で学習し、失敗したら CPU にフォールバック。\n",
    "    sample_weight の二重渡しを抑止する。\n",
    "    \"\"\"\n",
    "    kw = dict(fit_kwargs or {})\n",
    "    # ---- sample_weight の二重渡し防止 ----\n",
    "    if \"sample_weight\" in kw:\n",
    "        kw.pop(\"sample_weight\")\n",
    "    if sample_weight is not None:\n",
    "        kw[\"sample_weight\"] = sample_weight\n",
    "\n",
    "    try:\n",
    "        model.fit(X, y, **kw)\n",
    "        return model, False  # GPU 成功\n",
    "    except XGBoostError:\n",
    "        # GPU設定をCPUに切替\n",
    "        try:\n",
    "            model.set_params(\n",
    "                **{k: v for k, v in dict(model.get_params()).items()\n",
    "                   if k not in (\"device\", \"tree_method\", \"predictor\")}\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "        model.set_params(tree_method=\"hist\", predictor=\"auto\")\n",
    "        model.fit(X, y, **kw)\n",
    "        return model, True   # CPU フォールバック\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 4) 前処理 Transformer / 補助関数\n",
    "# ─────────────────────────────────────────────\n",
    "class WinsorizeLog1pTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"列ごとの1%-99% winsorize。0以上かつ右歪みが強い列は log1p。\"\"\"\n",
    "    def __init__(self, q_low=0.01, q_high=0.99, skew_thr=1.0):\n",
    "        self.q_low = q_low\n",
    "        self.q_high = q_high\n",
    "        self.skew_thr = skew_thr\n",
    "        self.quantiles_: Dict[str, Tuple[float, float]] = {}\n",
    "        self.log_cols_: List[str] = []\n",
    "        self.columns_: List[str] = []\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        self.columns_ = list(X.columns)\n",
    "        for c in self.columns_:\n",
    "            s = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "            lo, hi = np.nanpercentile(s, [self.q_low*100, self.q_high*100])\n",
    "            self.quantiles_[c] = (lo, hi)\n",
    "            if (s.min(skipna=True) >= 0) and (abs(s.skew(skipna=True)) > self.skew_thr):\n",
    "                self.log_cols_.append(c)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        Z = X[self.columns_].copy()\n",
    "        for c in self.columns_:\n",
    "            s = pd.to_numeric(Z[c], errors=\"coerce\")\n",
    "            lo, hi = self.quantiles_[c]\n",
    "            s = s.clip(lo, hi)\n",
    "            if c in self.log_cols_:\n",
    "                s = np.log1p(s)\n",
    "            Z[c] = s.fillna(s.median())\n",
    "        return Z.values  # ndarrayで返す\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return np.array(self.columns_)\n",
    "\n",
    "def make_sample_weight(y: np.ndarray) -> np.ndarray:\n",
    "    classes = np.unique(y)\n",
    "    cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y)\n",
    "    wmap = {c: w for c, w in zip(classes, cw)}\n",
    "    return np.array([wmap[v] for v in y], dtype=float)\n",
    "\n",
    "def multiclass_brier(y_true: np.ndarray, y_prob: np.ndarray) -> float:\n",
    "    oh = label_binarize(y_true, classes=np.arange(y_prob.shape[1]))\n",
    "    return float(np.mean(np.sum((y_prob - oh) ** 2, axis=1)))\n",
    "\n",
    "def _bootstrap_ci_core(values: List[float], alpha=0.05) -> Tuple[float, float, float]:\n",
    "    vals = np.array([v for v in values if np.isfinite(v)])\n",
    "    if len(vals) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    pt = float(np.nanmean(vals))\n",
    "    lo = float(np.nanpercentile(vals, 100*(alpha/2)))\n",
    "    hi = float(np.nanpercentile(vals, 100*(1 - alpha/2)))\n",
    "    return pt, lo, hi\n",
    "\n",
    "def get_bootstrap_ci(y_true: np.ndarray, y_prob: np.ndarray, n_boot: int = None) -> Dict[str, Tuple[float,float,float]]:\n",
    "    if n_boot is None:\n",
    "        n_boot = Config.N_BOOT\n",
    "    rng = np.random.default_rng(Config.RANDOM_STATE)\n",
    "    n = len(y_true)\n",
    "\n",
    "    def _safe_auc(yy, pp, avg):\n",
    "        try:\n",
    "            return roc_auc_score(yy, pp, multi_class=\"ovr\", average=avg)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    def _safe_ap(yy, pp, avg):\n",
    "        try:\n",
    "            yy_oh = label_binarize(yy, classes=np.arange(pp.shape[1]))\n",
    "            return average_precision_score(yy_oh, pp, average=avg)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    auc_w, auc_m, ap_m, brier = [], [], [], []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        yy = y_true[idx]\n",
    "        pp = y_prob[idx]\n",
    "        auc_w.append(_safe_auc(yy, pp, \"weighted\"))\n",
    "        auc_m.append(_safe_auc(yy, pp, \"macro\"))\n",
    "        ap_m.append(_safe_ap(yy, pp, \"macro\"))\n",
    "        brier.append(multiclass_brier(yy, pp))\n",
    "\n",
    "    out = {\n",
    "        \"AUROC_weighted\": _bootstrap_ci_core(auc_w),\n",
    "        \"AUROC_macro\":    _bootstrap_ci_core(auc_m),\n",
    "        \"AP_macro\":       _bootstrap_ci_core(ap_m),\n",
    "        \"Brier\":          _bootstrap_ci_core(brier)\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# sklearn 互換 RMSE（古い版対策）\n",
    "from sklearn.metrics import mean_squared_error as _sk_mse\n",
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[int]]\n",
    "def rmse_score(y_true: ArrayLike, y_pred: ArrayLike) -> float:\n",
    "    y_true = np.asarray(y_true, dtype=float).ravel()\n",
    "    y_pred = np.asarray(y_pred, dtype=float).ravel()\n",
    "    try:\n",
    "        return float(_sk_mse(y_true, y_pred, squared=False))\n",
    "    except TypeError:\n",
    "        return float(np.sqrt(_sk_mse(y_true, y_pred)))\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 5) 特徴量作成（Δ・月の循環）※時間検証をメタとして保持\n",
    "# ─────────────────────────────────────────────\n",
    "features_initial = [\n",
    "    '平均気温','平均気圧','Month','Age','Male','BMI',\n",
    "    'NIHSS_total_初診時',\n",
    "    't-pa','エダラボン','抗てんかん剤','RAS','Asprin','P2Y12',\n",
    "    '睡眠薬','抗凝固薬','糖尿病治療薬','スタチン','β遮断薬',\n",
    "    '抗生剤','リハビリ介入','脳血栓回収術','食事',\n",
    "    'ad_APTT','ad_HbA1c','ad_LDL_C','ad_PT_INR',\n",
    "    'ad_Alb','ad_BNP','ad_BUN','ad_CRP','ad_Hb',\n",
    "    'ad_K','ad_Na','ad_WBC','ad_eGFR',\n",
    "    'hours_48_心拍数','hours_48_非観血_収縮期',\n",
    "    'NIHSS_ab質問に対する反応','NIHSS_ac命令への反応','NIHSS_b最良の注視','NIHSS_c視野',\n",
    "    'NIHSS_d顔面麻痺','NIHSS_e上肢の運動右','NIHSS_f上肢の運動左','NIHSS_g下肢の運動右',\n",
    "    'NIHSS_h下肢の運動左','NIHSS_i四肢の運動失調','NIHSS_j感覚','NIHSS_k言語',\n",
    "    'NIHSS_l構音障害','NIHSS_m消去無視',\n",
    "    'TIA','アテローム血栓性梗塞','その他の脳梗塞','ラクナ梗塞','心原性脳塞栓','脳出血'\n",
    "]\n",
    "DELTA_TARGETS = ['Alb','BNP','BUN','CRP','Hb','K','Na','WBC','eGFR']\n",
    "\n",
    "def signed_log1p(x: pd.Series) -> pd.Series:\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "def build_features_no_impute(df: pd.DataFrame, keep_meta: bool = True) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    created = []\n",
    "    for col in DELTA_TARGETS:\n",
    "        ad_col = f\"ad_{col}\"; d3_col = f\"hours_48_{col}\"\n",
    "        if ad_col in out.columns and d3_col in out.columns:\n",
    "            out[f\"delta_{col}\"] = out[d3_col] - out[ad_col]\n",
    "            out[f\"delta_pct_{col}\"] = ((out[d3_col] - out[ad_col]) / out[ad_col].replace(0, np.nan)) * 100\n",
    "            out[f\"delta_pct_{col}\"] = out[f\"delta_pct_{col}\"].clip(-500, 500)\n",
    "            out[f\"delta_slog_{col}\"] = signed_log1p(out[f\"delta_{col}\"])\n",
    "            created += [f\"delta_{col}\", f\"delta_pct_{col}\", f\"delta_slog_{col}\"]\n",
    "\n",
    "    # 48h採血（バイタル以外）は削除\n",
    "    drop_cols = [c for c in out.columns if c.startswith(\"hours_48_\")\n",
    "                 and c not in (\"hours_48_心拍数\", \"hours_48_非観血_収縮期\")]\n",
    "    out.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "    extra = []\n",
    "    if 'Month' in out.columns:\n",
    "        out['Month_sin'] = np.sin(2 * np.pi * (out['Month'].astype(float) / 12.0))\n",
    "        out['Month_cos'] = np.cos(2 * np.pi * (out['Month'].astype(float) / 12.0))\n",
    "        extra += ['Month_sin','Month_cos']\n",
    "\n",
    "    base_cols = [c for c in features_initial if c in out.columns]\n",
    "    use_cols = base_cols + [c for c in created if c in out.columns] + extra\n",
    "\n",
    "    dt = out[use_cols].copy()\n",
    "    if keep_meta:\n",
    "        for mc in [Config.TARGET_COL, Config.LOS_COL, Config.INDEX_COL, Config.TIME_FLAG_COL]:\n",
    "            if mc in out.columns and mc not in dt.columns:\n",
    "                dt[mc] = out[mc]\n",
    "\n",
    "    for c in dt.columns:\n",
    "        if dt[c].dtype == bool:\n",
    "            dt[c] = dt[c].astype(int)\n",
    "    return dt\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 6) 多重代入（MICE, dev で fit → hold は transform）\n",
    "# ─────────────────────────────────────────────\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "META_COLS = [Config.TARGET_COL, Config.LOS_COL, Config.INDEX_COL, Config.TIME_FLAG_COL]\n",
    "\n",
    "def _iterative_imputer(seed: int) -> IterativeImputer:\n",
    "    return IterativeImputer(\n",
    "        random_state=seed,\n",
    "        max_iter=MIConfig.MAX_ITER,\n",
    "        sample_posterior=MIConfig.SAMPLE_POSTERIOR,\n",
    "        skip_complete=True,\n",
    "        tol=1e-3,\n",
    "        imputation_order=\"ascending\",\n",
    "        n_nearest_features=None,\n",
    "        min_value=None, max_value=None\n",
    "    )\n",
    "\n",
    "def multiple_impute_then_build(raw_df: pd.DataFrame,\n",
    "                               feature_builder_fn,\n",
    "                               features_needed: List[str]) -> List[pd.DataFrame]:\n",
    "    df = raw_df.copy()\n",
    "    if Config.TARGET_COL not in df.columns:\n",
    "        raise RuntimeError(f\"入力データに '{Config.TARGET_COL}' がありません。\")\n",
    "    df = df[~df[Config.TARGET_COL].isna()].copy()\n",
    "\n",
    "    if Config.TIME_FLAG_COL not in df.columns:\n",
    "        raise RuntimeError(f\"時間検証カラム '{Config.TIME_FLAG_COL}' がありません（0/1必須）。\")\n",
    "\n",
    "    core_cols = [c for c in features_needed if c in df.columns]\n",
    "    num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in META_COLS]\n",
    "    impute_cols = sorted(set(core_cols + num_cols))\n",
    "\n",
    "    msk_dev = (df[Config.TIME_FLAG_COL] == 0)\n",
    "    imputed_list: List[pd.DataFrame] = []\n",
    "    rng = np.random.default_rng(MIConfig.SEED)\n",
    "\n",
    "    for _ in range(MIConfig.M):\n",
    "        seed = int(rng.integers(1, 10_000_000))\n",
    "        imp = _iterative_imputer(seed)\n",
    "\n",
    "        Xd = df.loc[msk_dev,  impute_cols].astype(float)\n",
    "        Xh = df.loc[~msk_dev, impute_cols].astype(float)\n",
    "\n",
    "        imp.fit(Xd)                     # devのみで学習（リーク回避）\n",
    "        Xd_imp = imp.transform(Xd)\n",
    "        Xh_imp = imp.transform(Xh)\n",
    "\n",
    "        imputed = df.copy()\n",
    "        imputed.loc[msk_dev,  impute_cols] = Xd_imp\n",
    "        imputed.loc[~msk_dev, impute_cols] = Xh_imp\n",
    "\n",
    "        dt = feature_builder_fn(imputed, keep_meta=True)\n",
    "        imputed_list.append(dt)\n",
    "\n",
    "    return imputed_list\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 7) ES コールバック・可視化ユーティリティ\n",
    "# ─────────────────────────────────────────────\n",
    "def _build_xgb_fit_kwargs_for_es(\n",
    "    model: xgb.XGBClassifier,\n",
    "    X_val: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    sample_weight_tr: np.ndarray | None,\n",
    "    es_rounds: int = 100\n",
    ") -> dict:\n",
    "    sig = inspect.signature(model.fit)\n",
    "    kw: dict = {}\n",
    "    if sample_weight_tr is not None:\n",
    "        kw[\"sample_weight\"] = sample_weight_tr\n",
    "    if \"callbacks\" in sig.parameters:\n",
    "        es_cb = xgb.callback.EarlyStopping(rounds=es_rounds, save_best=True, maximize=False)\n",
    "        kw.update(dict(eval_set=[(X_val, y_val)], callbacks=[es_cb]))\n",
    "    elif \"early_stopping_rounds\" in sig.parameters:\n",
    "        kw.update(dict(eval_set=[(X_val, y_val)], early_stopping_rounds=es_rounds, verbose=False))\n",
    "    return kw\n",
    "\n",
    "def save_confusion_matrix_plot(cm: np.ndarray, model_name: str):\n",
    "    plt.figure(figsize=(7.5, 6))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"YlGnBu\",\n",
    "                     xticklabels=Config.CLASS_NAMES, yticklabels=Config.CLASS_NAMES,\n",
    "                     cbar_kws={\"shrink\": .8}, linewidths=.5, linecolor='white')\n",
    "    ax.set_title(f'Confusion Matrix - {model_name}', pad=12)\n",
    "    ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Config.RESULT_DIR / f\"{model_name}_cm.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 8) 分類器・回帰器の構築 & チューニング（GroupKFold）\n",
    "# ─────────────────────────────────────────────\n",
    "def build_estimator(name: str):\n",
    "    if name == \"Logistic\":\n",
    "        mdl = LogisticRegression(max_iter=1500, random_state=Config.RANDOM_STATE)\n",
    "        space = {\"model__C\": optuna.distributions.FloatDistribution(1e-4, 1e1, log=True)}\n",
    "        return mdl, space\n",
    "\n",
    "    elif name == \"XGBoost\":\n",
    "        base_kwargs = dict(\n",
    "            objective=\"multi:softprob\",\n",
    "            eval_metric=\"mlogloss\",\n",
    "            n_estimators=_XGB_N_EST_CLS,\n",
    "            random_state=Config.RANDOM_STATE,\n",
    "            **gpu_params()\n",
    "        )\n",
    "        mdl = xgb.XGBClassifier(**base_kwargs)\n",
    "        mdl.set_params(max_bin=_MAX_BIN)\n",
    "        if Config.BIG_SEARCH:\n",
    "            space = {\n",
    "                \"model__max_depth\":            optuna.distributions.IntDistribution(3, 12),\n",
    "                \"model__learning_rate\":        optuna.distributions.FloatDistribution(1e-3, 3e-1, log=True),\n",
    "                \"model__min_child_weight\":     optuna.distributions.IntDistribution(1, 20),\n",
    "                \"model__gamma\":                optuna.distributions.FloatDistribution(0, 10),\n",
    "                \"model__subsample\":            optuna.distributions.FloatDistribution(.5, 1.0),\n",
    "                \"model__colsample_bytree\":     optuna.distributions.FloatDistribution(.5, 1.0),\n",
    "                \"model__reg_alpha\":            optuna.distributions.FloatDistribution(1e-6, 1e2, log=True),\n",
    "                \"model__reg_lambda\":           optuna.distributions.FloatDistribution(1e-6, 1e2, log=True),\n",
    "            }\n",
    "        else:\n",
    "            space = {\n",
    "                \"model__max_depth\":            optuna.distributions.IntDistribution(3, 8),\n",
    "                \"model__learning_rate\":        optuna.distributions.FloatDistribution(5e-3, 5e-2, log=True),\n",
    "                \"model__min_child_weight\":     optuna.distributions.IntDistribution(1, 10),\n",
    "                \"model__gamma\":                optuna.distributions.FloatDistribution(0, 4),\n",
    "                \"model__subsample\":            optuna.distributions.FloatDistribution(.6, .9),\n",
    "                \"model__colsample_bytree\":     optuna.distributions.FloatDistribution(.6, .9),\n",
    "                \"model__reg_alpha\":            optuna.distributions.FloatDistribution(1e-4, 1, log=True),\n",
    "                \"model__reg_lambda\":           optuna.distributions.FloatDistribution(1e-3, 5, log=True)\n",
    "            }\n",
    "        return mdl, space\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {name}\")\n",
    "\n",
    "def build_regressor_and_space():\n",
    "    reg = xgb.XGBRegressor(\n",
    "        objective=Config.REG_OBJECTIVE,\n",
    "        n_estimators=_XGB_N_EST_REG,\n",
    "        random_state=Config.RANDOM_STATE,\n",
    "        **gpu_params()\n",
    "    )\n",
    "    reg.set_params(max_bin=_MAX_BIN)\n",
    "    if Config.BIG_SEARCH:\n",
    "        space = {\n",
    "            \"model__learning_rate\":    optuna.distributions.FloatDistribution(1e-3, 3e-1, log=True),\n",
    "            \"model__max_depth\":        optuna.distributions.IntDistribution(3, 12),\n",
    "            \"model__min_child_weight\": optuna.distributions.IntDistribution(1, 20),\n",
    "            \"model__gamma\":            optuna.distributions.FloatDistribution(0, 10),\n",
    "            \"model__subsample\":        optuna.distributions.FloatDistribution(.5, 1.0),\n",
    "            \"model__colsample_bytree\": optuna.distributions.FloatDistribution(.5, 1.0),\n",
    "            \"model__reg_alpha\":        optuna.distributions.FloatDistribution(1e-6, 1e2, log=True),\n",
    "            \"model__reg_lambda\":       optuna.distributions.FloatDistribution(1e-6, 1e2, log=True)\n",
    "        }\n",
    "    else:\n",
    "        space = {\n",
    "            \"model__max_depth\":        optuna.distributions.IntDistribution(3, 10),\n",
    "            \"model__learning_rate\":    optuna.distributions.FloatDistribution(1e-3, 5e-2, log=True),\n",
    "            \"model__min_child_weight\": optuna.distributions.IntDistribution(1, 15),\n",
    "            \"model__gamma\":            optuna.distributions.FloatDistribution(0, 5),\n",
    "            \"model__subsample\":        optuna.distributions.FloatDistribution(.6, .95),\n",
    "            \"model__colsample_bytree\": optuna.distributions.FloatDistribution(.6, .95),\n",
    "            \"model__reg_alpha\":        optuna.distributions.FloatDistribution(1e-4, 10, log=True),\n",
    "            \"model__reg_lambda\":       optuna.distributions.FloatDistribution(1e-4, 10, log=True)\n",
    "        }\n",
    "    return reg, space\n",
    "\n",
    "def tune_hyperparameters(pipe: Pipeline, space: Dict, X: pd.DataFrame, y: np.ndarray, groups: np.ndarray):\n",
    "    # GroupKFold でリーク耐性（層別は諦める）\n",
    "    cv = GroupKFold(n_splits=Config.N_SPLITS)\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        params = {}\n",
    "        for k, d in space.items():\n",
    "            if isinstance(d, optuna.distributions.FloatDistribution):\n",
    "                params[k] = trial.suggest_float(k, d.low, d.high, log=d.log)\n",
    "            elif isinstance(d, optuna.distributions.IntDistribution):\n",
    "                params[k] = trial.suggest_int(k, d.low, d.high, step=d.step)\n",
    "            else:\n",
    "                params[k] = trial.suggest_categorical(k, d.choices)\n",
    "\n",
    "        pipe.set_params(**params)\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        oof = np.zeros((len(y), len(classes)), dtype=np.float32)\n",
    "\n",
    "        for fold_idx, (tr_idx, va_idx) in enumerate(cv.split(X, y, groups), 1):\n",
    "            Xtr, ytr = X.iloc[tr_idx], y[tr_idx]\n",
    "            Xva, yva = X.iloc[va_idx], y[va_idx]\n",
    "\n",
    "            # dev-train / dev-val（早期終了）→ best_iter を得る\n",
    "            Xtr_tr, Xtr_ev, ytr_tr, ytr_ev = train_test_split(\n",
    "                Xtr, ytr, test_size=0.10, stratify=None, random_state=Config.RANDOM_STATE\n",
    "            )\n",
    "            pre = clone(pipe.named_steps['pre']).fit(Xtr_tr, ytr_tr)\n",
    "            Xtr_tr_t = pre.transform(Xtr_tr)\n",
    "            Xtr_ev_t = pre.transform(Xtr_ev)\n",
    "\n",
    "            model = clone(pipe.named_steps['model'])\n",
    "            sw = make_sample_weight(ytr_tr)\n",
    "            fit_kwargs = {}\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                fit_kwargs = _build_xgb_fit_kwargs_for_es(model, Xtr_ev_t, ytr_ev, sw, es_rounds=ES_ROUNDS)\n",
    "\n",
    "            # ES 学習\n",
    "            model_es, _ = fit_with_gpu_fallback_xgb(model, Xtr_tr_t, ytr_tr, sample_weight=sw, fit_kwargs=fit_kwargs)\n",
    "            best_iter = int(getattr(model_es, \"best_iteration\", None) or getattr(model_es, \"best_ntree_limit\", model_es.get_params().get(\"n_estimators\", _XGB_N_EST_CLS)))\n",
    "\n",
    "            # dev 全体でリフィット\n",
    "            pre_full = clone(pipe.named_steps['pre']).fit(Xtr, ytr)\n",
    "            Xtr_full_t = pre_full.transform(Xtr)\n",
    "            Xva_t      = pre_full.transform(Xva)\n",
    "            model_full = clone(model_es).set_params(n_estimators=best_iter)\n",
    "            sw_full = make_sample_weight(ytr)\n",
    "            model_full, _ = fit_with_gpu_fallback_xgb(model_full, Xtr_full_t, ytr, sample_weight=sw_full)\n",
    "\n",
    "            oof[va_idx] = model_full.predict_proba(Xva_t)\n",
    "\n",
    "            # 途中経過（任意）\n",
    "            try:\n",
    "                part_auc = roc_auc_score(y[va_idx], oof[va_idx], multi_class=\"ovr\", average=\"weighted\")\n",
    "                trial.report(part_auc, step=fold_idx)\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        return roc_auc_score(y, oof, multi_class=\"ovr\", average=\"weighted\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=Config.RANDOM_STATE),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
    "    )\n",
    "    early_stop = lambda s, t: s.stop() if len(s.trials) - s.best_trial.number > Config.PATIENCE else None\n",
    "    study.optimize(objective, n_trials=Config.N_TRIALS, callbacks=[early_stop], show_progress_bar=True)\n",
    "\n",
    "    pipe.set_params(**study.best_params)\n",
    "    best_params = {k.replace(\"model__\", \"\"): v for k, v in study.best_params.items()}\n",
    "    return pipe, best_params\n",
    "\n",
    "def cv_predict_regression_group(pipe: Pipeline, X: pd.DataFrame, y: np.ndarray, groups: np.ndarray) -> np.ndarray:\n",
    "    cv = GroupKFold(n_splits=Config.N_SPLITS)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "    for tr_idx, va_idx in cv.split(X, y, groups):\n",
    "        Xtr, ytr = X.iloc[tr_idx], y[tr_idx]\n",
    "        Xva = X.iloc[va_idx]\n",
    "        ytr_log = np.log1p(ytr)\n",
    "        p = clone(pipe)\n",
    "        p.fit(Xtr, ytr_log)\n",
    "        pred_log = p.predict(Xva)\n",
    "        oof[va_idx] = np.expm1(pred_log).clip(0, None)\n",
    "    return oof\n",
    "\n",
    "def tune_regression(pipe: Pipeline, space: Dict, X: pd.DataFrame, y: np.ndarray, groups: np.ndarray):\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        params = {}\n",
    "        for k, d in space.items():\n",
    "            if isinstance(d, optuna.distributions.FloatDistribution):\n",
    "                params[k] = trial.suggest_float(k, d.low, d.high, log=d.log)\n",
    "            elif isinstance(d, optuna.distributions.IntDistribution):\n",
    "                params[k] = trial.suggest_int(k, d.low, d.high, step=d.step)\n",
    "            else:\n",
    "                params[k] = trial.suggest_categorical(k, d.choices)\n",
    "        pipe.set_params(**params)\n",
    "        oof = cv_predict_regression_group(pipe, X, y, groups)\n",
    "        rmse = rmse_score(y, oof)   # 後方互換ヘルパ\n",
    "        return -rmse\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=Config.RANDOM_STATE),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
    "    )\n",
    "    early_stop = lambda s, t: s.stop() if len(s.trials) - s.best_trial.number > Config.PATIENCE else None\n",
    "    study.optimize(objective, n_trials=Config.N_TRIALS, callbacks=[early_stop], show_progress_bar=True)\n",
    "    pipe.set_params(**study.best_params)\n",
    "    best_params = {k.replace(\"model__\", \"\"): v for k, v in study.best_params.items()}\n",
    "    return pipe, best_params\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 9) 時間検証 split / スタック\n",
    "# ─────────────────────────────────────────────\n",
    "def prepare_from_dt_timeaware(dt_with_meta: pd.DataFrame) -> Tuple[pd.DataFrame, np.ndarray, pd.DataFrame, np.ndarray]:\n",
    "    for col in [Config.TARGET_COL, Config.TIME_FLAG_COL]:\n",
    "        if col not in dt_with_meta.columns:\n",
    "            raise RuntimeError(f\"dt_with_meta に '{col}' がありません。\")\n",
    "    y = pd.to_numeric(dt_with_meta[Config.TARGET_COL], errors=\"coerce\").astype(int).to_numpy()\n",
    "\n",
    "    meta_cols = [c for c in [Config.TARGET_COL, Config.LOS_COL, Config.INDEX_COL, Config.TIME_FLAG_COL]\n",
    "                 if c in dt_with_meta.columns]\n",
    "    X = dt_with_meta.drop(columns=meta_cols)\n",
    "\n",
    "    msk_hold = (dt_with_meta[Config.TIME_FLAG_COL] == 1).to_numpy()\n",
    "    dev_X, hold_X = X.loc[~msk_hold], X.loc[msk_hold]\n",
    "    dev_y, hold_y = y[~msk_hold], y[msk_hold]\n",
    "    logger.info(f\"Temporal split: dev={len(dev_X)}, hold={len(hold_X)} (flag=1 as hold)\")\n",
    "    return dev_X, dev_y, hold_X, hold_y\n",
    "\n",
    "def stack_for_tuning_class(dt_list: List[pd.DataFrame]) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n",
    "    Xs, ys, gs = [], [], []\n",
    "    for dt in dt_list:\n",
    "        Xd, yd, _, _ = prepare_from_dt_timeaware(dt)\n",
    "        Xs.append(Xd); ys.append(yd)\n",
    "        gs.append(dt.loc[Xd.index, Config.INDEX_COL].values)\n",
    "    return pd.concat(Xs, axis=0), np.concatenate(ys, axis=0), np.concatenate(gs, axis=0)\n",
    "\n",
    "def stack_for_tuning_reg(dt_list: List[pd.DataFrame]) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n",
    "    Xs, ys, gs = [], [], []\n",
    "    for dt in dt_list:\n",
    "        Xd, _, _, _ = prepare_from_dt_timeaware(dt)\n",
    "        ylos_d = dt.loc[Xd.index, Config.LOS_COL].astype(float).to_numpy()\n",
    "        Xs.append(Xd); ys.append(ylos_d)\n",
    "        gs.append(dt.loc[Xd.index, Config.INDEX_COL].values)\n",
    "    return pd.concat(Xs, axis=0), np.concatenate(ys, axis=0), np.concatenate(gs, axis=0)\n",
    "\n",
    "def split_indices_from_first(dt_list: List[pd.DataFrame]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    dt0 = dt_list[0]\n",
    "    assert Config.INDEX_COL in dt0.columns, \"INDEX 列が必要です。\"\n",
    "    msk_hold = (dt0[Config.TIME_FLAG_COL] == 1).to_numpy()\n",
    "    idx_all = dt0.index.to_numpy()\n",
    "    return idx_all[~msk_hold], idx_all[msk_hold]\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 10) 実行フロー：MI → スタックチューニング → 各MI学習 → プール\n",
    "# ─────────────────────────────────────────────\n",
    "# 10-1) 読み込み\n",
    "raw = pd.read_excel(RAW_PATH)\n",
    "logger.info(f\"Raw shape: {raw.shape}\")\n",
    "\n",
    "# 10-2) MI → 特徴量生成（Δ・月sin/cos）→ dt_list\n",
    "dt_list = multiple_impute_then_build(\n",
    "    raw_df=raw,\n",
    "    feature_builder_fn=build_features_no_impute,\n",
    "    features_needed=features_initial + [f\"ad_{c}\" for c in DELTA_TARGETS] + [f\"hours_48_{c}\" for c in DELTA_TARGETS]\n",
    ")\n",
    "dt_preview = dt_list[0].copy()\n",
    "dt_preview.to_csv(Config.RESULT_DIR / \"dt_with_meta_preview_MI1.csv\", index=True, encoding=\"utf-8-sig\")\n",
    "print(\"dt_with_meta (MI#1):\", dt_preview.shape)\n",
    "\n",
    "# 10-3) スタックで一度だけハイパラ探索（分類 & 回帰）\n",
    "if MIConfig.USE_STACK_TUNING:\n",
    "    Xcls_stack, ycls_stack, gcls_stack = stack_for_tuning_class(dt_list)\n",
    "    pre_cls = WinsorizeLog1pTransformer()\n",
    "    base_model_cls, space_cls = build_estimator(\"XGBoost\")\n",
    "    pipe_cls = Pipeline([(\"pre\", pre_cls), (\"model\", base_model_cls)])\n",
    "    tuned_cls, best_cls_params = tune_hyperparameters(pipe_cls, space_cls, Xcls_stack, ycls_stack, gcls_stack)\n",
    "    logger.info(f\"[STACK TUNED - CLASS] {best_cls_params}\")\n",
    "else:\n",
    "    tuned_cls, best_cls_params = None, None\n",
    "\n",
    "Xreg_stack, yreg_stack, greg_stack = stack_for_tuning_reg(dt_list)\n",
    "pre_reg = WinsorizeLog1pTransformer()\n",
    "reg_base, reg_space = build_regressor_and_space()\n",
    "pipe_reg = Pipeline([(\"pre\", pre_reg), (\"model\", reg_base)])\n",
    "tuned_reg_global, best_reg_params = tune_regression(pipe_reg, reg_space, Xreg_stack, yreg_stack, greg_stack)\n",
    "logger.info(f\"[STACK TUNED - REG] {best_reg_params}\")\n",
    "\n",
    "# 10-4) 各MIで学習→HOLD 予測格納\n",
    "hold_proba_list: List[pd.DataFrame] = []\n",
    "hold_pred_los_list: List[pd.DataFrame] = []\n",
    "per_imp_metrics: List[Dict] = []\n",
    "device_records: List[str] = []\n",
    "\n",
    "dev_idx, hold_idx = split_indices_from_first(dt_list)\n",
    "\n",
    "for i, dt in enumerate(dt_list, 1):\n",
    "    logger.info(f\"===== MI #{i} / {MIConfig.M} =====\")\n",
    "    Xd, yd, Xh, yh = prepare_from_dt_timeaware(dt)\n",
    "\n",
    "    # ── 分類：pre fit → ES → best_iter で dev 全体リフィット → hold 予測\n",
    "    pre = WinsorizeLog1pTransformer().fit(Xd, yd)\n",
    "    Xd_tr = pre.transform(Xd)\n",
    "    Xh_tr = pre.transform(Xh)\n",
    "\n",
    "    base_model, _ = build_estimator(\"XGBoost\")\n",
    "    if best_cls_params is not None:\n",
    "        base_model.set_params(**best_cls_params)\n",
    "\n",
    "    Xtr_tr, Xtr_ev, ytr_tr, ytr_ev = train_test_split(\n",
    "        Xd_tr, yd, test_size=0.10, random_state=Config.RANDOM_STATE\n",
    "    )\n",
    "    sw = make_sample_weight(ytr_tr)\n",
    "    fit_kwargs = _build_xgb_fit_kwargs_for_es(base_model, Xtr_ev, ytr_ev, sw, es_rounds=ES_ROUNDS)\n",
    "\n",
    "    cls_es, used_cpu = fit_with_gpu_fallback_xgb(\n",
    "        clone(base_model), Xtr_tr, ytr_tr, sample_weight=sw, fit_kwargs=fit_kwargs\n",
    "    )\n",
    "    best_iter = int(getattr(cls_es, \"best_iteration\", None) or getattr(cls_es, \"best_ntree_limit\", cls_es.get_params().get(\"n_estimators\", _XGB_N_EST_CLS)))\n",
    "\n",
    "    cls_full = clone(base_model).set_params(n_estimators=best_iter)\n",
    "    sw_full = make_sample_weight(yd)\n",
    "    cls_full, used_cpu2 = fit_with_gpu_fallback_xgb(cls_full, Xd_tr, yd, sample_weight=sw_full)\n",
    "    device_records.append(f\"MI#{i} CLASS: {'CPU' if (used_cpu or used_cpu2) else 'GPU'} (best_iter={best_iter})\")\n",
    "\n",
    "    proba = cls_full.predict_proba(Xh_tr)\n",
    "    auroc = roc_auc_score(yh, proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "    brier = multiclass_brier(yh, proba)\n",
    "    cm = confusion_matrix(yh, np.argmax(proba, axis=1))\n",
    "    per_imp_metrics.append({\"MI\": i, \"AUROC_weighted\": auroc, \"Brier\": brier})\n",
    "\n",
    "    idx_hold = dt.loc[hold_idx, Config.INDEX_COL].to_numpy()\n",
    "    df_proba = pd.DataFrame(proba, index=idx_hold, columns=[f\"proba_{c}\" for c in Config.CLASS_NAMES])\n",
    "    hold_proba_list.append(df_proba)\n",
    "\n",
    "    # 前処理器の保存（再現性）\n",
    "    with open(Config.RESULT_DIR / f\"winsorizer_MI{i}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(pre, f)\n",
    "\n",
    "    # ── 回帰（在院日数）：log学習 → 予測戻し\n",
    "    pre_r = WinsorizeLog1pTransformer().fit(Xd, yd)  # yは未使用\n",
    "    Xd_tr_r = pre_r.transform(Xd)\n",
    "    Xh_tr_r = pre_r.transform(Xh)\n",
    "\n",
    "    reg_model, _ = build_regressor_and_space()\n",
    "    reg_model.set_params(**best_reg_params)\n",
    "\n",
    "    ylos_d = dt.loc[Xd.index, Config.LOS_COL].astype(float).to_numpy()\n",
    "    ytr_log = np.log1p(ylos_d)\n",
    "\n",
    "    reg_es, used_cpu_r = fit_with_gpu_fallback_xgb(clone(reg_model), Xd_tr_r, ytr_log)\n",
    "    reg_pred_log = reg_es.predict(Xh_tr_r)\n",
    "    yhat_los = np.expm1(reg_pred_log).clip(0, None)\n",
    "\n",
    "    hold_pred_los_list.append(pd.DataFrame({f\"在院日数予測_MI{i}\": yhat_los}, index=idx_hold))\n",
    "    device_records.append(f\"MI#{i} REG: {'CPU' if used_cpu_r else 'GPU'}\")\n",
    "\n",
    "    # ── SHAP（オプション、MI#1のみ）\n",
    "    if DO_SHAP and i == 1:\n",
    "        try:\n",
    "            import shap\n",
    "            shap.utils._log.setLevel(logging.WARNING)\n",
    "            SAMPLE_BG = min(600, Xd_tr.shape[0])\n",
    "            rng = np.random.default_rng(Config.RANDOM_STATE)\n",
    "            bg = Xd_tr[rng.choice(Xd_tr.shape[0], SAMPLE_BG, replace=False)]\n",
    "            try:\n",
    "                explainer = shap.TreeExplainer(cls_full, data=bg, feature_perturbation=\"interventional\")\n",
    "            except Exception:\n",
    "                explainer = shap.Explainer(cls_full, bg)\n",
    "            MAX_EVAL = min(2000, Xh_tr.shape[0])\n",
    "            X_eval = Xh_tr[:MAX_EVAL]\n",
    "            sv = explainer(X_eval)\n",
    "            vals = getattr(sv, \"values\", sv)\n",
    "            if vals.ndim == 2:\n",
    "                vals = vals[:, None, :]\n",
    "            feat_names = Xd.columns.tolist()\n",
    "            mean_abs = np.abs(vals).mean(axis=0).mean(axis=0)\n",
    "            gi = pd.Series(mean_abs, index=feat_names).sort_values(ascending=False)\n",
    "            gi.to_csv(Config.RESULT_DIR / f\"XGB_MI1_SHAP_global_importance.csv\", encoding=\"utf-8-sig\")\n",
    "        except Exception as e:\n",
    "            logger.info(f\"SHAP error (MI#1): {e}\")\n",
    "\n",
    "# 10-5) MIプール：確率は列名一致で平均、LOSは行方向平均→1列\n",
    "proba_concat = pd.concat(hold_proba_list, axis=1)\n",
    "proba_mean = pd.DataFrame(index=proba_concat.index.unique())\n",
    "for cname in Config.CLASS_NAMES:\n",
    "    cols = [c for c in proba_concat.columns if c == f\"proba_{cname}\"]\n",
    "    if cols:\n",
    "        proba_mean[f\"proba_{cname}\"] = proba_concat[cols].mean(axis=1)\n",
    "\n",
    "los_concat = pd.concat(hold_pred_los_list, axis=1)   # MI毎の列\n",
    "los_mean   = los_concat.mean(axis=1).to_frame(\"在院日数予測\")\n",
    "\n",
    "# 10-6) プール確率で最終評価\n",
    "yh_true = dt_list[0].loc[hold_idx, Config.TARGET_COL].astype(int).to_numpy()\n",
    "index_hold = dt_list[0].loc[hold_idx, Config.INDEX_COL].to_numpy()\n",
    "y_prob = proba_mean.loc[index_hold].values\n",
    "\n",
    "cm_final = confusion_matrix(yh_true, np.argmax(y_prob, axis=1))\n",
    "final_ci = get_bootstrap_ci(yh_true, y_prob)\n",
    "\n",
    "flat = {}\n",
    "for k, (pt, lo, hi) in final_ci.items():\n",
    "    flat[k] = pt; flat[f\"{k}_95CI_low\"] = lo; flat[f\"{k}_95CI_high\"] = hi\n",
    "summary_pooled = {\"Model\": f\"XGBoost_MIpooled_{MODE}\", **{f\"Hold_{k}\": v for k, v in flat.items()},\n",
    "                  \"Devices\": \" | \".join(device_records)}\n",
    "pd.DataFrame([summary_pooled]).to_excel(Config.RESULT_DIR / f\"summary_metrics_MIpooled_{MODE}.xlsx\", index=False)\n",
    "\n",
    "pd.DataFrame(cm_final, index=Config.CLASS_NAMES, columns=Config.CLASS_NAMES)\\\n",
    "  .to_csv(Config.RESULT_DIR / f\"XGBoost_cm_MIpooled_{MODE}.csv\", encoding=\"utf-8-sig\")\n",
    "save_confusion_matrix_plot(cm_final, f\"XGBoost_MIpooled_{MODE}\")\n",
    "\n",
    "\n",
    "\n",
    "# 10-6b) 在院日数（回帰）の最終評価（MI平均, hold）\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "\n",
    "# hold 真値\n",
    "ylos_true_hold = dt_list[0].loc[hold_idx, Config.LOS_COL].astype(float).to_numpy()\n",
    "\n",
    "# MI平均予測を INDEX 順に整列\n",
    "yhat_los_hold = los_mean.loc[index_hold, \"在院日数予測\"].to_numpy()\n",
    "\n",
    "def _mape(y_true, y_pred, eps=1e-6):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return float(np.mean(np.abs((y_pred - y_true) / denom)))\n",
    "\n",
    "rmse = rmse_score(ylos_true_hold, yhat_los_hold)\n",
    "mae  = float(np.mean(np.abs(ylos_true_hold - yhat_los_hold)))\n",
    "medae = median_absolute_error(ylos_true_hold, yhat_los_hold)\n",
    "mape = _mape(ylos_true_hold, yhat_los_hold)\n",
    "r2   = r2_score(ylos_true_hold, yhat_los_hold)\n",
    "\n",
    "los_metrics = {\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MedAE\": medae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"N_hold\": int(len(ylos_true_hold))\n",
    "}\n",
    "pd.DataFrame([los_metrics]).to_csv(\n",
    "    Config.RESULT_DIR / f\"LOS_metrics_hold_MIpooled_{MODE}.csv\",\n",
    "    index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "# 予測と真値の散布図（y=x）\n",
    "plt.figure(figsize=(6.2, 5.6))\n",
    "plt.scatter(ylos_true_hold, yhat_los_hold, s=12, alpha=0.6)\n",
    "lims = [0, max(np.max(ylos_true_hold), np.max(yhat_los_hold)) * 1.05]\n",
    "plt.plot(lims, lims, 'k--', label='y = x')\n",
    "plt.xlim(lims); plt.ylim(lims)\n",
    "plt.xlabel(\"True LOS\"); plt.ylabel(\"Predicted LOS\")\n",
    "plt.title(f\"LOS: True vs Pred (hold) | RMSE={rmse:.2f}, MAE={mae:.2f}, R2={r2:.3f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.RESULT_DIR / f\"LOS_scatter_hold_MIpooled_{MODE}.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# 残差解析（ヒスト & 残差-予測プロット）\n",
    "resid = yhat_los_hold - ylos_true_hold\n",
    "\n",
    "plt.figure(figsize=(6.2, 4.6))\n",
    "plt.hist(resid, bins=30, color=\"#4C72B0\", alpha=0.85, edgecolor=\"white\")\n",
    "plt.axvline(0, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Residual (Pred - True)\"); plt.ylabel(\"Count\")\n",
    "plt.title(\"LOS residual histogram (hold)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.RESULT_DIR / f\"LOS_residual_hist_hold_{MODE}.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6.2, 4.6))\n",
    "plt.scatter(yhat_los_hold, resid, s=10, alpha=0.6)\n",
    "plt.axhline(0, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Predicted LOS\"); plt.ylabel(\"Residual (Pred - True)\")\n",
    "plt.title(\"Residual vs Predicted (hold)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.RESULT_DIR / f\"LOS_resid_vs_pred_hold_{MODE}.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Bland-Altman（平均 vs 差）\n",
    "mean_pair = (yhat_los_hold + ylos_true_hold) / 2.0\n",
    "diff_pair = yhat_los_hold - ylos_true_hold\n",
    "ba_mean = float(np.mean(diff_pair))\n",
    "ba_sd   = float(np.std(diff_pair, ddof=1))\n",
    "loa_low = ba_mean - 1.96*ba_sd\n",
    "loa_hi  = ba_mean + 1.96*ba_sd\n",
    "\n",
    "plt.figure(figsize=(6.6, 5.2))\n",
    "plt.scatter(mean_pair, diff_pair, s=10, alpha=0.6)\n",
    "plt.axhline(ba_mean, color=\"C1\", linestyle=\"-\", label=f\"Mean diff={ba_mean:.2f}\")\n",
    "plt.axhline(loa_low, color=\"C3\", linestyle=\"--\", label=f\"LoA-={loa_low:.2f}\")\n",
    "plt.axhline(loa_hi, color=\"C3\", linestyle=\"--\", label=f\"LoA+={loa_hi:.2f}\")\n",
    "plt.xlabel(\"Mean of True and Pred LOS\"); plt.ylabel(\"Difference (Pred - True)\")\n",
    "plt.title(\"Bland–Altman (hold)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.RESULT_DIR / f\"LOS_bland_altman_hold_{MODE}.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# 予測と真値のテーブル（確認用）\n",
    "pd.DataFrame({\n",
    "    \"INDEX\": index_hold,\n",
    "    \"LOS_true\": ylos_true_hold,\n",
    "    \"LOS_pred\": yhat_los_hold,\n",
    "    \"Residual\": resid\n",
    "}).to_csv(Config.RESULT_DIR / f\"LOS_predictions_hold_MIpooled_{MODE}.csv\",\n",
    "         index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "\n",
    "# 10-7) 予測CSV（INDEX, 分類予測, 在院日数予測）※MI平均\n",
    "pred_cls = np.argmax(y_prob, axis=1).astype(int)\n",
    "pred_df = pd.DataFrame({\n",
    "    \"INDEX\": index_hold,\n",
    "    \"分類予測\": pred_cls\n",
    "}).set_index(\"INDEX\").join(los_mean, how=\"left\")\n",
    "pred_df.reset_index().to_csv(Config.RESULT_DIR / f\"predictions_holdout_MIpooled_{MODE}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 10-8) 校正 & DCA\n",
    "def _calibration_bin_stats(y_true_bin: np.ndarray, p_hat: np.ndarray, n_bins: int = 10):\n",
    "    df = pd.DataFrame({\"y\": y_true_bin.astype(int), \"p\": p_hat})\n",
    "    df = df.sort_values(\"p\").reset_index(drop=True)\n",
    "    df[\"bin\"] = pd.qcut(df[\"p\"].rank(method=\"first\"), q=n_bins, labels=False, duplicates=\"drop\")\n",
    "    grouped = df.groupby(\"bin\", observed=True)\n",
    "    out = pd.DataFrame({\n",
    "        \"pred_mean\": grouped[\"p\"].mean(),\n",
    "        \"obs_rate\":  grouped[\"y\"].mean(),\n",
    "        \"count\":     grouped.size()\n",
    "    })\n",
    "    return out.dropna()\n",
    "\n",
    "def _logit(p, eps=1e-6):\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "def calibration_plots_and_metrics(y_true: np.ndarray, y_proba: np.ndarray, class_names: List[str], prefix: str):\n",
    "    n_classes = y_proba.shape[1]\n",
    "    rows = []\n",
    "    for c in range(n_classes):\n",
    "        y_bin = (y_true == c).astype(int)\n",
    "        p_hat = y_proba[:, c]\n",
    "        bin_df = _calibration_bin_stats(y_bin, p_hat, n_bins=10)\n",
    "        ece = np.average(np.abs(bin_df[\"obs_rate\"] - bin_df[\"pred_mean\"]), weights=bin_df[\"count\"])\n",
    "\n",
    "        X = _logit(p_hat).reshape(-1, 1)\n",
    "        try:\n",
    "            lr = LogisticRegression(C=1e6, solver=\"lbfgs\")\n",
    "            lr.fit(X, y_bin)\n",
    "            slope = float(lr.coef_.ravel()[0])\n",
    "            intercept = float(lr.intercept_.ravel()[0])\n",
    "        except Exception:\n",
    "            slope, intercept = np.nan, np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"class_id\": c, \"class_name\": class_names[c] if c < len(class_names) else str(c),\n",
    "            \"ECE\": ece, \"Calib_slope\": slope, \"Calib_intercept\": intercept\n",
    "        })\n",
    "\n",
    "        plt.figure(figsize=(5.8, 5.5))\n",
    "        plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Perfect\")\n",
    "        plt.plot(bin_df[\"pred_mean\"], bin_df[\"obs_rate\"], marker=\"o\", linewidth=1.8, label=\"Model\")\n",
    "        ax = plt.gca()\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.bar(bin_df[\"pred_mean\"], bin_df[\"count\"], width=0.07, alpha=0.25, edgecolor=\"none\")\n",
    "        ax2.set_ylabel(\"Count (per bin)\")\n",
    "        ax.set_xlabel(\"Predicted probability\")\n",
    "        ax.set_ylabel(\"Observed frequency\")\n",
    "        ax.set_title(f\"Calibration: {class_names[c] if c < len(class_names) else c}\")\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Config.RESULT_DIR / f\"{prefix}_calibration_class{c}.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(Config.RESULT_DIR / f\"{prefix}_calibration_metrics.csv\",\n",
    "                              index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "def decision_curve(y_true_bin: np.ndarray, p_hat: np.ndarray, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    N = len(y_true_bin)\n",
    "    NB, NB_all = [], []\n",
    "    for pt in thresholds:\n",
    "        pred_pos = (p_hat >= pt).astype(int)\n",
    "        TP = np.sum((pred_pos == 1) & (y_true_bin == 1))\n",
    "        FP = np.sum((pred_pos == 1) & (y_true_bin == 0))\n",
    "        nb = (TP / N) - (FP / N) * (pt / (1 - pt))\n",
    "        TP_all = np.sum(y_true_bin == 1)\n",
    "        FP_all = np.sum(y_true_bin == 0)\n",
    "        nb_all = (TP_all / N) - (FP_all / N) * (pt / (1 - pt))\n",
    "        NB.append(nb); NB_all.append(nb_all)\n",
    "    NB = np.array(NB); NB_all = np.array(NB_all)\n",
    "    NB_none = np.zeros_like(NB)\n",
    "    return thresholds, NB, NB_all, NB_none\n",
    "\n",
    "def plot_dca_multiclass(y_true: np.ndarray, y_proba: np.ndarray, class_names: List[str], prefix: str):\n",
    "    n_classes = y_proba.shape[1]\n",
    "    plt.figure(figsize=(7.8, 6.2))\n",
    "    thresholds = np.linspace(0.01, 0.80, 80)\n",
    "    for c in range(n_classes):\n",
    "        y_bin = (y_true == c).astype(int)\n",
    "        p_hat = y_proba[:, c]\n",
    "        th, NB, NB_all, NB_none = decision_curve(y_bin, p_hat, thresholds)\n",
    "        label = f\"{class_names[c] if c < len(class_names) else c}\"\n",
    "        plt.plot(th, NB, label=f\"Model ({label})\", linewidth=1.8)\n",
    "        if c == 0:\n",
    "            plt.plot(th, NB_all, color=\"gray\", linestyle=\"--\", label=\"Treat-all\")\n",
    "            plt.plot(th, NB_none, color=\"black\", linestyle=\":\", label=\"Treat-none\")\n",
    "    plt.xlabel(\"Threshold probability (pt)\")\n",
    "    plt.ylabel(\"Net Benefit\")\n",
    "    plt.title(\"Decision Curve Analysis (OVR)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Config.RESULT_DIR / f\"{prefix}_DCA_OVR.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "calibration_plots_and_metrics(\n",
    "    y_true=yh_true, y_proba=y_prob, class_names=Config.CLASS_NAMES, prefix=f\"XGBoost_MIpooled_{MODE}_holdout\"\n",
    ")\n",
    "plot_dca_multiclass(\n",
    "    y_true=yh_true, y_proba=y_prob, class_names=Config.CLASS_NAMES, prefix=f\"XGBoost_MIpooled_{MODE}_holdout\"\n",
    ")\n",
    "\n",
    "# 10-9) 付帯保存\n",
    "proba_mean.loc[index_hold].to_csv(\n",
    "    Config.RESULT_DIR / f\"predictions_holdout_proba_MIpooled_{MODE}.csv\", encoding=\"utf-8-sig\"\n",
    ")\n",
    "pd.DataFrame(per_imp_metrics).to_excel(\n",
    "    Config.RESULT_DIR / f\"per_imputation_metrics_{MODE}.xlsx\", index=False\n",
    ")\n",
    "(Config.RESULT_DIR / \"device_records.txt\").write_text(\"\\n\".join(device_records), encoding=\"utf-8\")\n",
    "\n",
    "print(\"完了。出力先:\", Config.RESULT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 論文用：結果テーブル（95% CI付き） & Figure 作成ブロック\n",
    "# 前提：主コードの実行後で、以下が存在\n",
    "#   - yh_true: hold の真のクラス (ndarray, shape [n])\n",
    "#   - y_prob : hold の予測確率 (ndarray, shape [n, n_classes])\n",
    "#   - index_hold: hold の INDEX 並び (ndarray, shape [n])\n",
    "#   - los_mean: DataFrame(index=INDEX, col=\"在院日数予測\")  ← MI平均\n",
    "#   - dt_list, hold_idx, Config: それぞれ主コードで定義済み\n",
    "# 生成物は Config.RESULT_DIR / \"paper\" 以下に保存\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, confusion_matrix, accuracy_score,\n",
    "    f1_score, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "PAPER_DIR = Config.RESULT_DIR / \"paper\"\n",
    "PAPER_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ==============\n",
    "# 汎用ブートストラップCI\n",
    "# ==============\n",
    "def bootstrap_ci_stat(stat_fn, y_true, y_pred=None, n_boot=1000, seed=42):\n",
    "    \"\"\"\n",
    "    stat_fn: callable -> float\n",
    "        例) lambda yt, yp: accuracy_score(yt, yp.argmax(1))\n",
    "        例) lambda yt, yp: f1_score(yt, yp.argmax(1), average='macro')\n",
    "        例) lambda yt, yp: rmse_score(yt, yp)  # 回帰など\n",
    "    y_pred: 分類は y_prob、回帰は連続予測\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    vals = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        yt = y_true[idx]\n",
    "        yp = y_pred[idx] if y_pred is not None else None\n",
    "        try:\n",
    "            v = float(stat_fn(yt, yp))\n",
    "        except Exception:\n",
    "            v = np.nan\n",
    "        vals.append(v)\n",
    "    vals = np.array(vals, float)\n",
    "    pt = float(np.nanmean(vals))\n",
    "    lo = float(np.nanpercentile(vals, 2.5))\n",
    "    hi = float(np.nanpercentile(vals, 97.5))\n",
    "    return pt, lo, hi\n",
    "\n",
    "def fmt_ci(pt, lo, hi, decimals=3):\n",
    "    f = lambda x: f\"{x:.{decimals}f}\" if np.isfinite(x) else \"nan\"\n",
    "    return f\"{f(pt)} [{f(lo)}, {f(hi)}]\"\n",
    "\n",
    "# =========================================\n",
    "# 1) 分類：メインメトリクス（95% CI）テーブル\n",
    "# =========================================\n",
    "# 既存の関数 get_bootstrap_ci を使って AUROC/AP/Brier のCIを取得\n",
    "ci_pack = get_bootstrap_ci(y_true=yh_true, y_prob=y_prob, n_boot=Config.N_BOOT)\n",
    "\n",
    "# 追加で Accuracy と Macro-F1 の CI をブートストラップ\n",
    "pred_cls_hold = np.argmax(y_prob, axis=1)\n",
    "acc_pt, acc_lo, acc_hi = bootstrap_ci_stat(lambda yt, yp: accuracy_score(yt, np.argmax(yp, 1)),\n",
    "                                           yh_true, y_prob, n_boot=max(500, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "f1_pt, f1_lo, f1_hi   = bootstrap_ci_stat(lambda yt, yp: f1_score(yt, np.argmax(yp, 1), average='macro'),\n",
    "                                          yh_true, y_prob, n_boot=max(500, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "\n",
    "cls_rows = []\n",
    "# AUROC/AP/Brier（既存関数の出力を整形）\n",
    "for key, (pt, lo, hi) in ci_pack.items():\n",
    "    cls_rows.append({\n",
    "        \"Metric\": key,\n",
    "        \"Point\": pt, \"CI_low\": lo, \"CI_high\": hi,\n",
    "        \"Display\": fmt_ci(pt, lo, hi, decimals=3)\n",
    "    })\n",
    "\n",
    "# Accuracy / Macro-F1 を追加\n",
    "cls_rows += [\n",
    "    {\"Metric\": \"Accuracy\", \"Point\": acc_pt, \"CI_low\": acc_lo, \"CI_high\": acc_hi, \"Display\": fmt_ci(acc_pt, acc_lo, acc_hi)},\n",
    "    {\"Metric\": \"F1_macro\", \"Point\": f1_pt,  \"CI_low\": f1_lo,  \"CI_high\": f1_hi,  \"Display\": fmt_ci(f1_pt,  f1_lo,  f1_hi)},\n",
    "]\n",
    "df_cls_table = pd.DataFrame(cls_rows)\n",
    "df_cls_table.to_csv(PAPER_DIR / \"Table_classification_metrics_CI.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "# Excel（見出し整形用）\n",
    "with pd.ExcelWriter(PAPER_DIR / \"Table_classification_metrics_CI.xlsx\", engine=\"xlsxwriter\") as w:\n",
    "    df_cls_table.to_excel(w, index=False, sheet_name=\"classification\")\n",
    "print(\"Saved:\", (PAPER_DIR / \"Table_classification_metrics_CI.*\").as_posix())\n",
    "\n",
    "# =========================================\n",
    "# 2) 回帰：メインメトリクス（95% CI）テーブル\n",
    "# =========================================\n",
    "# 真値・予測（INDEX順整列）\n",
    "ylos_true_hold = dt_list[0].loc[hold_idx, Config.LOS_COL].astype(float).to_numpy()\n",
    "yhat_los_hold  = los_mean.loc[index_hold, \"在院日数予測\"].to_numpy()\n",
    "\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "def _mape(y_true, y_pred, eps=1e-6):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return float(np.mean(np.abs((y_pred - y_true) / denom)))\n",
    "\n",
    "# ポイント推定\n",
    "rmse_pt = rmse_score(ylos_true_hold, yhat_los_hold)\n",
    "mae_pt  = float(np.mean(np.abs(ylos_true_hold - yhat_los_hold)))\n",
    "medae_pt = median_absolute_error(ylos_true_hold, yhat_los_hold)\n",
    "mape_pt = _mape(ylos_true_hold, yhat_los_hold)\n",
    "r2_pt   = r2_score(ylos_true_hold, yhat_los_hold)\n",
    "\n",
    "# CI（ブートストラップ）\n",
    "rmse_ci = bootstrap_ci_stat(lambda yt, yp: rmse_score(yt, yp), ylos_true_hold, yhat_los_hold,\n",
    "                            n_boot=max(1000, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "mae_ci  = bootstrap_ci_stat(lambda yt, yp: np.mean(np.abs(yt - yp)), ylos_true_hold, yhat_los_hold,\n",
    "                            n_boot=max(1000, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "medae_ci= bootstrap_ci_stat(lambda yt, yp: median_absolute_error(yt, yp), ylos_true_hold, yhat_los_hold,\n",
    "                            n_boot=max(1000, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "mape_ci = bootstrap_ci_stat(lambda yt, yp: _mape(yt, yp), ylos_true_hold, yhat_los_hold,\n",
    "                            n_boot=max(1000, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "r2_ci   = bootstrap_ci_stat(lambda yt, yp: r2_score(yt, yp), ylos_true_hold, yhat_los_hold,\n",
    "                            n_boot=max(1000, Config.N_BOOT), seed=Config.RANDOM_STATE)\n",
    "\n",
    "reg_rows = [\n",
    "    {\"Metric\": \"RMSE\",  \"Point\": rmse_pt,  \"CI_low\": rmse_ci[1],  \"CI_high\": rmse_ci[2],  \"Display\": fmt_ci(*rmse_ci, decimals=2)},\n",
    "    {\"Metric\": \"MAE\",   \"Point\": mae_pt,   \"CI_low\": mae_ci[1],   \"CI_high\": mae_ci[2],   \"Display\": fmt_ci(*mae_ci,  decimals=2)},\n",
    "    {\"Metric\": \"MedAE\", \"Point\": medae_pt, \"CI_low\": medae_ci[1], \"CI_high\": medae_ci[2], \"Display\": fmt_ci(*medae_ci,decimals=2)},\n",
    "    {\"Metric\": \"MAPE\",  \"Point\": mape_pt,  \"CI_low\": mape_ci[1],  \"CI_high\": mape_ci[2],  \"Display\": fmt_ci(*mape_ci, decimals=3)},\n",
    "    {\"Metric\": \"R2\",    \"Point\": r2_pt,    \"CI_low\": r2_ci[1],    \"CI_high\": r2_ci[2],    \"Display\": fmt_ci(*r2_ci,   decimals=3)},\n",
    "]\n",
    "df_reg_table = pd.DataFrame(reg_rows)\n",
    "df_reg_table.to_csv(PAPER_DIR / \"Table_regression_metrics_CI.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "with pd.ExcelWriter(PAPER_DIR / \"Table_regression_metrics_CI.xlsx\", engine=\"xlsxwriter\") as w:\n",
    "    df_reg_table.to_excel(w, index=False, sheet_name=\"regression\")\n",
    "print(\"Saved:\", (PAPER_DIR / \"Table_regression_metrics_CI.*\").as_posix())\n",
    "\n",
    "# =========================================\n",
    "# 3) 図：Multiclass ROC (OVR) with AUC (95% CI)\n",
    "# =========================================\n",
    "# クラスごとのROC、マクロ/マイクロ平均の曲線も併記\n",
    "n_classes = y_prob.shape[1]\n",
    "classes = list(range(n_classes))\n",
    "class_names = Config.CLASS_NAMES if len(Config.CLASS_NAMES) == n_classes else [str(i) for i in classes]\n",
    "\n",
    "# OVRのために one-hot\n",
    "Y_true_oh = label_binarize(yh_true, classes=classes)\n",
    "\n",
    "fpr = dict(); tpr = dict(); roc_auc = dict()\n",
    "for i in classes:\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_true_oh[:, i], y_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# マイクロ平均\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_true_oh.ravel(), y_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# マクロ平均（単純平均）\n",
    "roc_auc[\"macro\"] = float(np.mean([roc_auc[i] for i in classes]))\n",
    "\n",
    "# 図\n",
    "plt.figure(figsize=(7.5, 6.2))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='k', lw=2, label=f\"micro-average ROC (AUC={roc_auc['micro']:.3f})\")\n",
    "for i in classes:\n",
    "    plt.plot(fpr[i], tpr[i], lw=1.8, label=f\"{class_names[i]} (AUC={roc_auc[i]:.3f})\")\n",
    "plt.plot([0,1],[0,1], 'k--', lw=1)\n",
    "plt.xlim([0,1]); plt.ylim([0,1.02])\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"OVR ROC on hold-out\")\n",
    "plt.legend(loc=\"lower right\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PAPER_DIR / \"Fig_ROC_OVR_hold.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 参考：Weighted/Macro のAUCに 95%CI を注釈用テキストで保存\n",
    "auroc_w = ci_pack[\"AUROC_weighted\"]; auroc_m = ci_pack[\"AUROC_macro\"]\n",
    "(Path(PAPER_DIR) / \"Fig_ROC_OVR_hold_caption.txt\").write_text(\n",
    "    f\"Weighted AUROC = {fmt_ci(*auroc_w, decimals=3)}; \"\n",
    "    f\"Macro AUROC = {fmt_ci(*auroc_m, decimals=3)}\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 4) 図：Multiclass Precision-Recall (OVR)\n",
    "# =========================================\n",
    "plt.figure(figsize=(7.5, 6.2))\n",
    "for i in classes:\n",
    "    precision, recall, _ = precision_recall_curve(Y_true_oh[:, i], y_prob[:, i])\n",
    "    ap = average_precision_score(Y_true_oh[:, i], y_prob[:, i])\n",
    "    plt.plot(recall, precision, lw=1.8, label=f\"{class_names[i]} (AP={ap:.3f})\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"OVR Precision-Recall on hold-out\")\n",
    "plt.legend(loc=\"best\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PAPER_DIR / \"Fig_PR_OVR_hold.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# =========================================\n",
    "# 5) 図：Confusion Matrix（数値＋割合の2種）\n",
    "# =========================================\n",
    "cm = confusion_matrix(yh_true, pred_cls_hold, labels=classes)\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "cm_df.to_csv(PAPER_DIR / \"ConfusionMatrix_counts.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 割合（行正規化：感度イメージ）\n",
    "cm_rowpct = cm / cm.sum(axis=1, keepdims=True)\n",
    "cm_rowpct_df = pd.DataFrame(cm_rowpct, index=class_names, columns=class_names)\n",
    "cm_rowpct_df.to_csv(PAPER_DIR / \"ConfusionMatrix_rowpct.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 作図（counts）\n",
    "plt.figure(figsize=(6.2, 5.5))\n",
    "im = plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(n_classes), class_names, rotation=45, ha='right')\n",
    "plt.yticks(range(n_classes), class_names)\n",
    "for i in range(n_classes):\n",
    "    for j in range(n_classes):\n",
    "        plt.text(j, i, f\"{cm[i,j]:d}\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix (counts)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PAPER_DIR / \"Fig_CM_counts.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 作図（row%）\n",
    "plt.figure(figsize=(6.2, 5.5))\n",
    "im = plt.imshow(cm_rowpct, cmap=\"Greens\", vmin=0, vmax=1)\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(n_classes), class_names, rotation=45, ha='right')\n",
    "plt.yticks(range(n_classes), class_names)\n",
    "for i in range(n_classes):\n",
    "    for j in range(n_classes):\n",
    "        plt.text(j, i, f\"{cm_rowpct[i,j]*100:.1f}%\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix (row %)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PAPER_DIR / \"Fig_CM_rowpct.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# =========================================\n",
    "# 6) 回帰図：Bland–Altman + メトリクスCI注釈\n",
    "# =========================================\n",
    "resid = yhat_los_hold - ylos_true_hold\n",
    "mean_pair = (yhat_los_hold + ylos_true_hold) / 2.0\n",
    "ba_mean = float(np.mean(resid))\n",
    "ba_sd   = float(np.std(resid, ddof=1))\n",
    "loa_low = ba_mean - 1.96*ba_sd\n",
    "loa_hi  = ba_mean + 1.96*ba_sd\n",
    "\n",
    "# CI文字列\n",
    "rmse_txt = fmt_ci(*rmse_ci, decimals=2)\n",
    "mae_txt  = fmt_ci(*mae_ci,  decimals=2)\n",
    "r2_txt   = fmt_ci(*r2_ci,   decimals=3)\n",
    "\n",
    "plt.figure(figsize=(7.0, 5.3))\n",
    "plt.scatter(mean_pair, resid, s=12, alpha=0.6)\n",
    "plt.axhline(ba_mean, color=\"C1\", linestyle=\"-\", label=f\"Mean diff={ba_mean:.2f}\")\n",
    "plt.axhline(loa_low, color=\"C3\", linestyle=\"--\", label=f\"LoA-={loa_low:.2f}\")\n",
    "plt.axhline(loa_hi,  color=\"C3\", linestyle=\"--\", label=f\"LoA+={loa_hi:.2f}\")\n",
    "plt.xlabel(\"Mean of True and Pred LOS\"); plt.ylabel(\"Difference (Pred - True)\")\n",
    "plt.title(\"Bland–Altman (hold)\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "# 注釈枠（RMSE/MAE/R² の CI）\n",
    "txt = f\"RMSE = {rmse_txt}\\nMAE = {mae_txt}\\nR² = {r2_txt}\\nN = {len(ylos_true_hold)}\"\n",
    "plt.gca().text(0.02, 0.02, txt, transform=plt.gca().transAxes,\n",
    "               fontsize=10, va=\"bottom\", ha=\"left\",\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8, edgecolor=\"gray\"))\n",
    "plt.tight_layout()\n",
    "plt.savefig(PAPER_DIR / \"Fig_LOS_BlandAltman_hold.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# =========================================\n",
    "# 7) 論文添付用まとめ Excel（1ファイルにシート集約）\n",
    "# =========================================\n",
    "with pd.ExcelWriter(PAPER_DIR / \"Paper_Tables_FigRefs.xlsx\", engine=\"xlsxwriter\") as w:\n",
    "    df_cls_table.to_excel(w, index=False, sheet_name=\"Classification_CI\")\n",
    "    df_reg_table.to_excel(w, index=False, sheet_name=\"Regression_CI\")\n",
    "    # 混同行列（数/行%）\n",
    "    cm_df.to_excel(w, sheet_name=\"CM_counts\")\n",
    "    cm_rowpct_df.to_excel(w, sheet_name=\"CM_rowpct\")\n",
    "    # 図のファイルパス一覧\n",
    "    fig_paths = pd.DataFrame({\n",
    "        \"Figure\": [\"Fig_ROC_OVR_hold.png\", \"Fig_PR_OVR_hold.png\", \"Fig_CM_counts.png\",\n",
    "                   \"Fig_CM_rowpct.png\", \"Fig_LOS_BlandAltman_hold.png\"],\n",
    "        \"Path\": [str((PAPER_DIR / f).resolve()) for f in\n",
    "                 [\"Fig_ROC_OVR_hold.png\", \"Fig_PR_OVR_hold.png\", \"Fig_CM_counts.png\",\n",
    "                  \"Fig_CM_rowpct.png\", \"Fig_LOS_BlandAltman_hold.png\"]]\n",
    "    })\n",
    "    fig_paths.to_excel(w, index=False, sheet_name=\"Figure_files\")\n",
    "\n",
    "print(\"Paper-ready tables & figures saved to:\", PAPER_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20986325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 10:32:36,102 [INFO] Temporal split: dev=2205, hold=795 (flag=1 as hold)\n",
      " 99%|===================| 2354/2385 [00:32<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP 図・CSVを保存しました: C:\\Users\\tears\\Desktop\\Study\\2025\\12_CI\\004_ML2\\results_20250815_1659\\shap\n",
      "（学習デバイス）ES: GPU, full: GPU\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SHAP 解析（このブロックは学習コードの「後」に貼って実行）\n",
    "# - MI#1 の dev で XGBoost を再学習（ES→best_iter→全データリフィット）\n",
    "# - hold を対象に SHAP を計算\n",
    "# - 返り配列の軸順を自動判別し (samples, classes, features) へ正規化\n",
    "# - 成果物は Config.RESULT_DIR / \"shap\" 以下へ保存\n",
    "# =========================\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone as _clone\n",
    "\n",
    "# SHAPログ抑制（新バージョン対応）\n",
    "logging.getLogger(\"shap\").setLevel(logging.WARNING)\n",
    "\n",
    "SHAP_DIR = Config.RESULT_DIR / \"shap\"\n",
    "SHAP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# === 1) データ準備（MI#1 の dev/hold） ===\n",
    "dt = dt_list[0]\n",
    "Xd, yd, Xh, yh = prepare_from_dt_timeaware(dt)\n",
    "\n",
    "# === 2) 前処理 & 再学習（GPU→CPU フォールバック + ES→全学習リフィット） ===\n",
    "pre = WinsorizeLog1pTransformer().fit(Xd, yd)\n",
    "Xd_t = pre.transform(Xd)\n",
    "Xh_t = pre.transform(Xh)\n",
    "\n",
    "# 分類器をベストパラメータで構築\n",
    "base_model, _ = build_estimator(\"XGBoost\")\n",
    "if 'best_cls_params' in globals() and best_cls_params is not None:\n",
    "    base_model.set_params(**best_cls_params)\n",
    "\n",
    "# 早期終了のための小検証セット\n",
    "Xtr_tr, Xtr_ev, ytr_tr, ytr_ev = train_test_split(\n",
    "    Xd_t, yd, test_size=0.10, random_state=Config.RANDOM_STATE\n",
    ")\n",
    "sw = make_sample_weight(ytr_tr)\n",
    "fit_kwargs = _build_xgb_fit_kwargs_for_es(base_model, Xtr_ev, ytr_ev, sw, es_rounds=ES_ROUNDS)\n",
    "\n",
    "# GPU→CPU フォールバックで ES 学習\n",
    "cls_es, used_fallback_es = fit_with_gpu_fallback_xgb(\n",
    "    base_model, Xtr_tr, ytr_tr, sample_weight=sw, fit_kwargs=fit_kwargs\n",
    ")\n",
    "\n",
    "# best_iter 決定\n",
    "best_iter = int(\n",
    "    getattr(cls_es, \"best_iteration\", None)\n",
    "    or getattr(cls_es, \"best_ntree_limit\", cls_es.get_params().get(\"n_estimators\", _XGB_N_EST_CLS))\n",
    ")\n",
    "\n",
    "# 全 dev でリフィット\n",
    "cls_full = _clone(base_model).set_params(n_estimators=best_iter)\n",
    "sw_full = make_sample_weight(yd)\n",
    "cls_full, used_fallback_full = fit_with_gpu_fallback_xgb(cls_full, Xd_t, yd, sample_weight=sw_full)\n",
    "\n",
    "# === 3) SHAP 値の計算（メモリ節約のためサンプル） ===\n",
    "feat_names = Xd.columns.tolist()\n",
    "n_features_expected = X_eval_feat_count = Xd_t.shape[1]  # 変換後の特徴次元\n",
    "\n",
    "# 背景を dev からサンプリング\n",
    "SAMPLE_BG = min(800, Xd_t.shape[0])\n",
    "rng = np.random.default_rng(Config.RANDOM_STATE)\n",
    "bg_idx = rng.choice(Xd_t.shape[0], SAMPLE_BG, replace=False)\n",
    "bg = Xd_t[bg_idx]\n",
    "\n",
    "# 評価対象（hold）もサンプリング可能\n",
    "MAX_EVAL = 2000  # hold が大きい時の上限\n",
    "if Xh_t.shape[0] <= MAX_EVAL:\n",
    "    eval_idx = np.arange(Xh_t.shape[0])\n",
    "else:\n",
    "    eval_idx = rng.choice(Xh_t.shape[0], MAX_EVAL, replace=False)\n",
    "X_eval = Xh_t[eval_idx]\n",
    "y_eval = yh[eval_idx]\n",
    "\n",
    "# TreeExplainer 優先（失敗時は汎用 Explainer）\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(cls_full, data=bg, feature_perturbation=\"interventional\")\n",
    "except Exception:\n",
    "    explainer = shap.Explainer(cls_full, bg)\n",
    "\n",
    "sv_raw = explainer(X_eval)\n",
    "\n",
    "# === 3.1) SHAP 配列を (samples, classes, features) に正規化 ===\n",
    "def _to_scf(sv_obj, X_eval):\n",
    "    \"\"\"sv_obj を (samples, classes, features) に正規化して返す\"\"\"\n",
    "    # パターンA: 古いAPIで list[Explanation]（クラス数のリスト）\n",
    "    if isinstance(sv_obj, list):\n",
    "        arr = np.stack([s.values for s in sv_obj], axis=1)  # (samples, classes, features)\n",
    "        return arr\n",
    "\n",
    "    # パターンB: Explanation。values の形状がバージョンで揺れる\n",
    "    vals = getattr(sv_obj, \"values\", sv_obj)\n",
    "    arr = np.array(vals)\n",
    "\n",
    "    # バイナリなど (samples, features) → (samples, 1, features)\n",
    "    if arr.ndim == 2 and arr.shape[1] == X_eval.shape[1]:\n",
    "        return arr[:, None, :]\n",
    "\n",
    "    # 3次元だが軸順不明：候補の転置で末尾=features、先頭=samples になるものを探す\n",
    "    if arr.ndim == 3:\n",
    "        s = X_eval.shape[0]\n",
    "        f = X_eval.shape[1]\n",
    "        candidates = [\n",
    "            arr,                          # ( ?, ?, ? )\n",
    "            np.transpose(arr, (1, 0, 2)),\n",
    "            np.transpose(arr, (0, 2, 1)),\n",
    "            np.transpose(arr, (2, 0, 1)),\n",
    "            np.transpose(arr, (1, 2, 0)),\n",
    "            np.transpose(arr, (2, 1, 0)),\n",
    "        ]\n",
    "        for cand in candidates:\n",
    "            if cand.shape[0] == s and cand.shape[2] == f:\n",
    "                return cand  # (samples, classes, features) のはず\n",
    "        # どうしても決まらない場合は、最後の軸を features に合わせて、残りを sample×class とみなす\n",
    "        if arr.shape[-1] == f:\n",
    "            sc = arr.reshape(-1, f)  # (samples*classes, features)\n",
    "            # クラス数推定（割り切れない場合は 1 とする）\n",
    "            c_est = max(1, sc.shape[0] // s)\n",
    "            return sc.reshape(s, c_est, f)\n",
    "\n",
    "    # 最後の fallback：features 軸だけ合わせて (samples, 1, features) にする\n",
    "    if arr.ndim >= 1 and arr.shape[-1] == X_eval.shape[1]:\n",
    "        flat = arr.reshape(-1, X_eval.shape[1])\n",
    "        return flat[: X_eval.shape[0], :][:, None, :]\n",
    "\n",
    "    raise ValueError(f\"Unexpected SHAP value shape: {arr.shape}\")\n",
    "\n",
    "sv = _to_scf(sv_raw, X_eval)  # (samples, classes, features)\n",
    "n_samples, n_classes, n_features = sv.shape\n",
    "\n",
    "# === 4) 重要度の集計・保存 ===\n",
    "mean_abs_by_class = np.abs(sv).mean(axis=0)            # (n_classes, n_features)\n",
    "mean_abs_global = mean_abs_by_class.mean(axis=0)       # (n_features,)\n",
    "global_importance = pd.Series(mean_abs_global, index=feat_names).sort_values(ascending=False)\n",
    "global_importance.to_csv(SHAP_DIR / \"shap_global_importance.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# グローバル上位30のバー図\n",
    "plt.figure(figsize=(8, 10))\n",
    "global_importance.iloc[:30][::-1].plot(kind=\"barh\")\n",
    "plt.title(\"Mean |SHAP| (global, class-avg)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(SHAP_DIR / \"shap_bar_global_top30.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# === 5) クラス別ビースウォーム（上位特徴のみ、クラス別 expected_value に配慮） ===\n",
    "TOPK = 20\n",
    "expected = getattr(explainer, \"expected_value\", 0.0)\n",
    "\n",
    "def _class_base_value(c):\n",
    "    \"\"\"expected_value の形状の違いに安全に対応してクラス別ベース値を返す\"\"\"\n",
    "    if np.ndim(expected) == 0:\n",
    "        return float(expected)\n",
    "    arr = np.array(expected)\n",
    "    if arr.ndim == 1 and arr.shape[0] == n_classes:\n",
    "        return float(arr[c])\n",
    "    return float(arr.mean())\n",
    "\n",
    "for c in range(n_classes):\n",
    "    cls_name = Config.CLASS_NAMES[c] if c < len(Config.CLASS_NAMES) else f\"class{c}\"\n",
    "    # 上位特徴のインデックス（このクラスでの |SHAP| 平均が大きい順）\n",
    "    top_idx = np.argsort(mean_abs_by_class[c])[::-1][:TOPK]\n",
    "    sv_c_top = sv[:, c, :][:, top_idx]            # (n_samples, TOPK)\n",
    "    features_top = np.array(feat_names)[top_idx]  # (TOPK,)\n",
    "    base_val_c = _class_base_value(c)\n",
    "\n",
    "    # shap の新APIに合わせて Explanation を作る\n",
    "    exp = shap.Explanation(\n",
    "        values=sv_c_top,\n",
    "        base_values=base_val_c,\n",
    "        data=X_eval[:, top_idx],\n",
    "        feature_names=features_top\n",
    "    )\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.plots.beeswarm(exp, show=False, max_display=TOPK)\n",
    "    plt.title(f\"SHAP Beeswarm - {cls_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(SHAP_DIR / f\"shap_beeswarm_{cls_name}.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# === 6) 依存プロット（各クラスの上位3特徴 × 1対1、簡易散布） ===\n",
    "for c in range(n_classes):\n",
    "    cls_name = Config.CLASS_NAMES[c] if c < len(Config.CLASS_NAMES) else f\"class{c}\"\n",
    "    top_idx3 = np.argsort(mean_abs_by_class[c])[::-1][:3]\n",
    "    for j in top_idx3:\n",
    "        feat = feat_names[j]\n",
    "        plt.figure(figsize=(5.5, 4.5))\n",
    "        plt.scatter(X_eval[:, j], sv[:, c, j], s=10, alpha=0.6)\n",
    "        plt.xlabel(f\"{feat}\")\n",
    "        plt.ylabel(\"SHAP value\")\n",
    "        plt.title(f\"Dependence: {feat} → {cls_name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(SHAP_DIR / f\"shap_dependence_{cls_name}_{feat}.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "print(f\"SHAP 図・CSVを保存しました: {SHAP_DIR.resolve()}\")\n",
    "print(f\"（学習デバイス）ES: {'CPU' if used_fallback_es else 'GPU'}, full: {'CPU' if used_fallback_full else 'GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a full script file `paper_pipeline_full.py` with the requested functionality.\n",
    "from pathlib import Path\n",
    "\n",
    "code = r'''# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "paper_pipeline_full.py\n",
    "----------------------\n",
    "End-to-end pipeline to (1) improve model accuracy during development and\n",
    "(2) export AMA-ready tables and publication-quality figures for both\n",
    "multiclass discharge destination classification and LOS regression.\n",
    "\n",
    "Requirements (Python 3.9+):\n",
    "    numpy, pandas, scikit-learn, xgboost, matplotlib\n",
    "\n",
    "This script is organized to let you plug in your data quickly:\n",
    "    - Fill `load_data()` to return feature matrices and targets.\n",
    "    - Optionally adjust `Config` below.\n",
    "\n",
    "Outputs:\n",
    "    ./results/paper_full/  に図表が保存されます。\n",
    "\n",
    "Author: (you)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, accuracy_score, f1_score, r2_score,\n",
    "    median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# XGBoost (assumed available in your env)\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42  # avoid Type 3 fonts in PDF\n",
    "plt.rcParams[\"ps.fonttype\"]  = 42\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    RESULT_DIR: Path = Path(\"./results\")\n",
    "    RANDOM_STATE: int = 42\n",
    "    N_BOOT: int = 1000\n",
    "    CLASS_NAMES: List[str] = None  # e.g., [\"自宅\", \"転院\", \"死亡\"]\n",
    "    ID_COL: Optional[str] = None   # (optional) patient id\n",
    "    TARGET_CLS: str = \"discharge_cls\"  # classification target column\n",
    "    TARGET_REG: str = \"los_days\"       # LOS column (float)\n",
    "    LONG_LOS_THRESHOLD: int = 28       # threshold for long-stay gating\n",
    "    HOLDOUT_FRACTION: float = 0.2      # holdout ratio if you use load_data()\n",
    "    DEV_FRACTION: float = 0.2          # dev from train+dev (for calibration & threshold tuning)\n",
    "\n",
    "    # Classifier base params (sensible defaults for tabular)\n",
    "    xgb_cls_params: Dict = None\n",
    "    # Regressor base params\n",
    "    xgb_reg_params: Dict = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.xgb_cls_params is None:\n",
    "            self.xgb_cls_params = dict(\n",
    "                n_estimators=1500, max_depth=4, learning_rate=0.03,\n",
    "                subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "                min_child_weight=1.0, objective=\"multi:softprob\", tree_method=\"hist\",\n",
    "                eval_metric=\"mlogloss\", random_state=self.RANDOM_STATE\n",
    "            )\n",
    "        if self.xgb_reg_params is None:\n",
    "            self.xgb_reg_params = dict(\n",
    "                n_estimators=1200, max_depth=4, learning_rate=0.03,\n",
    "                subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "                min_child_weight=1.0, objective=\"reg:squarederror\", tree_method=\"hist\",\n",
    "                random_state=self.RANDOM_STATE\n",
    "            )\n",
    "\n",
    "\n",
    "CFG = Config(\n",
    "    RESULT_DIR=Path(\"./results\"),\n",
    "    CLASS_NAMES=[\"自宅\", \"転院\", \"死亡\"]\n",
    ")\n",
    "OUT_DIR = (CFG.RESULT_DIR / \"paper_full\").resolve()\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Utility helpers\n",
    "# ---------------------------\n",
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def save_json(data: dict, path: Path):\n",
    "    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def fmt_ci(pt, lo, hi, dec=3):\n",
    "    f = lambda x: f\"{x:.{dec}f}\"\n",
    "    return f\"{f(pt)} [{f(lo)}–{f(hi)}]\"\n",
    "\n",
    "\n",
    "def stratified_boot_idx(y: np.ndarray, n_boot=1000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y)\n",
    "    classes = np.unique(y)\n",
    "    idx_by_c = {c: np.flatnonzero(y == c) for c in classes}\n",
    "    n_by_c = {c: len(idx_by_c[c]) for c in classes}\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.concatenate([rng.choice(idx_by_c[c], n_by_c[c], replace=True) for c in classes])\n",
    "        yield idx\n",
    "\n",
    "\n",
    "def brier_multiclass(y_true: np.ndarray, proba: np.ndarray) -> float:\n",
    "    \"\"\"1-of-K multiclass Brier score.\"\"\"\n",
    "    y = np.eye(proba.shape[1])[y_true]\n",
    "    return float(np.mean(np.sum((y - proba) ** 2, axis=1)))\n",
    "\n",
    "\n",
    "def ece_binary(y_true_bin: np.ndarray, p_hat: np.ndarray, n_bins: int = 10) -> float:\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        m = (p_hat >= bins[i]) & (p_hat < bins[i + 1])\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        acc = np.mean(y_true_bin[m])\n",
    "        conf = np.mean(p_hat[m])\n",
    "        ece += (m.mean()) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def auroc_macro(y_true: np.ndarray, proba: np.ndarray) -> float:\n",
    "    oh = np.eye(proba.shape[1])[y_true]\n",
    "    aucs = []\n",
    "    for k in range(proba.shape[1]):\n",
    "        f, t, _ = roc_curve(oh[:, k], proba[:, k])\n",
    "        aucs.append(auc(f, t))\n",
    "    return float(np.mean(aucs))\n",
    "\n",
    "\n",
    "def auroc_weighted(y_true: np.ndarray, proba: np.ndarray) -> float:\n",
    "    oh = np.eye(proba.shape[1])[y_true]\n",
    "    aucs, ws = [], []\n",
    "    for k in range(proba.shape[1]):\n",
    "        f, t, _ = roc_curve(oh[:, k], proba[:, k])\n",
    "        aucs.append(auc(f, t))\n",
    "        ws.append(np.mean(y_true == k))\n",
    "    return float(np.average(aucs, weights=ws))\n",
    "\n",
    "\n",
    "def ap_macro(y_true: np.ndarray, proba: np.ndarray) -> float:\n",
    "    oh = np.eye(proba.shape[1])[y_true]\n",
    "    aps = []\n",
    "    for k in range(proba.shape[1]):\n",
    "        aps.append(average_precision_score(oh[:, k], proba[:, k]))\n",
    "    return float(np.mean(aps))\n",
    "\n",
    "\n",
    "def boot_ci_metric(fn, y_true: np.ndarray, proba: np.ndarray, n_boot=1000, seed=42) -> Tuple[float, float, float]:\n",
    "    vals = []\n",
    "    for idx in stratified_boot_idx(y_true, n_boot=n_boot, seed=seed):\n",
    "        vals.append(float(fn(y_true[idx], proba[idx])))\n",
    "    a = np.asarray(vals, float)\n",
    "    return float(np.mean(a)), float(np.percentile(a, 2.5)), float(np.percentile(a, 97.5))\n",
    "\n",
    "\n",
    "def boot_ci_reg(fn, yt: np.ndarray, yp: np.ndarray, n_boot=1000, seed=42) -> Tuple[float, float, float]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(yt)\n",
    "    arr = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        arr.append(float(fn(yt[idx], yp[idx])))\n",
    "    a = np.asarray(arr, float)\n",
    "    return float(np.mean(a)), float(np.percentile(a, 2.5)), float(np.percentile(a, 97.5))\n",
    "\n",
    "\n",
    "def rmse(yt, yp): return float(np.sqrt(np.mean((yp - yt) ** 2)))\n",
    "def mae(yt, yp): return float(np.mean(np.abs(yp - yt)))\n",
    "def mape(yt, yp, eps=1e-6): \n",
    "    denom = np.maximum(np.abs(yt), eps)\n",
    "    return float(np.mean(np.abs((yp - yt) / denom)))\n",
    "\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Data loading placeholder\n",
    "# ---------------------------\n",
    "def load_data() -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series, pd.DataFrame, pd.Series, List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Replace this stub with your own loader.\n",
    "    Must return:\n",
    "        X_train, y_train (classification),\n",
    "        X_hold,  y_hold  (classification),\n",
    "        X_reg_hold (features for LOS on hold), y_reg_hold (true LOS),\n",
    "        numeric_cols, categorical_cols\n",
    "    For demo purposes, we raise an error so you fill this function.\n",
    "    \"\"\"\n",
    "    raise RuntimeError(\"Please implement load_data() to return your dataset splits and columns.\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Modeling – Classification\n",
    "# ---------------------------\n",
    "def build_preprocessor(numeric_cols: List[str], categorical_cols: List[str]) -> ColumnTransformer:\n",
    "    num_pipe = Pipeline([(\"scaler\", StandardScaler(with_mean=False))])\n",
    "    cat_pipe = Pipeline([(\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))])\n",
    "    pre = ColumnTransformer([(\"num\", num_pipe, numeric_cols), (\"cat\", cat_pipe, categorical_cols)])\n",
    "    return pre\n",
    "\n",
    "\n",
    "def random_search_xgb_cls(X_dev: np.ndarray, y_dev: np.ndarray, n_trials: int = 20, seed: int = 42) -> Dict:\n",
    "    \"\"\"\n",
    "    Lightweight random search around decent defaults.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    space = {\n",
    "        \"max_depth\": [3, 4, 5, 6],\n",
    "        \"learning_rate\": [0.02, 0.03, 0.05, 0.08],\n",
    "        \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"min_child_weight\": [1.0, 2.0, 3.0, 5.0],\n",
    "        \"reg_lambda\": [0.5, 1.0, 2.0],\n",
    "        \"n_estimators\": [800, 1200, 1500, 2000],\n",
    "    }\n",
    "    def sample():\n",
    "        return {k: rng.choice(v) for k, v in space.items()}\n",
    "    best = None\n",
    "    best_auc = -1.0\n",
    "    K = len(np.unique(y_dev))\n",
    "    for _ in range(n_trials):\n",
    "        params = sample()\n",
    "        model = XGBClassifier(objective=\"multi:softprob\", num_class=K, tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "                              random_state=seed, **params)\n",
    "        model.fit(X_dev, y_dev)\n",
    "        proba = model.predict_proba(X_dev)\n",
    "        score = auroc_macro(y_dev, proba)\n",
    "        if score > best_auc:\n",
    "            best_auc = score\n",
    "            best = params\n",
    "    return best\n",
    "\n",
    "\n",
    "class OVRCalibratedClassifier:\n",
    "    \"\"\"\n",
    "    One-vs-Rest XGBoost classifier with isotonic calibration and per-class thresholding.\n",
    "    \"\"\"\n",
    "    def __init__(self, class_names: List[str], thresholds: Optional[np.ndarray] = None):\n",
    "        self.class_names = class_names\n",
    "        self.thresholds = thresholds  # shape [K]\n",
    "        self.model: Optional[CalibratedClassifierCV] = None\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray, X_dev: np.ndarray, y_dev: np.ndarray, params: Dict, seed: int = 42):\n",
    "        K = len(self.class_names)\n",
    "        # class weights\n",
    "        classes = np.arange(K)\n",
    "        cw = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "        sample_weight = cw[y_train]\n",
    "\n",
    "        base = XGBClassifier(objective=\"multi:softprob\", num_class=K, tree_method=\"hist\",\n",
    "                             eval_metric=\"mlogloss\", random_state=seed, **params)\n",
    "        base.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        # calibrate on dev\n",
    "        self.model = CalibratedClassifierCV(base_estimator=base, method=\"isotonic\", cv=\"prefit\")\n",
    "        self.model.fit(X_dev, y_dev)\n",
    "        # thresholds by maximizing F1 on dev\n",
    "        proba_dev = self.model.predict_proba(X_dev)\n",
    "        self.thresholds = np.zeros(K)\n",
    "        oh = np.eye(K)[y_dev]\n",
    "        for k in range(K):\n",
    "            p, r, thr = precision_recall_curve(oh[:, k], proba_dev[:, k])\n",
    "            f1 = 2 * p * r / (p + r + 1e-12)\n",
    "            j = int(np.nanargmax(f1))\n",
    "            self.thresholds[k] = 0.5 if j >= len(thr) else float(thr[j])\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= self.thresholds).astype(int).argmax(1)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Modeling – Regression (LOS)\n",
    "# ---------------------------\n",
    "class TwoStageLOSRegressor:\n",
    "    \"\"\"\n",
    "    Classifier gate for long-stay + quantile regressors (median) in each stratum.\n",
    "    log1p-transform with smearing on inverse transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, long_threshold: int = 28, seed: int = 42):\n",
    "        self.th = long_threshold\n",
    "        self.seed = seed\n",
    "        self.clf_long: Optional[CalibratedClassifierCV] = None\n",
    "        self.reg_short: Optional[GradientBoostingRegressor] = None\n",
    "        self.reg_long: Optional[GradientBoostingRegressor] = None\n",
    "        self.smear_short: float = 1.0\n",
    "        self.smear_long: float = 1.0\n",
    "        self.th_prob: float = 0.5  # probability threshold to choose long\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray, X_dev: np.ndarray, y_dev: np.ndarray):\n",
    "        # binary labels\n",
    "        yb_train = (y_train >= self.th).astype(int)\n",
    "        yb_dev   = (y_dev   >= self.th).astype(int)\n",
    "\n",
    "        # long-stay classifier (XGB + isotonic)\n",
    "        clf = XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "                            tree_method=\"hist\", random_state=self.seed,\n",
    "                            n_estimators=800, max_depth=4, learning_rate=0.05,\n",
    "                            subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0)\n",
    "        # class weights\n",
    "        cw = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=yb_train)\n",
    "        sw = cw[yb_train]\n",
    "        clf.fit(X_train, yb_train, sample_weight=sw)\n",
    "        self.clf_long = CalibratedClassifierCV(base_estimator=clf, method=\"isotonic\", cv=\"prefit\")\n",
    "        self.clf_long.fit(X_dev, yb_dev)\n",
    "\n",
    "        # separate regressors on log1p scale (median quantile via GBR)\n",
    "        def _fit_reg(X, y):\n",
    "            y_log = np.log1p(y)\n",
    "            reg = GradientBoostingRegressor(loss=\"quantile\", alpha=0.5,\n",
    "                                            n_estimators=800, max_depth=3, learning_rate=0.05,\n",
    "                                            random_state=self.seed)\n",
    "            reg.fit(X, y_log)\n",
    "            y_hat = reg.predict(X)\n",
    "            smear = float(np.mean(np.exp(y_log - y_hat)))  # Duan smearing on train\n",
    "            return reg, smear\n",
    "\n",
    "        m_short = y_train < self.th\n",
    "        m_long  = ~m_short\n",
    "        self.reg_short, self.smear_short = _fit_reg(X_train[m_short], y_train[m_short]) if m_short.any() else (None, 1.0)\n",
    "        self.reg_long,  self.smear_long  = _fit_reg(X_train[m_long],  y_train[m_long])  if m_long.any()  else (None, 1.0)\n",
    "\n",
    "        # choose prob threshold to minimize MAE on dev\n",
    "        p_dev = self.clf_long.predict_proba(X_dev)[:,1]\n",
    "        grid = np.linspace(0.2, 0.8, 25)\n",
    "        def _pred_with(pthr):\n",
    "            yhat = np.zeros_like(y_dev, dtype=float)\n",
    "            choose_long = p_dev >= pthr\n",
    "            if self.reg_short:\n",
    "                ys = np.expm1(self.reg_short.predict(X_dev[~choose_long])) * self.smear_short\n",
    "                yhat[~choose_long] = ys\n",
    "            if self.reg_long:\n",
    "                yl = np.expm1(self.reg_long.predict(X_dev[ choose_long])) * self.smear_long\n",
    "                yhat[ choose_long] = yl\n",
    "            return yhat\n",
    "        best_mae = 1e18\n",
    "        best_thr = 0.5\n",
    "        for t in grid:\n",
    "            yhat = _pred_with(t)\n",
    "            m = np.isfinite(yhat)\n",
    "            cur = np.mean(np.abs(yhat[m] - y_dev[m]))\n",
    "            if cur < best_mae:\n",
    "                best_mae = cur\n",
    "                best_thr = float(t)\n",
    "        self.th_prob = best_thr\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        p_long = self.clf_long.predict_proba(X)[:,1]\n",
    "        choose_long = p_long >= self.th_prob\n",
    "        yhat = np.zeros(X.shape[0], float)\n",
    "        if self.reg_short:\n",
    "            ys = np.expm1(self.reg_short.predict(X[~choose_long])) * self.smear_short\n",
    "            yhat[~choose_long] = ys\n",
    "        if self.reg_long:\n",
    "            yl = np.expm1(self.reg_long.predict(X[ choose_long])) * self.smear_long\n",
    "            yhat[ choose_long] = yl\n",
    "        return yhat\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Figures\n",
    "# ---------------------------\n",
    "def _ci_envelope_xy(xys: List[Tuple[np.ndarray, np.ndarray]]):\n",
    "    xs = np.linspace(0, 1, 200)\n",
    "    ys = np.zeros((len(xys), xs.size))\n",
    "    for i, (x, y) in enumerate(xys):\n",
    "        ys[i] = np.interp(xs, x, y, left=y[0], right=y[-1])\n",
    "    return xs, np.nanmean(ys, 0), np.nanpercentile(ys, 2.5, 0), np.nanpercentile(ys, 97.5, 0)\n",
    "\n",
    "\n",
    "def plot_roc_pr_with_ci(y_true: np.ndarray, proba: np.ndarray, class_names: List[str], out_dir: Path, seed=42):\n",
    "    ensure_dir(out_dir)\n",
    "    oh = np.eye(proba.shape[1])[y_true]\n",
    "\n",
    "    # ROC\n",
    "    plt.figure(figsize=(7.6, 6.2))\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(oh.ravel(), proba.ravel())\n",
    "    plt.plot(fpr_micro, tpr_micro, lw=2, label=f\"micro AUC={auc(fpr_micro, tpr_micro):.3f}\")\n",
    "    for k, name in enumerate(class_names):\n",
    "        f, t, _ = roc_curve(oh[:, k], proba[:, k])\n",
    "        # bootstrap envelope\n",
    "        xys = []\n",
    "        for idx in stratified_boot_idx(y_true, n_boot=300, seed=seed):\n",
    "            yy = np.eye(proba.shape[1])[y_true[idx]]\n",
    "            fi, ti, _ = roc_curve(yy[:, k], proba[idx, k])\n",
    "            xys.append((fi, ti))\n",
    "        xs, ym, yl, yh = _ci_envelope_xy(xys)\n",
    "        plt.plot(f, t, lw=1.8, label=f\"{name} AUC={auc(f, t):.3f}\")\n",
    "        plt.fill_between(xs, yl, yh, alpha=0.15)\n",
    "    plt.plot([0, 1], [0, 1], \"--\", lw=1)\n",
    "    plt.xlim(0, 1); plt.ylim(0, 1.02)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"OVR ROC with 95% CI (hold)\")\n",
    "    plt.legend(loc=\"lower right\", frameon=False, fontsize=9)\n",
    "    plt.tight_layout(); plt.savefig(out_dir / \"Fig_ROC_OVR_hold_CI.png\", dpi=600); plt.close()\n",
    "\n",
    "    # PR\n",
    "    def _plot_f1_isolines(ax, levels=(0.2, 0.4, 0.6, 0.8)):\n",
    "        r = np.linspace(0.01, 1, 200)\n",
    "        for fval in levels:\n",
    "            p = (fval * r) / (2 * r - fval + 1e-12)\n",
    "            p[(2 * r - fval) <= 0] = np.nan\n",
    "            ax.plot(r, p, linestyle=\":\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "    plt.figure(figsize=(7.6, 6.2)); ax = plt.gca()\n",
    "    for k, name in enumerate(class_names):\n",
    "        p, r, _ = precision_recall_curve(oh[:, k], proba[:, k])\n",
    "        ap = average_precision_score(oh[:, k], proba[:, k])\n",
    "        xys = []\n",
    "        for idx in stratified_boot_idx(y_true, n_boot=300, seed=seed):\n",
    "            yy = np.eye(proba.shape[1])[y_true[idx]]\n",
    "            pi, ri, _ = precision_recall_curve(yy[:, k], proba[idx, k])\n",
    "            xys.append((ri, pi))\n",
    "        xs, ym, yl, yh = _ci_envelope_xy(xys)\n",
    "        ax.plot(r, p, lw=1.8, label=f\"{name} AP={ap:.3f}\")\n",
    "        ax.fill_between(xs, yl, yh, alpha=0.15)\n",
    "    _plot_f1_isolines(ax)\n",
    "    ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
    "    ax.set_title(\"OVR Precision–Recall with 95% CI (hold)\")\n",
    "    ax.legend(loc=\"best\", frameon=False, fontsize=9)\n",
    "    plt.tight_layout(); plt.savefig(out_dir / \"Fig_PR_OVR_hold_CI.png\", dpi=600); plt.close()\n",
    "\n",
    "\n",
    "def plot_calibration(y_true: np.ndarray, proba: np.ndarray, class_names: List[str], out_dir: Path):\n",
    "    ensure_dir(out_dir)\n",
    "    bins = np.linspace(0, 1, 11)\n",
    "    oh = np.eye(proba.shape[1])[y_true]\n",
    "    for k, name in enumerate(class_names):\n",
    "        yb = oh[:, k]; ph = proba[:, k]\n",
    "        digit = np.digitize(ph, bins) - 1\n",
    "        obs, pred = [], []\n",
    "        for i in range(len(bins) - 1):\n",
    "            m = digit == i\n",
    "            if m.sum() == 0: \n",
    "                continue\n",
    "            obs.append(np.mean(yb[m])); pred.append(np.mean(ph[m]))\n",
    "        # logistic calibration slope/intercept via LS on logit\n",
    "        x = np.clip(ph, 1e-6, 1-1e-6)\n",
    "        z = np.log(x/(1-x))\n",
    "        A = np.c_[np.ones_like(z), z]\n",
    "        coef, *_ = np.linalg.lstsq(A, yb, rcond=None)\n",
    "        intercept, slope = coef[0], coef[1]\n",
    "        ece = ece_binary(yb, ph, 10)\n",
    "\n",
    "        plt.figure(figsize=(6.6, 6.0))\n",
    "        plt.plot([0, 1], [0, 1], \"--\", lw=1, label=\"Perfect\")\n",
    "        plt.plot(pred, obs, \"o-\", lw=2, label=\"Model\")\n",
    "        plt.xlabel(\"Predicted probability\"); plt.ylabel(\"Observed frequency\")\n",
    "        plt.title(f\"Calibration: {name}\\nECE={ece:.3f}, slope={slope:.2f}, intercept={intercept:.2f}\")\n",
    "        plt.legend(frameon=False)\n",
    "        plt.tight_layout(); plt.savefig(out_dir / f\"Fig_Calibration_{name}.png\", dpi=600); plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrices(y_true: np.ndarray, y_pred: np.ndarray, class_names: List[str], out_dir: Path):\n",
    "    ensure_dir(out_dir)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(class_names)))\n",
    "\n",
    "    def _heat(mat, title, fname, fmt=None, vmin=None, vmax=None):\n",
    "        plt.figure(figsize=(6.0, 5.4))\n",
    "        im = plt.imshow(mat, vmin=vmin, vmax=vmax)\n",
    "        plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "        plt.xticks(range(len(class_names)), class_names, rotation=45, ha=\"right\")\n",
    "        plt.yticks(range(len(class_names)), class_names)\n",
    "        for i in range(mat.shape[0]):\n",
    "            for j in range(mat.shape[1]):\n",
    "                if fmt == \"count\":\n",
    "                    s = f\"{int(mat[i,j])}\"\n",
    "                else:\n",
    "                    s = f\"{mat[i,j]*100:.1f}%\"\n",
    "                plt.text(j, i, s, ha=\"center\", va=\"center\")\n",
    "        plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(title)\n",
    "        plt.tight_layout(); plt.savefig(out_dir / fname, dpi=600); plt.close()\n",
    "\n",
    "    _heat(cm, \"Confusion Matrix (counts)\", \"Fig_CM_counts.png\", fmt=\"count\")\n",
    "    rowpct = cm / cm.sum(axis=1, keepdims=True)\n",
    "    colpct = cm / cm.sum(axis=0, keepdims=True)\n",
    "    _heat(rowpct, \"Confusion Matrix (row %)\", \"Fig_CM_rowpct.png\", vmin=0, vmax=1)\n",
    "    _heat(colpct, \"Confusion Matrix (col %)\", \"Fig_CM_colpct.png\", vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "def plot_bland_altman(y_true: np.ndarray, y_pred: np.ndarray, out_dir: Path, fname=\"Fig_LOS_BlandAltman_hold_CI.png\", title=\"Bland–Altman (hold)\"):\n",
    "    resid = y_pred - y_true\n",
    "    mean_pair = (y_pred + y_true) / 2\n",
    "    ba_mean = float(np.mean(resid)); ba_sd = float(np.std(resid, ddof=1))\n",
    "    loa_low = ba_mean - 1.96 * ba_sd; loa_hi = ba_mean + 1.96 * ba_sd\n",
    "    X = np.c_[np.ones_like(mean_pair), mean_pair]\n",
    "    beta = np.linalg.lstsq(X, resid, rcond=None)[0]\n",
    "    slope = float(beta[1])\n",
    "\n",
    "    plt.figure(figsize=(7.0, 5.3))\n",
    "    plt.scatter(mean_pair, resid, s=10, alpha=0.6)\n",
    "    plt.axhline(ba_mean, linestyle=\"-\", label=f\"Mean diff={ba_mean:.2f}\")\n",
    "    plt.axhline(loa_low, linestyle=\"--\", label=f\"LoA-={loa_low:.2f}\")\n",
    "    plt.axhline(loa_hi, linestyle=\"--\", label=f\"LoA+={loa_hi:.2f}\")\n",
    "    xx = np.linspace(mean_pair.min(), mean_pair.max(), 100)\n",
    "    yy = beta[0] + beta[1] * xx\n",
    "    plt.plot(xx, yy, linestyle=\"-.\", label=f\"slope={slope:.3f}\")\n",
    "    plt.xlabel(\"Mean of True and Pred LOS\"); plt.ylabel(\"Difference (Pred − True)\")\n",
    "    plt.title(title); plt.legend(frameon=False)\n",
    "    plt.tight_layout(); plt.savefig(out_dir / fname, dpi=600); plt.close()\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main routine (example workflow)\n",
    "# ---------------------------\n",
    "def main():\n",
    "    set_seed(CFG.RANDOM_STATE)\n",
    "    ensure_dir(OUT_DIR)\n",
    "\n",
    "    # -------------------- Load your data --------------------\n",
    "    # Implement `load_data()` to return the following 8 objects:\n",
    "    # X_train, y_train, X_hold, y_hold, X_reg_hold, y_reg_hold, num_cols, cat_cols\n",
    "    # If you already have dev split, adapt below.\n",
    "    try:\n",
    "        X_train_all, y_train_all, X_hold, y_hold, X_reg_hold, y_reg_hold, numeric_cols, categorical_cols = load_data()\n",
    "    except RuntimeError as e:\n",
    "        # Guide for users\n",
    "        guide = OUT_DIR / \"HOW_TO_USE.txt\"\n",
    "        guide.write_text(\n",
    "            \"Implement load_data() in this script to return your dataset.\\n\"\n",
    "            \"Expected: X_train_all, y_train_all (classification)\\n\"\n",
    "            \"          X_hold, y_hold (classification)\\n\"\n",
    "            \"          X_reg_hold, y_reg_hold (regression/LOS)\\n\"\n",
    "            \"          numeric_cols, categorical_cols (lists of column names)\\n\\n\"\n",
    "            \"Alternatively, ignore main() and import functions from this module.\\n\",\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "        print(str(e))\n",
    "        print(f\"A usage guide was written to: {guide.resolve()}\")\n",
    "        return\n",
    "\n",
    "    # Split train_all into train/dev (for calibration & threshold search)\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "        X_train_all, y_train_all, test_size=CFG.DEV_FRACTION, random_state=CFG.RANDOM_STATE, stratify=y_train_all\n",
    "    )\n",
    "\n",
    "    # Preprocess\n",
    "    pre = build_preprocessor(numeric_cols, categorical_cols)\n",
    "    pre.fit(X_train_all)\n",
    "\n",
    "    Xtr = pre.transform(X_train); Xdv = pre.transform(X_dev); Xho = pre.transform(X_hold)\n",
    "    Xtr_all = pre.transform(X_train_all)  # for LOS training stage if needed\n",
    "\n",
    "    # -------------------- Classification model --------------------\n",
    "    K = len(np.unique(y_train_all))\n",
    "    params = random_search_xgb_cls(Xdv, y_dev, n_trials=24, seed=CFG.RANDOM_STATE)\n",
    "    # Blend defaults with searched params\n",
    "    cls_params = {**CFG.xgb_cls_params, **params, \"num_class\": K}\n",
    "\n",
    "    clf = OVRCalibratedClassifier(class_names=CFG.CLASS_NAMES)\n",
    "    clf.fit(Xtr, y_train, Xdv, y_dev, params=cls_params, seed=CFG.RANDOM_STATE)\n",
    "\n",
    "    # Evaluate on hold\n",
    "    proba_hold = clf.predict_proba(Xho)\n",
    "    pred_hold = clf.predict(Xho)\n",
    "\n",
    "    # Metrics + AMA table\n",
    "    auw_ci = boot_ci_metric(auroc_weighted, y_hold, proba_hold, n_boot=CFG.N_BOOT, seed=CFG.RANDOM_STATE)\n",
    "    aum_ci = boot_ci_metric(auroc_macro,    y_hold, proba_hold, n_boot=CFG.N_BOOT, seed=CFG.RANDOM_STATE)\n",
    "    apm_ci = boot_ci_metric(ap_macro,       y_hold, proba_hold, n_boot=CFG.N_BOOT, seed=CFG.RANDOM_STATE)\n",
    "    bsr_ci = boot_ci_metric(lambda yt,pp: brier_multiclass(yt,pp), y_hold, proba_hold, n_boot=CFG.N_BOOT, seed=CFG.RANDOM_STATE)\n",
    "    acc_ci = boot_ci_metric(lambda yt,pp: accuracy_score(yt, pp.argmax(1)), y_hold, proba_hold, n_boot=CFG.N_BOOT, seed=CFG.RANDOM_STATE)\n",
    "    f1m_ci = boot_ci_metric(lambda yt,pp: f1_score(yt, pp.argmax(1), average=\"macro\"), y_hold, proba_hold, n_boot=CFG.N_BOOT, seed=CFG.RANDOM_STATE)\n",
    "\n",
    "    df_cls = pd.DataFrame([{\n",
    "        \"Model\": \"XGBoost + OVR + Isotonic + ThresholdOpt\",\n",
    "        \"AUROC (weighted)\": fmt_ci(*auw_ci, 3),\n",
    "        \"AUROC (macro)\":    fmt_ci(*aum_ci, 3),\n",
    "        \"AP (macro)\":       fmt_ci(*apm_ci, 3),\n",
    "        \"Brier score\":      fmt_ci(*bsr_ci, 3),\n",
    "        \"Accuracy\":         fmt_ci(*acc_ci, 3),\n",
    "        \"F1 (macro)\":       fmt_ci(*f1m_ci, 3),\n",
    "    }])\n",
    "    df_cls.to_csv(OUT_DIR / \"Table_AMA_main_classification.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # Figures\n",
    "    plot_roc_pr_with_ci(y_hold, proba_hold, CFG.CLASS_NAMES, OUT_DIR, seed=CFG.RANDOM_STATE)\n",
    "    plot_calibration(y_hold, proba_hold, CFG.CLASS_NAMES, OUT_DIR)\n",
    "    plot_confusion_matrices(y_hold, pred_hold, CFG.CLASS_NAMES, OUT_DIR)\n",
    "\n",
    "    # -------------------- LOS regression (two-stage) --------------------\n",
    "    # Split training LOS target from the same patients as classification (replace if needed)\n",
    "    if CFG.TARGET_REG in X_train_all.columns:\n",
    "        y_los_all = X_train_all[CFG.TARGET_REG].astype(float).to_numpy()\n",
    "        y_los_train, y_los_dev = y_los_all[:len(X_train)], y_los_all[len(X_train):len(X_train)+len(X_dev)]\n",
    "    else:\n",
    "        # If LOS is provided separately, adapt here; otherwise assume y_reg_hold belongs to hold only\n",
    "        y_los_train = None; y_los_dev = None\n",
    "\n",
    "    # For simplicity we reuse Xtr/Xdv for LOS; adapt if you use different features\n",
    "    # Here we safeguard in case LOS labels for train/dev are not present.\n",
    "    if y_los_train is None or len(y_los_train) != Xtr.shape[0]:\n",
    "        # fallback: split hold LOS to mimic dev for code continuity (you should replace with your labels)\n",
    "        print(\"WARNING: LOS train/dev labels not found; skipping LOS model training. Only hold evaluation will be plotted if possible.\")\n",
    "        yhat_los_hold = X_reg_hold[CFG.TARGET_REG].values if CFG.TARGET_REG in X_reg_hold.columns else np.zeros_like(y_reg_hold)\n",
    "    else:\n",
    "        los_model = TwoStageLOSRegressor(long_threshold=CFG.LONG_LOS_THRESHOLD, seed=CFG.RANDOM_STATE)\n",
    "        los_model.fit(Xtr, y_los_train, Xdv, y_los_dev)\n",
    "        Xho_reg = Xho if Xho.shape[0] == X_reg_hold.shape[0] else pre.transform(X_reg_hold)\n",
    "        yhat_los_hold = los_model.predict(Xho_reg)\n",
    "\n",
    "    # Evaluate LOS on hold (requires y_reg_hold)\n",
    "    yt = y_reg_hold.astype(float).to_numpy()\n",
    "    yp = yhat_los_hold.astype(float)\n",
    "    rmse_ci = boot_ci_reg(rmse, yt, yp, n_boot=max(2000, CFG.N_BOOT), seed=CFG.RANDOM_STATE)\n",
    "    mae_ci  = boot_ci_reg(mae,  yt, yp, n_boot=max(2000, CFG.N_BOOT), seed=CFG.RANDOM_STATE)\n",
    "    med_ci  = boot_ci_reg(lambda a,b: float(median_absolute_error(a,b)), yt, yp, n_boot=max(2000, CFG.N_BOOT), seed=CFG.RANDOM_STATE)\n",
    "    mape_ci = boot_ci_reg(mape, yt, yp, n_boot=max(2000, CFG.N_BOOT), seed=CFG.RANDOM_STATE)\n",
    "    r2_ci   = boot_ci_reg(lambda a,b: float(r2_score(a,b)), yt, yp, n_boot=max(2000, CFG.N_BOOT), seed=CFG.RANDOM_STATE)\n",
    "\n",
    "    # Save LOS table (AMA)\n",
    "    df_reg = pd.DataFrame([{\n",
    "        \"RMSE\":  fmt_ci(*rmse_ci, 2),\n",
    "        \"MAE\":   fmt_ci(*mae_ci, 2),\n",
    "        \"MedAE\": fmt_ci(*med_ci, 2),\n",
    "        \"MAPE\":  fmt_ci(*mape_ci, 3),\n",
    "        \"R²\":    fmt_ci(*r2_ci, 3),\n",
    "        \"N_hold\": len(yt)\n",
    "    }])\n",
    "    df_reg.to_csv(OUT_DIR / \"Table_LOS_metrics.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # Plot Bland–Altman\n",
    "    plot_bland_altman(yt, yp, OUT_DIR)\n",
    "\n",
    "    # Upper quartile error (long-stay region)\n",
    "    q = np.percentile(yt, 75)\n",
    "    hi = yt >= q\n",
    "    hi_mae = float(np.mean(np.abs(yp[hi] - yt[hi])))\n",
    "    Path(OUT_DIR / \"Regression_upper_quartile_error.txt\").write_text(\n",
    "        f\"MAE@Top25% LOS (>=P75={q:.1f}d): {hi_mae:.2f} days\\n\", encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    # Save config used\n",
    "    save_json(asdict(CFG), OUT_DIR / \"run_config.json\")\n",
    "\n",
    "    print(\"All done. Outputs saved to:\", OUT_DIR.resolve())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "path = Path('/mnt/data/paper_pipeline_full.py')\n",
    "path.write_text(code, encoding='utf-8')\n",
    "str(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10-10) 長期入院（LOS ≥ 21d）二値分類：開発→最適しきい値→校正→論文用図表\n",
    "#  前提：あなたのフルコード（dt_list, hold_idx, Config, WinsorizeLog1pTransformer,\n",
    "#       fit_with_gpu_fallback_xgb, _build_xgb_fit_kwargs_for_es, gpu_params 等）が実行済み\n",
    "#  出力：Config.RESULT_DIR / \"longstay21\" 以下\n",
    "# ============================================\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (roc_auc_score, precision_recall_curve, confusion_matrix,\n",
    "                             roc_curve, auc, f1_score, accuracy_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "LONG_DIR = (Config.RESULT_DIR / \"longstay21\")\n",
    "LONG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LONG_THR_DAYS = 21\n",
    "RNG = np.random.default_rng(Config.RANDOM_STATE)\n",
    "\n",
    "# ---------- 小物ユーティリティ ----------\n",
    "def stratified_boot_idx(y: np.ndarray, n_boot=600, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y)\n",
    "    cls = np.unique(y)\n",
    "    idx_by = {c: np.flatnonzero(y==c) for c in cls}\n",
    "    n_by   = {c: len(idx_by[c]) for c in cls}\n",
    "    for _ in range(n_boot):\n",
    "        yield np.concatenate([rng.choice(idx_by[c], n_by[c], replace=True) for c in cls])\n",
    "\n",
    "def boot_ci_binary(stat_fn, y_true: np.ndarray, p_hat: np.ndarray, thr=None, n_boot=600, seed=42):\n",
    "    vals=[]\n",
    "    for idx in stratified_boot_idx(y_true, n_boot=n_boot, seed=seed):\n",
    "        yt = y_true[idx]; ph = p_hat[idx]\n",
    "        vals.append(float(stat_fn(yt, ph, thr)))\n",
    "    a = np.asarray(vals, float)\n",
    "    return float(np.mean(a)), float(np.percentile(a,2.5)), float(np.percentile(a,97.5))\n",
    "\n",
    "def fmt_ci(pt, lo, hi, dec=3):\n",
    "    f = lambda x: f\"{x:.{dec}f}\"\n",
    "    return f\"{f(pt)} [{f(lo)}–{f(hi)}]\"\n",
    "\n",
    "# 指標（thrが必要なものは第3引数にthrを受け取る形へ）\n",
    "def _auroc(yt, ph, thr=None): return float(roc_auc_score(yt, ph))\n",
    "def _ap(yt, ph, thr=None):\n",
    "    p, r, _ = precision_recall_curve(yt, ph)\n",
    "    return float(np.trapz(p[::-1], r[::-1]))\n",
    "def _sens(yt, ph, thr):  # Recall+\n",
    "    yp = (ph>=thr).astype(int); tp = np.sum((yp==1)&(yt==1)); fn = np.sum((yp==0)&(yt==1))\n",
    "    return float(tp/(tp+fn+1e-12))\n",
    "def _spec(yt, ph, thr):\n",
    "    yp = (ph>=thr).astype(int); tn = np.sum((yp==0)&(yt==0)); fp = np.sum((yp==1)&(yt==0))\n",
    "    return float(tn/(tn+fp+1e-12))\n",
    "def _ppv(yt, ph, thr):\n",
    "    yp = (ph>=thr).astype(int); tp = np.sum((yp==1)&(yt==1)); fp = np.sum((yp==1)&(yt==0))\n",
    "    return float(tp/(tp+fp+1e-12))\n",
    "def _npv(yt, ph, thr):\n",
    "    yp = (ph>=thr).astype(int); tn = np.sum((yp==0)&(yt==0)); fn = np.sum((yp==0)&(yt==1))\n",
    "    return float(tn/(tn+fn+1e-12))\n",
    "def _acc(yt, ph, thr):\n",
    "    yp = (ph>=thr).astype(int); return float(np.mean(yp==yt))\n",
    "def _f1(yt, ph, thr):\n",
    "    yp = (ph>=thr).astype(int); \n",
    "    tp=np.sum((yp==1)&(yt==1)); fp=np.sum((yp==1)&(yt==0)); fn=np.sum((yp==0)&(yt==1))\n",
    "    return float(2*tp/(2*tp+fp+fn+1e-12))\n",
    "\n",
    "def _ci_envelope(xys):\n",
    "    xs = np.linspace(0,1,200)\n",
    "    Ys = np.zeros((len(xys), xs.size))\n",
    "    for i,(x,y) in enumerate(xys):\n",
    "        Ys[i] = np.interp(xs, x, y, left=y[0], right=y[-1])\n",
    "    return xs, np.nanmean(Ys,0), np.nanpercentile(Ys,2.5,0), np.nanpercentile(Ys,97.5,0)\n",
    "\n",
    "def plot_roc_ci(y_true, p_hat, out_png):\n",
    "    fpr, tpr, _ = roc_curve(y_true, p_hat); a = auc(fpr,tpr)\n",
    "    xys=[]\n",
    "    for idx in stratified_boot_idx(y_true, n_boot=300, seed=Config.RANDOM_STATE):\n",
    "        fi,ti,_ = roc_curve(y_true[idx], p_hat[idx]); xys.append((fi,ti))\n",
    "    xs, ym, yl, yh = _ci_envelope(xys)\n",
    "    plt.figure(figsize=(7.0,5.8))\n",
    "    plt.plot(fpr,tpr,lw=2,label=f\"AUC={a:.3f}\")\n",
    "    plt.fill_between(xs, yl, yh, alpha=0.15)\n",
    "    plt.plot([0,1],[0,1],'--',lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC (hold)  |  LOS ≥ {LONG_THR_DAYS} d\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=600); plt.close()\n",
    "\n",
    "def plot_pr_ci(y_true, p_hat, out_png):\n",
    "    pr, rc, _ = precision_recall_curve(y_true, p_hat)\n",
    "    ap = float(np.trapz(pr[::-1], rc[::-1]))\n",
    "    xys=[]\n",
    "    for idx in stratified_boot_idx(y_true, n_boot=300, seed=Config.RANDOM_STATE):\n",
    "        pi,ri,_ = precision_recall_curve(y_true[idx], p_hat[idx]); xys.append((ri,pi))\n",
    "    xs, ym, yl, yh = _ci_envelope(xys)\n",
    "    plt.figure(figsize=(7.0,5.8)); ax=plt.gca()\n",
    "    ax.plot(rc, pr, lw=2, label=f\"AP={ap:.3f}\")\n",
    "    ax.fill_between(xs, yl, yh, alpha=0.15)\n",
    "\n",
    "    # F1 等高線（読み取り補助）\n",
    "    r = np.linspace(0.01,1,200)\n",
    "    for f in (0.2,0.4,0.6,0.8):\n",
    "        p = (f*r)/(2*r - f + 1e-12); p[(2*r-f)<=0]=np.nan\n",
    "        ax.plot(r,p, linestyle=\":\", linewidth=0.8, alpha=0.6)\n",
    "    ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
    "    ax.set_title(f\"Precision–Recall (hold)  |  LOS ≥ {LONG_THR_DAYS} d\")\n",
    "    ax.legend(frameon=False); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=600); plt.close()\n",
    "\n",
    "def plot_calibration_binary(y_true, p_hat, out_png):\n",
    "    bins = np.linspace(0,1,11)\n",
    "    digit = np.digitize(p_hat, bins)-1\n",
    "    obs, pred, cnt = [], [], []\n",
    "    for i in range(len(bins)-1):\n",
    "        m = (digit==i)\n",
    "        if m.sum()==0: continue\n",
    "        obs.append(np.mean(y_true[m])); pred.append(np.mean(p_hat[m])); cnt.append(np.sum(m))\n",
    "    plt.figure(figsize=(6.2,5.6))\n",
    "    plt.plot([0,1],[0,1],'--',lw=1,label=\"Perfect\")\n",
    "    plt.plot(pred, obs, 'o-', lw=2, label=\"Model\")\n",
    "    ax = plt.gca(); ax2 = ax.twinx(); ax2.bar(pred, cnt, width=0.07, alpha=0.25)\n",
    "    ax.set_xlabel(\"Predicted probability\"); ax.set_ylabel(\"Observed frequency\"); ax2.set_ylabel(\"Count/bin\")\n",
    "    plt.title(\"Calibration (hold)\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=600); plt.close()\n",
    "\n",
    "def decision_curve_binary(y_true, p_hat, out_png):\n",
    "    th = np.linspace(0.01, 0.8, 80); N=len(y_true)\n",
    "    NB, NB_all = [], []\n",
    "    for pt in th:\n",
    "        pred = (p_hat>=pt).astype(int)\n",
    "        TP = np.sum((pred==1)&(y_true==1)); FP = np.sum((pred==1)&(y_true==0))\n",
    "        nb = (TP/N) - (FP/N) * (pt/(1-pt))\n",
    "        TP_all = np.sum(y_true==1); FP_all = np.sum(y_true==0)\n",
    "        nb_all = (TP_all/N) - (FP_all/N) * (pt/(1-pt))\n",
    "        NB.append(nb); NB_all.append(nb_all)\n",
    "    NB = np.array(NB); NB_all = np.array(NB_all); NB_none = np.zeros_like(NB)\n",
    "    plt.figure(figsize=(7.0,5.8))\n",
    "    plt.plot(th, NB, label=\"Model\", lw=1.8)\n",
    "    plt.plot(th, NB_all, '--', color=\"gray\", label=\"Treat-all\")\n",
    "    plt.plot(th, NB_none, ':', color=\"black\", label=\"Treat-none\")\n",
    "    plt.xlabel(\"Threshold probability (pt)\"); plt.ylabel(\"Net Benefit\")\n",
    "    plt.title(f\"DCA (hold)  |  LOS ≥ {LONG_THR_DAYS} d\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(out_png, dpi=600); plt.close()\n",
    "\n",
    "# ---------- MIごとに学習・予測（dev内で校正＆しきい値） ----------\n",
    "proba_hold_list = []\n",
    "thr_list = []\n",
    "y_long_hold_ref = None\n",
    "idx_hold = dt_list[0].loc[hold_idx, Config.INDEX_COL].to_numpy()\n",
    "\n",
    "for i, dt in enumerate(dt_list, 1):\n",
    "    # dev/hold へ（あなたの関数の出力に沿う）\n",
    "    Xd, _, Xh, _ = prepare_from_dt_timeaware(dt)\n",
    "    # ターゲット（二値）\n",
    "    y_long_dev  = (dt.loc[Xd.index, Config.LOS_COL].astype(float).to_numpy() >= LONG_THR_DAYS).astype(int)\n",
    "    y_long_hold = (dt.loc[Xh.index, Config.LOS_COL].astype(float).to_numpy() >= LONG_THR_DAYS).astype(int)\n",
    "    if y_long_hold_ref is None:\n",
    "        y_long_hold_ref = y_long_hold.copy()  # 参照（MI間で一致するはず）\n",
    "\n",
    "    # 前処理\n",
    "    pre = WinsorizeLog1pTransformer().fit(Xd, y_long_dev)\n",
    "    Xd_tr = pre.transform(Xd); Xh_tr = pre.transform(Xh)\n",
    "\n",
    "    # dev内を train(70%) / temp(30%) に、temp→ calib(15%) / val(15%) へ分割\n",
    "    Xtr_all, Xtmp, ytr_all, ytmp = train_test_split(\n",
    "        Xd_tr, y_long_dev, test_size=0.30, random_state=Config.RANDOM_STATE, stratify=y_long_dev\n",
    "    )\n",
    "    Xcal, Xval, ycal, yval = train_test_split(\n",
    "        Xtmp, ytmp, test_size=0.5, random_state=Config.RANDOM_STATE, stratify=ytmp\n",
    "    )\n",
    "\n",
    "    # 早期終了用に train をさらに 10% 切ってES\n",
    "    Xtr_es, Xes, ytr_es, yes = train_test_split(\n",
    "        Xtr_all, ytr_all, test_size=0.10, random_state=Config.RANDOM_STATE, stratify=ytr_all\n",
    "    )\n",
    "\n",
    "    # 分類器（不均衡重み）\n",
    "    cw = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=ytr_es)\n",
    "    sw = cw[ytr_es]\n",
    "    base = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "        n_estimators=800, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "        random_state=Config.RANDOM_STATE, **gpu_params()\n",
    "    )\n",
    "    fit_kw = _build_xgb_fit_kwargs_for_es(base, Xes, yes, sw, es_rounds=ES_ROUNDS)\n",
    "    mdl_es, _ = fit_with_gpu_fallback_xgb(base, Xtr_es, ytr_es, sample_weight=sw, fit_kwargs=fit_kw)\n",
    "    best_iter = int(getattr(mdl_es, \"best_iteration\", None) or getattr(mdl_es, \"best_ntree_limit\", 800))\n",
    "\n",
    "    # train全体でリフィット\n",
    "    cw2 = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=ytr_all)\n",
    "    sw2 = cw2[ytr_all]\n",
    "    mdl = xgb.XGBClassifier(**{**mdl_es.get_params(), \"n_estimators\": best_iter})\n",
    "    mdl, _ = fit_with_gpu_fallback_xgb(mdl, Xtr_all, ytr_all, sample_weight=sw2)\n",
    "\n",
    "    # isotonic再校正（calibセット）\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    cal = CalibratedClassifierCV(base_estimator=mdl, method=\"isotonic\", cv=\"prefit\")\n",
    "    cal.fit(Xcal, ycal)\n",
    "\n",
    "    # valでF1最大しきい値\n",
    "    p_val = cal.predict_proba(Xval)[:,1]\n",
    "    pr, rc, thr = precision_recall_curve(yval, p_val)\n",
    "    f1 = 2*pr*rc/(pr+rc+1e-12); j = int(np.nanargmax(f1))\n",
    "    best_thr = 0.5 if j>=len(thr) else float(thr[j])\n",
    "    thr_list.append(best_thr)\n",
    "\n",
    "    # hold予測\n",
    "    p_hold = cal.predict_proba(Xh_tr)[:,1]\n",
    "    df_p = pd.DataFrame({\"p\": p_hold}, index=dt.loc[Xh.index, Config.INDEX_COL].values)\n",
    "    proba_hold_list.append(df_p)\n",
    "\n",
    "# ---------- MIプール（平均） ----------\n",
    "proba_concat = pd.concat(proba_hold_list, axis=1).sort_index()\n",
    "p_pool = proba_concat.mean(axis=1).loc[idx_hold].values\n",
    "thr_pool = float(np.mean(thr_list))  # 簡便：MI別最適しきい値の平均\n",
    "y_hold_bin = y_long_hold_ref  # ground truth\n",
    "\n",
    "# ---------- 指標（95%CIつき） ----------\n",
    "auw = boot_ci_binary(_auroc, y_hold_bin, p_pool, None, n_boot=Config.N_BOOT, seed=Config.RANDOM_STATE)\n",
    "apw = boot_ci_binary(_ap,    y_hold_bin, p_pool, None, n_boot=Config.N_BOOT, seed=Config.RANDOM_STATE)\n",
    "sen = boot_ci_binary(_sens,  y_hold_bin, p_pool, thr_pool, Config.N_BOOT, Config.RANDOM_STATE)\n",
    "spe = boot_ci_binary(_spec,  y_hold_bin, p_pool, thr_pool, Config.N_BOOT, Config.RANDOM_STATE)\n",
    "ppv = boot_ci_binary(_ppv,   y_hold_bin, p_pool, thr_pool, Config.N_BOOT, Config.RANDOM_STATE)\n",
    "npv = boot_ci_binary(_npv,   y_hold_bin, p_pool, thr_pool, Config.N_BOOT, Config.RANDOM_STATE)\n",
    "acc = boot_ci_binary(_acc,   y_hold_bin, p_pool, thr_pool, Config.N_BOOT, Config.RANDOM_STATE)\n",
    "f1c = boot_ci_binary(_f1,    y_hold_bin, p_pool, thr_pool, Config.N_BOOT, Config.RANDOM_STATE)\n",
    "\n",
    "# AMA表（推定値 [95%CI]）\n",
    "table = pd.DataFrame([{\n",
    "    \"Model\": f\"XGB(isotonic)+MI pooled (LOS≥{LONG_THR_DAYS})\",\n",
    "    \"AUROC\": fmt_ci(*auw, 3),\n",
    "    \"AP\":    fmt_ci(*apw, 3),\n",
    "    \"Sensitivity\": fmt_ci(*sen, 3),\n",
    "    \"Specificity\": fmt_ci(*spe, 3),\n",
    "    \"PPV\": fmt_ci(*ppv, 3),\n",
    "    \"NPV\": fmt_ci(*npv, 3),\n",
    "    \"Accuracy\": fmt_ci(*acc, 3),\n",
    "    \"F1\": fmt_ci(*f1c, 3),\n",
    "    \"Threshold*\": f\"{thr_pool:.3f}\",\n",
    "    \"Prevalence\": f\"{np.mean(y_hold_bin):.3f}\"\n",
    "}])\n",
    "table.to_csv(LONG_DIR/\"Table_longstay21_metrics_AMA.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# ---------- 図 ----------\n",
    "plot_roc_ci(y_hold_bin, p_pool, LONG_DIR/\"Fig_ROC_hold_CI.png\")\n",
    "plot_pr_ci (y_hold_bin, p_pool, LONG_DIR/\"Fig_PR_hold_CI.png\")\n",
    "plot_calibration_binary(y_hold_bin, p_pool, LONG_DIR/\"Fig_Calibration_hold.png\")\n",
    "decision_curve_binary  (y_hold_bin, p_pool, LONG_DIR/\"Fig_DCA_hold.png\")\n",
    "\n",
    "# 混同行列（counts/row%/col%）\n",
    "yp = (p_pool >= thr_pool).astype(int)\n",
    "cm = confusion_matrix(y_hold_bin, yp, labels=[0,1])\n",
    "pd.DataFrame(cm, index=[\"<21\",\"≥21\"], columns=[\"pred<21\",\"pred≥21\"]).to_csv(LONG_DIR/\"ConfusionMatrix_counts.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "def _heat(mat, title, fname, pct=False):\n",
    "    plt.figure(figsize=(5.6,4.8))\n",
    "    im = plt.imshow(mat if not pct else mat*100, vmin=0, vmax=(1 if pct else None))\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            s = f\"{mat[i,j]*100:.1f}%\" if pct else f\"{int(mat[i,j])}\"\n",
    "            plt.text(j,i,s,ha=\"center\",va=\"center\")\n",
    "    plt.xticks([0,1], [\"pred<21\",\"pred≥21\"]); plt.yticks([0,1], [\"<21\",\"≥21\"])\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(title)\n",
    "    plt.tight_layout(); plt.savefig(LONG_DIR/fname, dpi=600); plt.close()\n",
    "\n",
    "_heat(cm, \"Confusion Matrix (counts)\", \"Fig_CM_counts.png\", pct=False)\n",
    "rowpct = cm / cm.sum(axis=1, keepdims=True); _heat(rowpct, \"Confusion Matrix (row %)\", \"Fig_CM_rowpct.png\", pct=True)\n",
    "colpct = cm / cm.sum(axis=0, keepdims=True); _heat(colpct, \"Confusion Matrix (col %)\", \"Fig_CM_colpct.png\", pct=True)\n",
    "\n",
    "# サマリも保存\n",
    "pd.Series({\n",
    "    \"thr_pool\": thr_pool,\n",
    "    \"event_rate_hold\": float(np.mean(y_hold_bin)),\n",
    "    \"n_hold\": int(len(y_hold_bin))\n",
    "}).to_csv(LONG_DIR/\"summary.txt\")\n",
    "\n",
    "print(\"二値（LOS≥21d）完了 →\", LONG_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ad84467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary(Home vs Non-Home)  AUROC=0.798  AP=0.770\n",
      "thr=0.50: {'thr': 0.5, 'sens': 0.7113402061855651, 'spec': 0.7665847665847647, 'ppv': 0.7439353099730438, 'npv': 0.7358490566037718, 'acc': 0.7396226415094339, 'f1': 0.7272727272727263}\n",
      "thr@prevalence: {'thr': 0.4820980084017388, 'sens': 0.7448453608247403, 'spec': 0.7567567567567548, 'ppv': 0.7448453608247403, 'npv': 0.7567567567567548, 'acc': 0.7509433962264151, 'f1': 0.7448453608247413}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAHTCAYAAAB7ilFJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWqRJREFUeJzt3XlYVGX/BvB7GIZVFtlhhlVEcN9Qyw1TS0Xb0SzfMk1td8lMzVIr07LCTN/yza3MFi1/We4KpuIuuSsiCLILiDCsA8yc3x/I6DigLAeGgftzXXNd8MyZc75zQOfmOc95HokgCAKIiIiIRGBi6AKIiIio+WCwICIiItEwWBAREZFoGCyIiIhINAwWREREJBoGCyIiIhINgwURERGJhsGCiIiIRMNgQURERKJhsCAiIiLRMFgQPcD69eshkUiQmJhY5fMLFiyARCJp3KKakJCQEEgkErz77rtVPj9+/HiEhIQ0blG3hYSE3PfYPj4+GD9+fKPVUx+Vv4eVDzMzM3h7e2P8+PGIi4vT2fbu7UxMTODs7IwBAwZg/fr14CoO1NAYLIio3tzd3REeHo4TJ04YupRmb9++fbh8+TKioqIwf/58HD58GL1790ZKSorOdm+88QYuX76M8+fPY9OmTQgODsaECRPw/vvvG6hyailMDV0AERm/Rx99FNeuXcPLL7+M06dPw8zMzNAlNVtt2rSBj48PAKBXr14ICQlBmzZtsH79esybN0+7nZOTEwIDAwEAHTp0wKBBg5CVlYXvvvsOn376qSFKpxaCPRZEDeSHH35A586dYWFhAQ8PD7z55pvIzc3V2SYkJATjxo3DypUr4e7uDnt7e8yaNQuCICA8PBzu7u6wtbXF66+/jvLycp3XZmVlYcKECXBycoKdnR1CQkJw8ODB+9YjkUhw+vRpnfb9+/dDIpFg//79AIBvvvkGfn5+sLS0RM+ePfHXX3/V6P2uWLECsbGx+Oijjx64rUqlwvvvvw9vb2+Ym5ujXbt2+Oqrr6DRaHS2k0gk+O6777Bq1Sq0bdsWrVq1Qt++fXHu3Lka1VQXubm5eOONN+Du7g4LCwt06dIFP/74o842iYmJkEgk+OOPP/Dss8/C2toaAQEBiIiIQE5ODp566ilYW1vDz88Pf/75p94x9u/fj759+8LS0hJeXl6YPHkysrKy6lSvn58fHB0dkZSU9MBtpVIpZDJZnY5DVFMMFkQN4OOPP8bEiRMxatQoHDx4EF9++SX++usvDBw4EEVFRTrbRkVF4YcffsCmTZvw4YcfYunSpRg7dix++eUX/Pbbb/jyyy+xatUqfPPNN9rX5OfnY+DAgbh27Rp+/vln7NmzB126dMGgQYOwZ8+eKmsaPXo07Ozs8NNPP+m0//LLL2jTpg1CQkIQERGBadOm4YMPPsDRo0fx5JNPVhmIqtK5c2fMmjULn332mV54uZtGo8GoUaPw3XffYd68eTh8+DAmTZqEefPmYfLkyXrbf/vtt1i/fj2+++47/PXXX8jMzMSYMWP0QogYCgsLMXDgQPz9998IDw/HwYMHERoaigkTJuCTTz7R2/6dd96Bv78/IiMj4ePjg+eeew5hYWFo164dIiMj0aNHDzz33HNIT0/Xvmb37t0YPnw4QkJCcODAAXz77bf4999/0a9fP73fjZpISkrCzZs3oVAoqnxerVYjLS0N4eHh2LhxIz788MNaH4OoVgQiuq9169YJAASpVFrlQyKRCHf/U0pKShJMTU2F6dOn6+wnOjpaMDExEZYsWaJtGzhwoGBlZSWkpqZq29q0aSNYWloKGRkZOtv169dP+/2iRYsEX19foaSkROcYYWFhwkMPPVTte3n11VcFDw8PQa1WC4IgCKWlpYKDg4OwePFiQRAEYenSpYK9vb1QVlamfU1RUdF9z8/AgQOFl156SRAEQSgpKRHat28vdO3aVbuPl156SRg4cKB2+19++UUAIGzdulVnP+Hh4QIA4dixY9o2AIKbm5uQm5urbVu9erUAQIiLi7tvXZW13e9nB0BbuyAIwuLFiwWpVCpER0fr7Gfq1KmCTCYTkpOTBUEQhISEBAGA8OSTT2q3OXjwoABAePrpp7VtldutXr1a29a2bVth7ty5Ovu/efOmYGFhIaxatara91L5e5iQkCAIgiDk5uYKe/bsEbp06SJYWVkJ8fHxOudNIpHo/H6OGzdOOHLkyAPPGVF9sceCqIZ27NiBM2fO6D1effVVne127dqF8vJyvb++u3fvjuDgYGzfvl2nvUuXLvDw8NB+7+HhgR49esDV1VXb5uXlpfNX744dO5CYmAhra2uYmppqH3/88cd9ewsmTZqEtLQ0REZGAqj461mpVGrvjAgNDUVpaSmGDRuGAwcOQBAEWFpa1vgcmZubY+3atTh//jwWL15c5TZ///03XF1d8fjjj+u0T548GRKJRO/8jBs3DnZ2dtrvfX19AUB7Pj766COdczB48GCd1/fs2bPKn9uZM2d0zntlbT179kT37t112l999VWUlZXp9QYNHz5c+7VcLgcAjBgxQtvm5eWlU2tcXByuXr2KJUuW6NTs4uKCkpKS+/7sKvn7+8PU1BT29vZ47LHHYG1tjYiICPj5+enV/O+//2LTpk3o0qULjh49Cnd39wfun6i+OHiTqIYCAgK0g+bu5uLiovN9ZmYmAMDb21tvWy8vL5w5c0an7d6BjiYm+nnfxMREZ4zFjRs38Mgjj2DZsmU1rL5C9+7d0a1bN2zcuBFDhgzBzz//jJEjR8LNzQ0AEBQUhJMnT2L+/PkYOnQo/P39sXLlSgwaNKjGx+jduzemT5+ORYsW4fnnn9d7PjMzs8pzY2VlBScnJ2RkZOi0W1tb63xfeX4qz8err76Kp59+utrtra2t0bFjxyprvXe8QWZmpl6oAO4EhHtru/tnV1mXVCqtttYbN24AAJYtW1blOW3dunWVdd5tx44d8PDwgJmZGTw8PNCqVasqt3NxcUHnzp3RuXNnDB06FN27d8fo0aNx7NixKn/HiMTCYEEkMmdnZwBAcnIyAgICdJ5LSkqCk5NTvY/h6OiIGzduVPuBeT8TJ07E3LlzER4ejr///hu//vqrzvPt27fH5s2bkZ6ejrfeegsjRoxAbGwsPD09a3yMjz76CFu3bsXUqVP13q+zszMuXryo95ri4mJkZ2fX+vy4uLjohbu6cnZ2RnJysl575cDI+v7sHB0dAQClpaV1+tkB1Qfc+7Gzs8PSpUvxzDPP4Oeff8a4cePqdGyimmBsJRLZo48+CqlUitWrV+u0nz59GqdOnUJoaGi9jzF8+HBcuHBBr2v+6NGj1U5UVemFF15AWVkZ3n33Xdjb22PYsGHa59RqNfLy8gBUzE2xdu1alJSU1Hp+CktLS6xduxY7d+7UXna5u/b09HTs2LFDp/3777+HIAg6lxIa2/Dhw3Hy5Em9u07+97//wdTUFI8++mi99t+uXTv4+vpi5cqVKCkp0Xnu/fffx4EDB+q1//t56qmn0K5dOyxatKhBBr4SVWKwIBKZj48PZs+eja+++goffvghTp48id9++w1PPPEEAgMDMXXq1HofY/r06QgMDMQzzzyD5cuXIzo6GmvXrsXIkSNhYWFx39fa29vjmWeewZo1a/Dyyy/rdN2///776NWrFzZv3oxz585h2bJlkMlk6NatW61r7NevH9588029HoCxY8di4MCBePHFF7FmzRqcOnUKX3zxBWbPno0XX3wR/fr1q/WxxDJt2jT4+/vj8ccfx2+//YYTJ05g3rx5WL58OebOnVvrnoJ7SSQSrFixAsnJyRgwYAC2bduGEydO4PXXX8eyZcvg4OAgzhup5thTp05FTEwMtm7d2mDHIeKlEKIG8Mknn8DT0xPLly/HkiVL4ODggKeeegqLFi2q9pp4bdja2iIqKgrz5s3D4sWLkZOTA39/fyxatEhvMGlVJk2ahI0bN2LChAk67fPmzYNGo8GMGTOQlZWFgIAA/P7773oDA2vq008/xbZt23TaTE1NsWPHDsyfPx8LFizAjRs34O3tjQULFmDmzJl1Oo5YbGxscOjQIcydOxdvv/02cnNzERAQgFWrVmHixImiHGPEiBGIiIjAggULMGbMGJiamuLhhx/G4cOH0alTJ1GOUZ2XXnoJ8+bNw9KlS/HUU0816LGo5ZIIAieOJyIiInHwUggRERGJhsGCiIiIRMNgQURERKJhsCAiIiLRMFgQERGRaBgsiIiISDQtah4LjUaDtLQ02NjYQCKRGLocIiIioyEIAvLz8+Hh4XHf9WZaVLBIS0ur1XoHREREpCs5ORkKhaLa51tUsLCxsQFQcVJsbW0NXA0REZHxUCqV8PT01H6WVqdFBYvKyx+2trYMFkRERHXwoKEEHLxJREREomGwICIiItEwWBAREZFoWtQYCyIiahiCIKC8vBxqtdrQpVAdSaVSmJqa1ns6BgYLIiKql9LSUqSnp6OoqMjQpVA9WVlZwd3dHWZmZnXeB4MFERHVmUajQUJCAqRSKTw8PGBmZsYJCI2QIAgoLS1FVlYWEhIS0LZt2/tOgnU/DBZERFRnpaWl0Gg08PT0hJWVlaHLoXqwtLSETCbD9evXUVpaCgsLizrth4M3iYio3ur61y01LWL8HPmbQERERKJhsCAiIiLRGCxYaDQaHDt2DDNmzICDgwPWr19/3+1TU1MxZswY+Pj4QC6XY/r06VCpVI1TLBERNVu7d++GqakpUlJSdNpDQkJga2sLhUIBDw8PtG/fHp9++mmtb6kVBAFLly5Fu3btIJfLERISgkuXLlW7fVhYGBQKhc7DyckJJiYmyMjIAAC95xUKBWxsbBAUFFTn44rFYMFi3bp1ePvtt2FlZQWpVHrfbUtLSzF06FAoFArExcXh4sWLiI6OxvTp0xupWiIiaq5Wr14NT09PrFu3Tu+5GTNmICUlBWlpafjtt9/w/fff4+OPP67V/j/55BOsW7cOkZGRSElJwRNPPIEhQ4YgNze3yu03b96MlJQUnccTTzyB559/Hm5ubgCg93xiYiLkcjneeeedOh9XNEIT4O3tLaxbt67a5zds2CA4ODgIKpVK23bq1CnBzMxMyMrKqvFx8vLyBABCXl5efcolIqLbiouLhUuXLgnFxcXaNo1GIxSqyhr9odFoal1/ZmamYGtrK2zdulXw8fHR2cfAgQOF+fPn62z/xRdfCD169Kjx/ouKigQbGxvh999/12nv1KmT8PXXX9doHxcuXBBsbGyE5OTkarf59ttvhS5dughqtbpex63q51mppp+hRnG7aWRkJB577DGdCTt69OgBR0dHREREYMyYMVW+TqVS6VwuUSqVota1+2IGwvfGItjHAR8/2VHUfRMRGaviMjXaf7i70Y976aPHYGVWu4+19evXY8iQIRgxYgQmTZqEiIgIDBkypNrtCwsLYWlpWeP9nzx5EgUFBQgNDdVpHzlyJHbu3Im33377gft4//33MXnyZCgUiiqfLykpwcKFC/H9999r7+oQ47h1ZRSDN9PS0uDh4aHXLpfLkZqaWu3rFi9eDDs7O+3D09NT1LryissQk5GPlFucbY6IyBitXr0aL730EkxNTfHCCy9gzZo1VW5XXl6O3bt34+uvv8YLL7wAoOID38fHp9qHWq1GWloaHBwc9OaEeNDnV6WLFy9i165dmDFjRrXbrF27Fk5OTjohor7HrQ+j6LGQyWRV3lv7oNnd5syZo/PDUCqVoocLIiLSZSmT4tJHjxnkuLVx4MAB5ObmYsSIEQCACRMmoGfPnsjJyYGDgwMAYNmyZdqbC7y8vPDVV1/hpZdeAgAsWrQIixYtuu8x6vr5Vemzzz7Dc889V+Uf1wCgVquxdOlSzJ8/X2ef9T1ufRhFsFAoFEhLS9NrT09Ph1wur/Z15ubmMDc3b8jSiIjoHhKJpNaXJAxh9erVyMvLg5OTk7atvLwcGzZswNSpUwEA06ZNw4IFC6p8/Zw5c7Bhw4Zq93/9+nUoFApkZ2ejtLRU53L+gz6/AODmzZvYtGkTdu+u/rLSzp07kZWVhbCwMJ32+hy3voziUsiwYcOwZ88elJeXa9tiYmKQmZmJwYMHG7AyIiIyRrdu3cLvv/+Ow4cPIzc3V/v48ssvq70ccq/Fixfr3Z1x90MqlaJ79+5wdnbGrl27dF67b98+DB8+/L77/+mnn+Dm5oYBAwZUu82aNWvwzDPPwNraWqe9PsetL6MIFqGhoXBxccEHH3wAtVqNvLw8vPnmm3j55Zd1kiYREVFN/PTTT/D29kaPHj102seOHYvLly/jxIkTohxHJpNh2rRpmDdvnnYOipUrVyIxMRH/+c9/7vvaX3/9FSNGjKj28kV+fj527NihN0CzvsetryYZLFJSUqBQKLB582YAgKmpKXbt2oVLly7B09MTHTp0QKdOnfD1118buFIiIjJGq1ev1g7CvJuLiwuGDh2K1atXi3as9957D6NHj0afPn3g4eGB33//Hfv27UPr1q0BAEePHoVCocDRo0e1r8nOzsaJEyfue4fK3r17UVZWhkceeaROx20oEkEQhAY9QhOiVCphZ2eHvLw82Nra1nt/m04lY9bv5zConTPWvdxLhAqJiIxLSUkJEhIS4OvrW+fVMKnpuN/Ps6afoU2yx4KIiIiME4MFERERiYbBgoiIiETDYEFERESiYbAgIqJ6a0H3ATRrYvwcGSyIiKjOZDIZAKCoiGsmNQeVP8fKn2tdNP05V4mIqMmSSqWwt7dHZmYmAMDKyqpR1qMgcQmCgKKiImRmZsLe3h5Sae3WXbkbgwUREdWLm5sbAGjDBRkve3t77c+zrhgsiIioXiQSCdzd3eHi4oKysjJDl0N1JJPJ6tVTUYnBgoiIRCGVSkX5YCLjxsGbREREJBoGCyIiIhINgwURERGJhsGCiIiIRMNgQURERKJhsCAiIiLRMFgYGY1GwLrDCVgRedXQpRAREenhPBZGpEBVjum/ncHeSzcAAKN7esLF1sLAVREREd3BYGEkbihL8NLaE4jJyNe2lao1BqyIiIhIHy+FGIHknCKEfXcUMRn5cLYxh9SEC/wQEVHTxGDRxCXnFGH0qqNIyimCp4Mltrz2MGRSBgsiImqaeCmkCbtZoMKLa08gPa8EbZytsfGVPnCz45gKIiJquhgsmqii0nJM+OEUErILIbe3xM+T+sCVAzWJiKiJ46WQJkgQBMzZch5nk3NhbyXDDxN6MVQQEZFRYLBogn49mYytZ9IgNZHgf//pCX+XVoYuiYiIqEYYLJqYS2lKzP/rIgDg3cfaoZevg4ErIiIiqjkGiyakTK3BO5vPorRcg0HtnDG5v5+hSyIiIqoVBosmZN3hBFxOV8LeSoYvwrrAhPNVEBGRkWGwaCJSbhUhfG/F+h9zhgfCsZW5gSsiIiKqPQaLJmLh35dQXKZGsE9rhPXwNHQ5REREdcJg0QScTMzB3ks3IDWRYNFTnXgJhIiIjBaDhYEJgoDPd8UAAEb3VCDA1aZO+9l5Ph2Phh/A4bhsMcvTodEI+Pl4EgZ/+Q9+O5nUYMchIiLjxWBhYMcTcnAy8RbMTE0wdXBAnfax99INvPXLacTeKNAuqS628yl5eOq/hzH3/84jPqsQ289n6DyfV1SGjLySBjk2EREZD07pbWAr98cBqOitqMs6IIfjsvHGxn9RrhHELg1ARWBYuicGG48nQajiECVlaqyJSsB/98ehTCPgxNzBsLcya5BaiIio6WOPhQHFZChx6Go2pCYSTBnQptavv3qjAK9uiEapWgNz09r/KI9fu4n/rDmOI9VcPvnnSiYeXXYAPx2rCBVPdvXAe8MCAVRcwtlxPh1DvjqApbuvoLBUjdJyDbLyVQAq5uSIvZEPoao0QkREzRZ7LAzox6PXAQCPtneFp4NVrV8/4YeTEASgl48DunnZY9XBazV+7U/HrmPBXxdRrhHg1MocD/s7aZ8rUJVj0fbL+OVExTgKXydrLHqqIx5u44Q/olMAAIeuZuPQ1YpA4mZrgZzCUpSqNRBQcWlm8c7LuJZViEVPdcQLvb21+y5UleO3k8mwNpdiTLBXrd8zERE1bQwWBqIsKcP//ZsKAHjpYZ9avbZcXdELIAiAt6MVvvtPD6w7nFCj15apNVj490X8dOzO4EvNXb0KF1Lz8PrGf5GUUwQAeLmvD2Y9FghLM6nevsxNTTBlYBu8OtAP/T7bj5zCUrz9y2nEZORrt0m9VQyg4pLJT8eu49t/4nGzsBQmEuDxLvIq90tERMaLwcJAtp9LR3GZGv4urdC7luuB3D2eYs1LwXCwrtmYhqLSckzZEI1DV7MhkQBBbra4lK4EUHFpY+PxJHz09yWUqjWQ21tiaVhnPNzGSWcfXTzt4Gxjju5e9vhgZHsoWuv2tMRk5MPM1ARuthZIyilCmVqDDUcT8U1kHDJvXyYBAI0AlGk0sASDBRFRc8JgYSC/376k8GwPBSSS2s1b4WFngbS8Eiwb07XGK5/mFZXh5fUn8G9SLqzMpPj6uW5IyinCpW2XUFSqxtRfz+Cvs2kAgCFBLvgyrCvsrGR6+/F3scHJ94fo12RfcTnkia4eePexdlgblYi1hxOwJioBlTlIbm+J10LaYN6fF2r1fomIyHgwWBhAYnYhoq/fgokEeKqbvNavXz+hF5TFZejpU7OejkxlCV5cewIxGfmws5Rh3cvB6O7VGmuiKi6fVN6iKjWRYPawQLzS37fWYeenib2hLC6Hl6NuD4ZGAJxameHtwW0xJtgTEkgYLIiImjEGCwPYfj4dANDX3wmutrW/xbQ2k2hlKksw5n/HkJBdCGcbc2yY2AuBbrZ62zlam+HbcT3qvEy7vZWZzm2mjwS6YP+VTIR2cserIW3QyrziV620XFOn/Yslv6QMNhb6PTFERCQOBgsD2HWhYnKp4R3dG/Q4NwtUeGH1cSRkF0Jub4mfJ/WGt6O19nm326Em0M0G37/Ys053plSnX1sn7J8ZItr+6qO4VI2/z6bhp+PXcS4lD58/2xmje3I9FiKihsBg0ciSc4pwPjUPJhLg0Q6uDXac/JIyvLj2BK5mFsDN1gK/TOqjd5liRCc3/P1mP7R1bQULWdMeRJlyqwil5Rr4OeuOKVGVq3Ey4Ra6e9vDykz31zkuswAbj1/HH9EpUJaUa9svpSkbpWYiopaIwaKRRVyuGM8Q7OMApwZaGr1MrcHrG//FxTQlHK3N8NMrvfVCBQBIJBJ0Utg1SA1iScwuxPLIq/jzdCqkJhKcmjcUdpYy5JeU4efjSVgTlYDMfBXG9fHCJ092glojYM/FDPx49DqOXrup3Y+ngyVaW5nhXEoe1h9JRGeFHZ7urgAAZBeo8OfpVFiaSXXm3CgpU+PqjQJ08LDlwnBERDXEYNHI/onNAlAxBqEhCIKAef93AYeuZsNSJsX6l3vV+M6RpuT6zUJ8ExmH/zudCvXt20o0agFxmQWIjLmBH49eR/5dvRDJOcVYdzgBaw8nIDmnYu4MEwnwSKArXujjhYFtnfHff+JwLiUPABBxORMuNhb45UQS9lzKQNntuUGGd3RHWm4xNp1KxtYzacgrLsO80CC80t+vkc8AEZFxYrBoRCVlahy7/Vf0wHbODXKM7efTkV1QMQHViue7NekeiaSbRego160vLbcYy/bF4o9/7wSKQe2csf9KRSB75tsj2m39nK3h59QK+y7fwIHYLBy4HdpaW8nwQm9vjO3tBbm9pXb7sb28sP5IIrILSrH9fLp2EO3dnvn2CBKyC3XafjiaiDHBnjqDPgtU5RAEgQNBiYjuwbVCGtGJhByUlGngZmuBdnVcHv1BsgtKAQAfjmyPwUENN4ZDDCO/iUJuUUW9+SVlWLo7BoO++AebTqVArREQ0s4Z//f6w1j3ci9Y3zVDZxdPe3w3rgf2TR+oM07F18kanzzZEUdmD8bMx9rphAoAcGxljulD76wga2Nuihcf8saOt/vD9PaljoTsQpiZmmBUFw8Muh3+knOK8eWeWJSrNYiMuYHXN0aj+0d7MeiLA1CVq6t9f4IgcK0UImpx2GPRiI7EV/RW9G/rVOt5Imrj6e7yWk8T3likJhJYm0lRWFrxgZyVr8Lf59KxbG8sbhZWhIxevg6YPTwQ3b1aa183oZ8vLqUpMaGfLx5u46g9f8M6uiHlVjE6ye0wONDlgWMhhnd0x9UbBWjvYYuRnd21Az5HB3viSkY+nuzqgce7yGFnJcNfZ9O0PSV7LmZg27l0ZBfcmT00u0AFZXE5nG3uhB5VuRr/XMnCn6dTERGTibHBnlj4REfkFJZi14UMbD+fhvyScmyY0LvKCciIiIwdg0UjOpFQESx6+zmKvu/KeSLau9vi06c6NWhwqQ+piQQbJ/XBkysPAwBeXHsC6XklAAA/J2vMHh6Ioe1d9ep/59F2Ve7P1kKGGXf1QjyIg7UZFjzeQa/906c66bU93sUD17ML8eXeWKTdrtHR2gxPdJVj7V1rs2g0Ak5dv4U/z6Ri+7l05BWXaZ/bfj4DCTeLcDguW3tpBwC+P3QN7zwa0GR/TkREdcVg0UiKS9XagYO1XRukJp4L9oKlmRQjOrk3+VtHu3raw9bCFMqScqTnlaC1lQzThgTg+d5ekEmb1tW5QYEu2BydgvbutnimhwIh7Zwhk5pog8WXe64gKi4bKbcXWwMAV1tztHe3xf4rWcguUOHg7bEfHTxscf1mEQpU5VixPw49fCp6ZE4m5OC5YK8q79whIjI2DBaN5HTSLZRrBLjbWUDR2vLBL6glOysZXnzIR/T9NhRPBytcTlfihd7eeOfRAJ1ZO5uSjnI7HJw1qNrnfz2ZDKCix2h4Rzc82U2OPn6OyMwvwRMrDsPeSoZRnT0Q2tkdfs6tMHPzWe06Ma/8cErbi5GRV4IvR3fR6cEoKVPjQGwWikvVeKKrB3s3iMgoMFg0kpOJtwBUjB/gBwTw86Q+KC5Vw82u9lOaNwVtnK2RkF2IAQHOeLaHAkOCXHV6itztLHGiisXaPn+mMzLyShB1+9KIiaRiPZUtp1PhYW+JNwb5458rmdh+Ph2RMZkouj0WJa+4DJZmUjzR1QPmpk27R4qIWjYGi0ZyNiUXANDN096gdTQVdpYy2Fka7+DFv97sh3K1UOsBmCYmEswa1g6dL9ihf1tnJN4sxJwt5wEAPx5NxJqoBBSX6d9pMv+viwAAUxOJdmIvIqKmiMGiEQiCoB1f0Ulhb9hiSBTW5nX/p9NZYY/Ot38Pevs6IPr6Lfx+17TjitaWGNHJHSM6uWPR9kva3i4AKFSVV7VLIqImg8GiEaTnlSC7QAVTEwk6eOivLEotV2UPRlFpOTwdrBDayR2d5Hbay2X/faEHErIL8b+D17Dv9nTwRERNGYNFIzh3+zJIgKtNk79jgxqfi40F/vtCjyqfc7Yxh7ONOdYfSajyeSKipqZp3dvXTFVeBunchKfXJiIiEgODRSO4kpEPAGjPyyBERNTM8VJII7hyoyJYNNT6IESpucUwk5rA2cYcAFCu1kBZUg4H66YzP4hGI+BSuhKHrmYjKi4Ll9PzMW1IW6Oaf4WIHsygwWL9+vX44osvkJubC3d3d4SHh6Nfv35VbhsREYGPPvoI8fHxkEql6N27NxYvXow2bdo0ctW1U6gq187KGMBgQSJKzyvG9nPp+PNMKi6kKmFvJcOyMV2x++IN7LyQDmVxGZY91w0WpiYYEOBskPE9qbnFiLqahUNXs3Ek/iZybq8HU+nDrReRcqsYc0cE1ftYypIynErMwfFrOTiekIOrN/Lxcl9fTB8aAOkD1pAhIvEYLFhs2LABc+bMQWRkJIKCgrB582aEhobi9OnT8PPz09n233//RWhoKDZs2ICwsDCoVCrMnj0bISEhiI2NhaWl+DNZiuVqZgGAikF4rZvQX49knHIKy7Dh2HX8fTYNJxNzcPfiqblFZRi/7qTO9m//choAMDjQBd+O6wEz04qrn6m5xdhzMQO7L2ZArRHw/Ys9cTo5F3sv3cD5lDx8MLI9et0z9XxxqRpHr2XDQibFw22cqqwvv6QMR+NvIiouG1FXs3HtniXorc2k6OPnCAszKbafq1i2/tDVbMRkKOFqY1GrfyM5haU4kZCDEwk5OJ5wE5fSlbh3MdkV++Pwy4kk/P1WP3jYW0JVrobMxOSBi9URUd0ZLFgsXLgQM2fORFBQxV8qYWFh+PHHH7FixQp89dVXOtvu3bsX7du3R1hYGADA3NwcCxYswLJly3D58mV079690euvqdgMXgYh8YTvi9X5PtinNYZ3dMdH2y4BAGwtTBHa2R37Y7KQoSzRbhcRk4kpG06hp48Ddl/M0A4ortT1o7063++6kIFevg64oSxBxOVMRFy+gai4bKjKNTCRAIfeewRye0sIgoC4zAJExmRi/5VMnEqsmLq+komkYpn7/v5O6NfWGd287CGTmkAQBHTztMcn2y/jcroSw5YdAgBM7OcLp1bmmDLADxpBgOlda8dk5pfg+LU7QSL2RoHe+fF1skYvHwdYmkmx/kgiAOBmYSkeXhKJ7l72OJOcC40AzBrWDqYmEkzs58feDCKRGSRYJCUlIT4+HqNGjdJpHzVqFMLDw/WCRY8ePfDxxx8jJiYGgYGBAIDt27fDxcUFAQHVr2ypUqmgUt1Z5lqpVIr4Lqq2ZGcMSsrU2hU0K8dX8DII1Ye12Z1/qp3kdni8S8X6Ix72Fb11D/s7IreoDD29W8NUaoKbBSocupqNG8oSLN4ZAwDYfyVLuwy8RAIEezvgRGKOdr9uthawNpciPqsQR+Kz8fiKKL0AAlRMQb7jXDqScoqw/0qmzgJsAODjaIV+bZ3Qz98ZD7VxrHKGVYlEgn5t9Xs91kRV3Fb72a6KmmcPD0RabjGOxN9EXKZ+kGjr0gq9/RzQ29cRvXwd4Gp7Z4r4KQP98NDiSO33/yblar/+fNcVAMCXe2Kx5fWHkZBdiFOJtxB7Ix8vPuSDYR3d9I5FRDVjkGCRlpYGAPDw8NBpl8vlSE1N1dt+yJAh+PrrrzFixAiEhIQgMzMTZmZmOHToEFq1alXtcRYvXoyFCxeKW/x95JeU4bsD8QCAtx7xh2Mrc8RnVfxn2Na1+jqJHmTmY+3QxdMeff2d4Otkrfd8oJvuHUeOrczxZDc5AMDK3BQf/HkBADAwwBnDOrphSJArnG3McTguG6eTbmFAgDM6ye3wxZ4rWLk/HjG3e9okEqCLwh5DglwwpL0rXlxzApn5KizacVl7LDNTE/Txc8Qj7ZwR0s4FPlXUV5VAN1v8/upDkEiA8L1XkZpbjIR7Lp0suR2KKmsJcrO9HSQcEOzjAMdW5tXu393OEtc+HYGPt19CkUqNYF8HbDqZjPisAty8PdZDVa5B6PIondcVl6lhaSbF6aRbaO9ui4HtnCGVSHR6T4ioegYJFjJZxV8wJia6/1CrW5xLrVYjKSkJbm5uCA4ORnp6On7++WccOHDgvj0Wc+bMwYwZM7TfK5VKeHp6ivAOqpZXXKb92vT2e7t+swgA4ONYs/9siariamuBcX286/Ta//TxRk/v1vCwt9TrPejr74S+/nd6Doa2d8PeSzfg7WiNoUGuGBToor3TBKgIyJn5KnjYWWBQoAsGtXPBw/6OsDKr238lPX0qxnH89EpvAMCpxBz8m3QLB2KzcDjuJto4W6OvvxMebuOEPn4OtV4F18REgvmjOmi/f7ZHxTor8VkFeDT8oHZ12Q4etrC1kOHotZs4nZSLl9aeuLOP2wvFvdLPF7GZBcgpVCF8dFe0ZS8kUZUMEiwUiop/3GlpafD399e2p6enQy6X623/2WefYceOHThy5Ig2lEyYMAGdO3dGQEAABg4cWOVxzM3NYW5e/V80YlMW37WOg6Tilr/knIpg4e1o1Wh1EN0ryL1mc6h09bTHnulV/3sCgDUvBSMrXwVFa8sGWaW3p48Devo4YPKANigpUzfYnSxtnFvh0keP4eqNAvg4WaOVuSkupysx/OuKsR5uthbaMSqVQ0ZWR92Z/fTbf+KxNKwLx2cQVcEgwcLV1RVdu3bFjh078Pbbb2vb9+7di+HDh+ttHxUVhb59+2pDBQD4+PjA398fx48frzZYNDZlSZnO92m5JSjXCDAzNYGbrXEuD050NwuZFJ4OjROSG/r2WHNTKTrK78yGG+Rui6j3BsFMagIXWwtEX89BYnYRDsdl40xKLjp62CE+qwAX05TYcjoV3bzs8R/OwUGkx2B3hcyaNQvvvvsuhg0bhoCAAGzduhU7d+5EdHS03raDBg3CV199hRdeeAHBwcFQq9VYu3YtLly4gMGDBxug+qopi3WDReLNiuvF3g5WvL2NyAgoWt8JTT28HdDD2wHP9LizTP0f0Sl4Z/NZAEBCdlGj10dkDAwWLMaOHQulUomRI0eioKAACoUC27Ztg7+/P1JSUtCnTx+Eh4cjLCwM77zzDszMzDBx4kTcvHkTarUanTp1wq5du9CjR9WLNxlC5bLXla5XBguOryBqFp7poUBsZj5WHbiGtYcT8EigC0ylEgS62dR6/AdRc2XQmTenTJmCKVOm6LUrFAqkpKRovzcxMcHUqVMxderUxiyv1u7tsbgzcJPjK4iaCxvzO/9tjltzHAAwqJ0zvn+xJ2Iy8nEqMQenrt+C1ESCz5/tDHNTrmhMLQvXChHRvWMsEm8HC+8a3n5HRE3fmGAv7L54A+dT78zxcTjuJros3IPCUrXOtmE9PKucr4OoOWOwEJHOXSEAUm5VBAtF66Y75TgR1Y6zjTn+erMv4rMKkXKrCOPXnUSpWoNSdUVvRnfv1jiXkotbRWX45WQSVh2Mx7mUPDzTXQE7SxlCO7vB34W3qlLzxWAhont7LNLzKm5X87BjsCBqTiQSCfxdWqGNszWWPN0JpWoNgn0cEOBqA6mJBKHLD+FWUZl2PRQAWHu44nbVmAwlvh3XdMaGEYmNwUJEd4+xKC5VayfMcrfnraZEzZFEIsFzvbz02scEe2LjsSQEutugpEyN3RdvwKmVObILVChQlVexJ6Lmg8FCRHf3WKTnVayf0MrcFLYW+mslEFHz9eJDPnjxnjku/u90Cqb/dtYwBRE1Ik5+L6K7x1hUXgZxs2NvBRERtRwMFiK6u8ciLbeix8KdwYKIiFoQXgoR0d1jLDI4cJOIqnDoajb6fBqBh9o44ti1m0jPK8GmKQ+hl6+DdhtBEFBcpq7z4m5EhsTfWpEIgqAz82blpRAO3CQiQPePjAxlCf7vdKr2+9GrjmLNSz1x/WYRTl3PwYmEW8guUGHRUx3xQu87q9qqNQJMJNWvBE3UFDBYiKSkTKPzfVoeL4UQ0R29fB3w8yu98favp+Hv0gq9fByw7Xw6rmVVTP0/8YdTeq95//8u4EpGPlqZm+JU4i2cTclFOzcbbHntYSRkF+LU9VtQFpdhaHtX5BSWopPCjjN9ksExWIjk3jksMrSDN3kphIgqehke9nfCqXlDtW0zHm2H0d8dxYnEHFjITPCQnyN6+jggLrNA26Px49HrOvs5l5IH//d36rQt3hmj/XpsL084tTJHL18H9PN3gkQigapcjQupSpxOuoX8knJMGegHKzNTCIKA1NxinE7KxemkXERfz0G+qhxfj+mGTgo7ENUFg4VIiu6Zyje7QAUAcLExN0Q5RGQkfpjQC+l5xfBxtNauglxUWg5nG3P87+A1+DpZo4d3a/Twbo05W85rX2cpk6K4TK23v19OJOt8383LHhdTlShV3+lV3X4+Hb5O1jidlKv9v+puo1ZEAQCeC/ZEam4xRnX2QHx2AZJzijCpvx+6ebUW5b1T88RgIZKSe/6Bl6kFAIBTKwYLIqqepZkUfs6tdNqszEwxd0QQ5o4I0mn3dbJG7I18dPW0R5C7LQAgPqsAjtbmWB11DasOXIOzjTmy8u+EhdNJuQAAR2sz3CwsBQDEZRYgLrMAAGBqIkF7D1t087THzyeStP93AcCvJytCyqGr2dq2Hecz4OlgCedW5vj82c6cnpz0MFiIpKq/HCQSoLUVJ8ciInH08XNEHz9HnbZAt4qAMWd4EOYMrwgieUVl+O8/cSgqVaOblz16eLeGl4MVIi5nInxfLHwcrdHNyx7dvOzRwcMOFrKKcRkLn+iI5JwifLL9EtLzSnAlIx+qcg3au9siJkMJze3MkZxTjOScYkz+MRqRM0Ma7f2TcWCwEMm9PRYA4GBlBlMppwohosZlZyXDnHt6OwBgSHtXDGnvet/XejpYYdV/emq/FwQBEokEeUVlCN8XC3NTE6w6eA0AkFXFZRQiBguRVBUsHFuZGaASIiLxVN7aamclw4LHOwAARgd7YvCXB2AikUAQBCTlFMFCJoWrLe+CIwYL0dx7uykAOFpzfAURNV/5JWXo/vFe3CqquCtu17T+2ksz1HKxn14kxaX6PRZOvCOEiJqhVuamkEgAjQBtqACAYcsOYeDS/bjJSyQtGoOFSKoavOlozUshRNT8uNpa4NsXuuOjJzpg6xt9MbKzu/a56zeL0OOTffgm4iqXiG+heClEJFWNsXDiGAsiaqaGdbwTJlY83x1TB+djaPhBbduXe2Px/aFrGNbRDWOCPdHD26Gq3VAzxB4LkVQdLHgphIhahrauNjgy+xGEdroTOJQl5dh0KgUrIuMMWBk1NgYLkVQ5eJPBgohaEA97S6x8oTu2v90PPb1bayfx2n8lCzEZSgNXR42FwUIkVY6x4KUQImqBOnjY4ffXHsYbg9po2z7484IBK6LGxGAhkirnseDgTSJqwQYEOMP+9uzDecVlD9iamgsGC5FU1WNhZ8npvImo5bK1kOG/z3cHABSq1PjhSCKm/3YGK/dzzEVzxrtCRKKqYoyFjQWDBRERAKTmFmP+Xxe134/t5QUH9uo2S+yxEElVPRbS20sgExG1VIHutnC2MYe9lQyD2jlr27/YcwWCINznlWSs2GMhkntn3rSx4KklInKwNsOJuYMBVKw70uHDXSgsVePn40n4+XgS3h8RhCe6esCF64w0G+yxEElJuW6w4PgKIqIKEolEu5jZl6O76jy3aMdl9Po0Akt3x6C0XP+SMhkfBguR3NtjwWBBRKRvWEc3bHurH7p72eu0r9wfj5+OXUd6XjEEQUChqhyCIECt4eUSY8P+epGo7knathy4SURUpY5yO2x5vS8A4LeTSXjvj/MAgI+2XcJH2y7pbGshM0FbFxv8+UZfjlszEgwWImGPBRFR7Y0J9kKBSo2P7wkUlUrKNDifmodei/bBzkqGD0a2h0YjYGCAM0yl7HRvihgsRMIxFkREdfNCby+0cbaGi40Frt8shLW5KbILVFBrBLz7+zkAwM3CUtwsLMXL604CAL4Z2w2jungYsmyqBoOFSO7tsbC15KklIqoJC5kUIe1cAADtPWx1nmttZYbzqXn48WgibhXdmb0zLbe4UWukmuOnnwg0gv4YC/ZYEBHV35D2rhjS3hXThrTFraIyzP/rIv4+m4bFO2Pg79IKg4NcDV0i3YMXqESgKud03kREDUkikcDB2gz+zq20baeu3zJgRVQdBgsRFFcxnbctgwURkejefMQfIXfN4ElND4OFCFS3p/OW3HUnFIMFEZH4pCYS+DlV9FocjM1CUWm5gSuiezFYiKBynRBLmVTbxkshREQN62KaEt/9E2/oMugeDBYiKLkdLCzuChb2DBZERA1iSJCL9uvopFtczKyJ4V0hIqic397KTIoBbT1QUqaBr5O1gasiImqeHvZ3wqxh7fD5ris4HHcTfnN3oJ+/E0rLNXhveCC6e7U2dIktGoOFCMrVFWlZJjXBsue6GbgaIqLmr7PcXvu1IACHrmYDAJ7+7xFM7OeLYR3dYG5qgs4K+6p3QA2Gl0JEUKap6LHgPPZERI2jX1snHJo1CP3bOuHR9rpzWayJSkDYd0fx+IrDOJGQY6AKWy72WIigcvU9UwYLIqJG4+lghQ0Te2u/j4y5gQnrT+lsM3rVUeya1h+Bbrb3vpwaCHssRFB216UQIiIyjEcCXRHz8TAcnfMIxvby0rbHZxYasKqWh5+EIjKVsseCiMiQLGRSuNtZYvHTndDNy97Q5bRIDBYi4qUQIqKmw4y9yAbBsy4iUxOeTiIiatn4SSgiXgohImp6rtzI5yRajYjBQkQcvElE1PQsj7iKf2KzDF1Gi8FPQhFxjAURUdMxIODOKqhJN4sMWEnLwmAhIl4KISJqOt4Y5I8RndwAAPP/uojo65wsqzFwgiwRcfAmEVHT4mFnqf361xPJyFSq4GFviQ4etjDl5esGwWAhIvZYEBE1LdOHBmD/lUzEZxVic3QKNkenAAC6ednjl0l9dFalJnEwrolIxh4LIqImxdrcFBP7+em1n07KxZQN0QaoqPljj4WIpOyxICJqcp7v7YUh7V3Q2soM6bklGLB0PwAgPqtAu40gCEjOKUapWgNFa0v2ZNQDg4WIZLwrhIioSXKxsQAAeDla4Y/XHsIz3x5Fyq1iDFt2EF4OVvg3KRfZBSrt9lvf6IsunvYGqta4se9eRBwIRETU9Fmb3/mbOiYjH3su3dAJFQDwzuazOH7tJsrUmsYuz+ixx0JEHLxJRNT0tXO1wdwRgfh0Rwwebe+Knj6t0d2rNTp42GHM/47iXEoe4jILMOZ/xwAANhameGOQP14d2MbAlRsHg/6JvX79enTs2BEKhQLBwcGIioq67/bffPMNAgICIJfL0b59e6xfv75xCq0hTpBFRNT0SSQSTB7QBolLQvG/F3ti8oA26OnjAEszKd4c5K+3fX5JOXZfzMCVjHwUqMoNULFxMViPxYYNGzBnzhxERkYiKCgImzdvRmhoKE6fPg0/P/0RvEuXLsW6deuwe/du+Pr64sSJExgzZgyGDBkChUJhgHegj/NYEBEZt0c7uCFxSSjyisuw6WQyEm8WYuPxJJxOysVjyw4CAPbNGAB/FxsDV9p0GeyTcOHChZg5cyaCgoIAAGFhYRgwYABWrFiht61SqcTChQuxcuVK+Pr6AgB69eqFuLi4JhMqAEDGSyFERM2CnaUMkwb4YWwvL73nhnx1ED6zt2POlvPQaLi42b0MEiySkpIQHx+PUaNG6bSPGjUKO3fu1Ns+MjISZmZmCAkJ0WmXSu9/O5BKpYJSqdR5NCQO3iQial46yu2wa1p/7J42AH39HXWe++VEEnp9ug//dzoF5RzkqWWQT8K0tDQAgIeHh067XC5Hamqq3vZxcXEIDAzEH3/8gZ49e8LHxwehoaE4d+7cfY+zePFi2NnZaR+enp7ivYkqcIwFEVHzE+hmi3ZuNtj4Sh9sf7sfxj/so30uu6AU0387i4iYTMMV2MQYJFjIZLKKg98zJkEiqfqDWa1W48qVK/jrr7+wb98+xMbGYtCgQejfvz9SUlKqPc6cOXOQl5enfSQnJ4v3JqrAYEFE1Lx18LDDgsc74Jux3XTabxWWGqiipscgwaJyXERlz0Wl9PR0yOVyve29vLygUqmwevVq2Nvbw8zMDDNnzoSHhwe2bt1a7XHMzc1ha2ur82hIvBRCRNQyjOrigcQloRgS5AIAWHXwGpQlZQauqmkwyCehq6srunbtih07dui07927F8OHD9fb/qGHHoKJiQnKy/Vv8zE3N2+wOmuLgzeJiFoW6e2e6oTsQmyJrr4HvSUx2J/Ys2bNwueff47Y2FgAwNatW7Fz5068/vrretv6+Phg9OjRmDBhAvLz86HRaLBs2TJkZ2fj8ccfb+zSq8XbTYmIWpaX+/pqv+YcFxUMNo/F2LFjoVQqMXLkSBQUFEChUGDbtm3w9/dHSkoK+vTpg/DwcISFhQEAVqxYgdmzZ6Ndu3YQBAEdOnRAREQEXFxcDPUW9HDmTSKilqWPnyOeC/bEryeTcfTaTRyJvwlnG3O89Yh/i53rwqBTek+ZMgVTpkzRa1coFHqDMi0sLLBs2TIsW7askaqrPfZYEBG1PJX3HRyOu6ltS71VjN+mPKS9VNKScK0QEbHHgoio5Qnt5IHTSbkwl0lxNjkXAHDq+i20mVsxjrCLwg6+TtYIH9O12rsfmxMGCxFx8CYRUcvTr60Tdk0bAACIy8zHkK8O6jx/NiUPZ1Py8PogfwS4Nv/LIwwWIpLyUggRUYvm72KD8wseRXZBKdYfToCp1ARrohIAAI+GH0RvXwf8MKEXLGT3nznamNXpk/DkyZPo3bs3rKysIJVKdR4tmawFXksjIiJdNhYy+DpZY+ETHfHByPZ4uM2dqcCPJ+Rg98UMA1bX8OrUYzFx4kSEhITgk08+gZmZmdg1GS1OkEVERPfa+EpvnE3Jw5MrDwMApv56Br5O1uissDdsYQ2kTsEiOzsby5cvF7sWo8fBm0REdC+JRIKunvb4Tx9vbDh2HQCw5d9UdPSwg0kz7Omu05/YgYGBSExMFLkU4yfjGAsiIqrGx092RC8fBwDA+iOJ2HmheV4SqVOPxdtvv42RI0di3rx5eiuUDhgwQJTCjFFLvF+ZiIhqLrSzO04k5gAAknKKDFxNw6hTsHj66acBAM8//7xOu0QigVqtrn9VRoq3mxIR0f289LAPzqXk4Y9/m++6InUKFhqNRuw6mgUO3iQiogepnCOrpKx5/iHOeSxEZMpLIUREVENfR1zFltMpGNHJHZ6trfBoe1e42FoYuqx6q/Of2GvXrkVgYCAsLCwQEBCAVatWiVmXUeJdIURE9CBtXVppv07OKcaqA9cw788L6PVpBC6m5RmwMnHUKVhs2rQJ7733HiZPnowtW7bgtddew4cffoiNGzeKXZ9R4SJkRET0IJMH+GH1iz3hbGOu99zbv5w2QEXiqtOlkCVLlmDPnj3o1q0bAGDEiBEYPHgw/vOf/+CFF14QtUBjwsGbRET0IBKJBEPau2JIe1cAgKpcjRFfH0J8ViFuFZUZuLr6q9Of2FlZWdpQUalz587IyckRpShjxcGbRERUW+amUvz3hR4AgJzCUsRkKA1cUf3U6ZPQ0dERZ8+e1Wk7f/48WrduLUpRxoqDN4mIqC7uXk192LJD+PtsmuGKqac6XQqZPXs2hg4dirlz5yIwMBCxsbFYvHgxli5dKnZ9RoXBgoiI6qKNcyv09nXA8YSKnv+3fjmNQlU54rMKoCrXYPbwQFiZGceNnHWq8rnnnkN+fj6WLl2KxMREeHl54YMPPsC4cePErs+ocOZNIiKqC6mJBL9NeQjf/hOPz3bFAABmbzmvff7qjQKYSiVwtDbDYx3cMCjQpckuvV7n+DNp0iRMmjRJzFqMmkwqgUTCYEFERHX3WkgbHLqahRMJOQhyt8X51IrbT49eu6nd5s8zFZdJvn+xJ4beHgDalNQ4WKSlpemtC0J3sLeCiIjE8POkPihTayCTmmDTyWQsj7wKiaRizou7TfrxFL4Z2w2jujStz+YaB4s+ffogKSkJAGBiYlLtX+ctda0QrmxKRERikd2+y3B0sCdGB3tq20vLNZj662ntyqif7Yox3mCxadMm7df79+9vkGKMGWfdJCKihmZmaoKVz3fHzM1nseV0KlJuFaNAVY5W5k1nYGeteiwqDRw4sEGKMWacw4KIiBqDiYkEE/v7YsvpVABAx/m78e5j7fDGIH8DV1ahTp+Gx44dw759+wBUjL0YMWIE+vXrhzNnzohZm1GRcYwFERE1Eh9Ha9jc1UuxdPcVnE66hd+jU/DriSSoNYLBaqtTsHjnnXegUqkAAG+++SbkcjnGjx+PyZMni1qcMZHyUggRETUSa3NTnFvwKL5+rqu27an/HsHMzWcxe8t5HLqaZbDa6hQsEhISEBoaiszMTBw5cgT//e9/8corryAtzXhnCqsvDt4kIqLGJJFI8HgXD3g7WgEALGVSWN6e20JZUm6wuuo02qN169b4559/8Ntvv2H06NGQyWRITEyETCYTuz6jwcGbRETU2CQSCf5+qx9u5JXA18kaL649gSPxNx/8wgZUp2CxdOlSPPfcc1AoFNi9ezcAYNmyZXjttddELc6YcMl0IiIyBFsLGWwtms4f9nUKFiNGjEBGRoZO2yeffAJra2tRijJGnCCLiIiaij+iU/BYB1eYmzb+tN+i/ZndqlWrFj2lNXMFEREZmsntz+EDsVnYcT7dIDXUuMeib9++OHz4MABg0KBB1YaIyMhIcSozMi05VBERUdMwro83ouKyAQC3CssMUkONg8Wzzz6r/TokJKQhajFq7LEgIiJDG9bRDY938cBfZw13l2aNg8X06dO1X8+fP79BijFm7LEgIiKq4xiL8vJyfP/99zptc+fORVFRkShFGSP2WBARUVPwVDc55oUGoZevg0GOX6dgMXfuXGzatAnl5RUTcKjVamRnZ2PWrFmiFmdMJGCyICIiwxsU6IJX+vuho9zOIMevU7DYvHkztmzZAlPTiispUqkU33zzDbZv3y5qccaEV0KIiIjqGCzKyspgY2Oj0yaTyVBaWipKUcaIwYKIiKiOwaJDhw74/PPPddo+++wzdOnSRZSijJEJkwUREVHdZt784osvMGDAAGzcuBFBQUG4cuUKrl+/rp3noiVisCAiIqpjj0WnTp1w/vx5hIWFwdbWFs8++yzOnz+PoKAgseszGswVREREdeyxAACFQoF58+ahrKysRa9qWonzWBAREdWxx0IQBISHh8PX1xceHh4AgOeeew4XLlwQtThjwlhBRERUx2DxySefYMOGDfj6669hZWUFAJg8eTJmzpwpanHGhBNkERER1TFY/PDDD9i9ezcef/xxSKUVS7I+8sgjuHz5sqjFGRMO3iQiIqpjsFCpVHB0dARQcVkEAEpLS6HRaMSrzMgwVxAREdUxWPTu3RvTp09HeXm5dtDiggUL0K9fP1GLMyYcvElERFTHu0K++uorDBw4EBs3bkRhYSHatm0LU1NT7N27V+z6jAZjBRERUR2DhZeXFy5evIgtW7YgNTUV/v7+CA0NhYWFhdj1GQ2OsSAiIqpjsJg5cya++OILjBs3Tux6jJZJnS4qERERNS91+jg8duwY0tLSxK7FqHHZdCIiojr2WPzwww+YP38+HnnkEfTp00d7yylQcZmkJeKVECIiojoGi7Zt2wIA1qxZo70bQhAESCQSqNVq8aozIrwrhIiIqI7BIiEhQew6jB5n3iQiIqpFsCgsLMRbb72Fbdu2wdLSEuPGjcPHH38ME45aBMC7QoiIiIBaBItPPvkEFy5cwHfffYeCggJ89NFHcHNzw1tvvdWQ9RkNxgoiIqJaBIstW7Zgz5498Pb2BlAxzuKdd95hsLiNYyyIiIhqcbtpUVGRNlQAQJ8+fXjL6V2YK4iIiGoRLO79i1wikXB8xV04eJOIiKgWl0JycnIwYcIEnbasrCy9trVr14pTmZHh4E0iIqJa9FiEhYVBEASdx7PPPqvXVhvr169Hx44doVAoEBwcjKioqBq9btq0aZBIJEhMTKzV8RoScwUREVEteizWrVsn6oE3bNiAOXPmIDIyEkFBQdi8eTNCQ0Nx+vRp+Pn5Vfu6PXv24J9//hG1FjFw8CYREVEd1woRw8KFCzFz5kwEBQUBqOgRGTBgAFasWFHta7KzszFhwgSsWrWqscqsMcYKIiIiAwWLpKQkxMfHY9SoUTrto0aNws6dO6t93YQJEzB69Gj07t27RsdRqVRQKpU6j4bCMRZEREQGChaVt6l6eHjotMvlcqSmplb5mm+//RYJCQlYvHhxjY+zePFi2NnZaR+enp51L/oBeFcIERGRgYKFTCarOPg9t6tWN07h8uXLmDt3Ln766SeYm5vX+Dhz5sxBXl6e9pGcnFz3oh+AYyyIiIjquAhZfSkUCgAVPRf+/v7a9vT0dMjlcp1ty8rK8Pzzz2Pu3Lno0qVLrY5jbm5eqyBSH8wVREREBuqxcHV1RdeuXbFjxw6d9r1792L48OE6bampqThz5gxmzZoFiUSifQCAr68v+vXr12h134+EwzeJiIgM02MBALNmzcK7776LYcOGISAgAFu3bsXOnTsRHR2ts52Pj0+V82NIJBIkJCTAx8enkSq+P46xICIiMmCwGDt2LJRKJUaOHImCggIoFAps27YN/v7+SElJQZ8+fRAeHo6wsDBDlVgrvBRCRERkwGABAFOmTMGUKVP02hUKBVJSUu772trO8tnQeLspERGRASfIam54VwgRERGDhWiYK4iIiBgsRMPBm0RERAwWouHtpkRERAwWomGPBREREYOFaDh4k4iIiMFCNMwVREREDBai4TwWREREDBaiYawgIiJisBCNCUdvEhERMViIhVdCiIiIGCxEw3ksiIiIGCxEwyshREREDBai4aUQIiIiBgvR8HZTIiIiBgvRcOZNIiIiBgvRMFYQERExWIiGgzeJiIgYLETDSyFEREQMFqJhjwURERGDhWjYY0FERMRgIRrmCiIiIgYL0XAeCyIiIgYL0TBWEBERMViIhj0WREREDBaiYa4gIiJisBAN7wohIiJisBAN57EgIiJisBANOyyIiIgYLETDwZtEREQMFqLhGAsiIiIGC9EwVhARETFYiIaXQoiIiBgsRMNcQURExGAhGt5uSkRExGAhIiYLIiIiBguRsMeCiIiIwUI0HLxJRETEYCEa5goiIiIGC9Gwx4KIiIjBQjzMFURERAwWYmGPBREREYOFaHhXCBEREYOFaCS8FkJERMRgIRb2WBARETFYiIfBgoiIiMFCLBy8SURExGAhGgYLIiIiBgvRMFcQERExWIiGgzeJiIgYLETEZEFERMRgIRL2WBARETFYiIaDN4mIiBgsRMNcQURExGAhGvZYEBERMVgQERGRiBgsRMIeCyIiIgYL0ZjwTBIRETFYiIXLphMRERk4WKxfvx4dO3aEQqFAcHAwoqKiqt02JSUFY8aMgaenJxQKBZ588kkkJiY2XrEPwHksiIiIDBgsNmzYgDlz5mDz5s1ISUnBrFmzEBoaimvXrultW1ZWhiFDhsDHxwfXrl3D9evX0bZtW4wYMQLl5eUGqF4fh1gQEREZMFgsXLgQM2fORFBQEAAgLCwMAwYMwIoVK/S2jYmJgbu7O5YsWQKZTAapVIoPP/wQly9fxqVLlxq79CpJmCyIiIgMEyySkpIQHx+PUaNG6bSPGjUKO3fu1Nu+U6dO2L9/v86H9/nz5wEANjY21R5HpVJBqVTqPBoK7wohIiIyULBIS0sDAHh4eOi0y+VypKamPvD10dHRCAsLw/jx4+Hr61vtdosXL4adnZ324enpWb/C74OxgoiIyEDBQiaTVRz8nns0a3I5Yfny5ejfvz/Gjx+P1atX33fbOXPmIC8vT/tITk6ue9EPwB4LIiIiwNQQB1UoFAAqei78/f217enp6ZDL5VW+RqPRYNKkSTh06BD279+P3r17P/A45ubmMDc3F6foB2CuICIiMlCPhaurK7p27YodO3botO/duxfDhw+v8jXvvvsuYmNjcerUqRqFisbGYEFERGSgHgsAmDVrFt59910MGzYMAQEB2Lp1K3bu3Ino6Gi9bY8fP44ff/wRMTExsLW1NUC1D8ZLIURERAYMFmPHjoVSqcTIkSNRUFAAhUKBbdu2wd/fHykpKejTpw/Cw8MRFhaGXbt2oaCgAF26dNHbz4wZMzBjxgwDvANdzBVERESARBAEwdBFNBalUgk7Ozvk5eWJ0vOx6VQyZv1+DgBwfO5guNpa1HufRERETVFNP0O5VohI2GFBRETEYCEazrxJRETEYFE/d11EYq4gIiJisKgXzV3DU3hXCBEREYNFvdw96pXLphMRETFY1MvdPRYSDt8kIiJisKiPu2/UlfBMEhERMVjUh6DTY0FEREQMFvWgO8aC0YKIiIjBoh40Gt4VQkREdDcGi3rQcB4LIiIiHQwW9XD3pRAGCyIiIgaLehF4uykREZEOBot6uPt2U06QRURExGBRL5zSm4iISBeDRT1w8CYREZEuBot6EO4avsll04mIiBgs6uXuMRZERETEYFEvApMFERGRDgaLetAwVxAREelgsKgHDXssiIiIdDBY1ANzBRERkS4Gi3rgGAsiIiJdDBb1wFhBRESki8GiHjjGgoiISBeDRT3wrhAiIiJdDBb1wA4LIiIiXQwW9cDBm0RERLoYLOqBsYKIiEgXg0U9aDjIgoiISAeDRT0wVxAREelisKgHgRdDiIiIdDBY1APHbhIREelisKgH3hVCRESki8GiHjjGgoiISBeDRT1wSm8iIiJdDBb1wFhBRESki8GiHjjGgoiISBeDRT0wVxAREelisKgHjrEgIiLSxWBRD8wVREREuhgs6oG3mxIREelisKgHDt4kIiLSxWBRD4wVREREuhgs6oGDN4mIiHQxWNQDcwUREZEuBot6YI8FERGRLgaLemCuICIi0sVgUQ8Ch28SERHpYLCoB43G0BUQERE1LQwW9cAeCyIiIl0MFvXAmTeJiIh0MVjUA2feJCIi0sVgUQ/MFURERLoYLOqB81gQERHpYrCoB8YKIiIiXQwW9cDBm0RERLoYLOqBgzeJiIh0MVjUA3MFERGRLoMGi/Xr16Njx45QKBQIDg5GVFRUtdumpqZizJgx8PHxgVwux/Tp06FSqRqxWn0cvElERKTLYMFiw4YNmDNnDjZv3oyUlBTMmjULoaGhuHbtmt62paWlGDp0KBQKBeLi4nDx4kVER0dj+vTpBqj8DuYKIiIiXQYLFgsXLsTMmTMRFBQEAAgLC8OAAQOwYsUKvW03bdqEGzduYPHixTA1NYW9vT3Cw8OxZs0aZGdnN3bpWuyxICIi0mWQYJGUlIT4+HiMGjVKp33UqFHYuXOn3vaRkZF47LHHYGZmpm3r0aMHHB0dERERUe1xVCoVlEqlzkNMzBVERES6DBIs0tLSAAAeHh467XK5HKmpqVVuf++299u+0uLFi2FnZ6d9eHp61rNyXS8+7A0AeLiNo6j7JSIiMlamhjioTCYDAJiY6OYaiURS7fb3bnu/7SvNmTMHM2bM0H6vVCpFDRcjO3sgyN0WXg5Wou2TiIjImBkkWCgUCgAVPRH+/v7a9vT0dMjl8iq3r+zluFt121cyNzeHubm5CBVXr41zqwbdPxERkTExyKUQV1dXdO3aFTt27NBp37t3L4YPH663/bBhw7Bnzx6Ul5dr22JiYpCZmYnBgwc3eL1ERERUMwa7K2TWrFn4/PPPERsbCwDYunUrdu7ciddff11v29DQULi4uOCDDz6AWq1GXl4e3nzzTbz88stwcnJq7NKJiIioGga5FAIAY8eOhVKpxMiRI1FQUACFQoFt27bB398fKSkp6NOnD8LDwxEWFgZTU1Ps2rULb7zxBjw9PWFiYoKwsDAsWbLEUOUTERFRFSRCC1rwQqlUws7ODnl5ebC1tTV0OUREREajpp+hXCuEiIiIRMNgQURERKJhsCAiIiLRMFgQERGRaBgsiIiISDQMFkRERCQaBgsiIiISDYMFERERiYbBgoiIiETDYEFERESiMdhaIYZQOXu5Uqk0cCVERETGpfKz80ErgbSoYJGfnw8A8PT0NHAlRERExik/Px92dnbVPt+iFiHTaDRIS0uDjY0NJBKJKPtUKpXw9PREcnIyFzYTAc+n+HhOxcXzKT6eU3E11PkUBAH5+fnw8PCAiUn1IylaVI+FiYkJFApFg+zb1taW/yBExPMpPp5TcfF8io/nVFwNcT7v11NRiYM3iYiISDQMFkRERCQaBot6Mjc3x/z582Fubm7oUpoFnk/x8ZyKi+dTfDyn4jL0+WxRgzeJiIioYbHHgoiIiETDYEFERESiYbAgIiIi0TBY1MD69evRsWNHKBQKBAcHIyoqqtptU1NTMWbMGPj4+EAul2P69OlQqVSNWG3TV5vzmZKSgjFjxsDT0xMKhQJPPvkkEhMTG69YI1Gbc3q3adOmQSKR8Jzeo7bn85tvvkFAQADkcjnat2+P9evXN06hRqQ25zQiIgIDBw6EQqGAt7c3Ro8ejfj4+EastmnTaDQ4duwYZsyYAQcHhwf+vjX655JA9/Xjjz8Kbm5uwqVLlwRBEIRNmzYJtra2Qnx8vN62KpVKCAoKEmbMmCGUlZUJt27dEvr37y+89tprjV12k1Wb81laWiq0a9dOmDVrllBaWiqUl5cLM2fOFIKCgoSysrLGLr3Jqs05vdvu3buFLl26CACEhISERqjUONT2fH7++edCUFCQcO3aNUEQBOH48eOCj4+PkJyc3Gg1N3W1OafR0dGCubm5sGnTJkEQBKGkpESYNm2aoFAohKKiokatu6lavXq1EBwcLLz//vuCk5OTsG7dumq3NcTnEoPFA7Rp00b44osvdNpGjhwpTJ8+XW/bDRs2CA4ODoJKpdK2nTp1SjAzMxOysrIavFZjUJvzee7cOSEkJETQaDTaNqVSKQAQzp492+C1GovanNNKWVlZglwuF44dO8ZgcY/anM+8vDzB2tpaiIyM1GkvLy9v0BqNTW3O6ZIlS4Ru3brptOXm5goAhOjo6Aat0xh5e3vfN1gY4nOJl0LuIykpCfHx8Rg1apRO+6hRo7Bz50697SMjI/HYY4/BzMxM29ajRw84OjoiIiKiwett6mp7Pjt16oT9+/frrOty/vx5AICNjU3DFmskantOK02YMAGjR49G7969G7pEo1KXf/NmZmYICQnRaZdKpQ1ZplGp7Tnt0aMHYmNjERMTo23bvn07XFxcEBAQ0OD1NjeG+FxqUWuF1FZaWhoAwMPDQ6ddLpcjNTW1yu07duyo117d9i1Nbc/nvaKjoxEWFobx48fD19e3QWo0NnU5p99++y0SEhKwefPmBq/P2NT2fMbFxSEwMBB//PEHlixZguzsbHTo0AGLFy9G586dG6Xmpq6253TIkCH4+uuvMWLECISEhCAzMxNmZmY4dOgQWrVq1Sg1NyeG+Fxij8V9yGQyANBbxa26lVFlMlmVK76JtZKqsavt+bzb8uXL0b9/f4wfPx6rV69ukPqMUW3P6eXLlzF37lz89NNPnOWwCrU9n2q1GleuXMFff/2Fffv2ITY2FoMGDUL//v2RkpLS4PUag7qc06SkJLi5uSE4OBjdu3fHuXPncODAgQavtTkyxOcSeyzuo3Il1LS0NPj7+2vb09PTIZfLq9y+Mp3frbrtW5rank+gYvTzpEmTcOjQIezfv59d9/eozTktKyvD888/j7lz56JLly6NWqexqO3vqJeXF1QqFVavXq3tap45cybWrFmDrVu34o033micwpuw2p7Tzz77DDt27MCRI0e0oWTChAno3LkzAgICMHDgwMYpvJkwxOcSeyzuw9XVFV27dsWOHTt02vfu3Yvhw4frbT9s2DDs2bMH5eXl2raYmBhkZmZi8ODBDV5vU1fb8wkA7777LmJjY3Hq1CmGiirU5pympqbizJkzmDVrFiQSifYBAL6+vujXr1+j1d1U1fZ39KGHHoKJiYnOv/lK7BGqUNtzGhUVhb59+2pDBQD4+PjA398fx48fb/B6mxuDfC41yJDQZuTnn38W5HK5cOXKFUEQBOHPP/8UbG1thatXr+ptW1ZWJnTo0EGYPXu2UF5eLuTm5gqDBw8WpkyZ0thlN1m1OZ/Hjh0TnJychOzs7MYu06jU5pxWBbwrREdtz+fEiROFMWPGCEqlUlCr1UJ4eLjg5OQk3LhxozHLbtJqc04///xzwc3NTThx4oQgCBV32Pzvf/8TZDKZcOrUqUat2xg86K4QQ3wuMVjUwHfffSe0bdtWcHd3F4KDg4WDBw8KgiAIycnJglwu195vXdn2+OOPC+7u7oJcLhemTZsmlJSUGKr0Jqmm53PBggWChYWFIJfL9R5ffvmlId9Ck1Ob39F7MVjoq835LC4uFqZOnSq4u7sLbm5uwuDBg3k7dBVqek7VarWwbNkyoVOnToKHh4fg6uoqDBkyRIiIiDBk+U3WvcGiKXwucXVTIiIiEg3HWBAREZFoGCyIiIhINAwWREREJBoGCyIiIhINgwURERGJhsGCiIiIRMNgQURERKJhsCAiIiLRMFgQUb2NHz8e1tbWUCgUcHd3R5s2bfD++++jpKSkwY8dEhKCBQsWaL+XSCT4559/Gvy4RFQ1BgsiEkVYWBhSUlKQnp6O/fv3IyIiAq+99pqhyyKiRsZgQUSi8/LywqxZs/D7778buhQiamQMFkTUIAoLC2FtbQ0AuHnzJiZMmAAvLy94e3tj6tSpKCoq0m57/fp1PPPMM1AoFFAoFJg4cSKUSiUAQBAEfP755/Dz84O7uzuGDRuG5ORkg7wnInowBgsiEpUgCIiOjsbHH3+M9957D4IgYMSIEbh16xZiYmJw4cIFXL58Ge+99x6AigAyYMAAuLm5ISEhAXFxcVCpVFiyZAkAIDIyEmvWrMHBgweRkpICGxsbzJgxw5BvkYjuw9TQBRBR8/D7778jIiICmZmZcHd3x+rVqzFkyBBERUXh5MmTSE9Ph5WVFQBg6dKlCA4OxldffYX/+7//Q0FBAcLDwyGTySCTybB27VqYmZkBAAYPHowLFy5AJpMBAMaNG4eZM2ca7H0S0f0xWBCRKJ599lmsX78eSUlJmDhxIlauXIlBgwYhJSUFJiYm6N27t872VlZWuH79Oq5fv442bdpogwQAna9v3LiBhQsX4sCBA8jPz0dpaSksLCwa7X0RUe0wWBCRqLy8vLB582YEBQVhxYoV6Nu3L2QyGWJjY3UCQyVvb28kJCSgrKxM2ysBAOXl5TA1NcX48eMhlUqxZ88eyOVy7Ny5k3ebEDVhHGNBRKKzt7fHBx98gPnz58PX1xe9evXC5MmTtQMyT58+jZEjR0KlUuGpp56CtbU1pk6dCpVKBbVajYULF2LcuHEAAKVSibZt20IulyMrKwvLly/XGfhJRE0LgwURNYhJkybB0dERixYtwpYtW2Bubo5OnTrB09MTb7zxBmbOnAlzc3NYW1vj0KFDyM7Ohp+fH3x8fBATE4Ply5cDAFauXIlDhw7B3d0dw4cPx9y5c1FSUoKMjAwDv0MiqopEEATB0EUQERFR88AeCyIiIhINgwURERGJhsGCiIiIRMNgQURERKJhsCAiIiLRMFgQERGRaBgsiIiISDQMFkRERCQaBgsiIiISDYMFERERiYbBgoiIiETz/0gIvZyYuLNdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "# === 自宅(=1) / 非自宅(=0) へ二値化（再学習なし）===\n",
    "home_name = \"自宅\"\n",
    "home_id = (Config.CLASS_NAMES.index(home_name) if home_name in Config.CLASS_NAMES else 0)\n",
    "\n",
    "y_bin = (yh_true == home_id).astype(int)\n",
    "p_home = y_prob[:, home_id]  # P(自宅)\n",
    "\n",
    "# しきい値の候補\n",
    "prev = y_bin.mean()\n",
    "thr05 = 0.5\n",
    "thr_prev = np.quantile(p_home, 1 - prev)  # 予測陽性率 ≒ 有病率 に合わせる\n",
    "\n",
    "def at(thr):\n",
    "    pred = (p_home >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_bin, pred, labels=[0,1]).ravel()\n",
    "    sens = tp/(tp+fn+1e-12); spec = tn/(tn+fp+1e-12)\n",
    "    ppv  = tp/(tp+fp+1e-12); npv  = tn/(tn+fn+1e-12)\n",
    "    acc  = (tp+tn)/(tp+tn+fp+fn); f1 = 2*tp/(2*tp+fp+fn+1e-12)\n",
    "    return dict(thr=thr, sens=sens, spec=spec, ppv=ppv, npv=npv, acc=acc, f1=f1)\n",
    "\n",
    "# しきい値不要の指標\n",
    "auroc = roc_auc_score(y_bin, p_home)\n",
    "ap    = average_precision_score(y_bin, p_home)\n",
    "print(f\"Binary(Home vs Non-Home)  AUROC={auroc:.3f}  AP={ap:.3f}\")\n",
    "print(\"thr=0.50:\", at(thr05))\n",
    "print(\"thr@prevalence:\", at(thr_prev))\n",
    "\n",
    "# ROC / PR（簡易）\n",
    "fpr,tpr,_ = roc_curve(y_bin, p_home)\n",
    "plt.figure(figsize=(6,5)); plt.plot(fpr,tpr,label=f\"AUC={roc_auc_score(y_bin,p_home):.3f}\")\n",
    "plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"Home vs Non-Home ROC\"); plt.legend(); plt.show()\n",
    "\n",
    "pr,rc,_ = precision_recall_curve(y_bin, p_home)\n",
    "plt.figure(figsize=(6,5)); plt.plot(rc,pr,label=f\"AP={average_precision_score(y_bin,p_home):.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Home vs Non-Home PR\"); plt.legend(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
